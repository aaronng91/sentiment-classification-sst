{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sentiment Classification on Stanford Sentiment Treebank",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A43-Jjo1ySkk",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Classification on Stanford Sentiment Treebank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIFl11dIyQUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import vocab\n",
        "from torchtext.vocab import Vectors\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byixbpx4yQUf",
        "colab_type": "text"
      },
      "source": [
        "Download SST dataset and load into notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VN4ALzOgRu6u",
        "colab": {}
      },
      "source": [
        "! `curl -fsS https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip -o /tmp/trainDevTestTrees_PTB.zip`\n",
        "! `unzip -q -o -d /tmp /tmp/trainDevTestTrees_PTB.zip`\n",
        "! `rm -f /tmp/trainDevTestTrees_PTB.zip`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OJRhwJrtRu6x",
        "colab": {}
      },
      "source": [
        "def loadsst(path):\n",
        "    xs = list()\n",
        "    ys = list() \n",
        "    with open(path) as file:\n",
        "        # Quick, dirty, and improper S-expression parsing.\n",
        "        for i , line in enumerate(file):\n",
        "            soup = line.split()\n",
        "            ys.append(int(soup[0].lstrip(\"(\")))\n",
        "            tokens = list()\n",
        "            for chunk in soup[1:-1]:\n",
        "                if chunk[-1] == \")\":\n",
        "                    token = chunk.rstrip(')')\n",
        "                    tokens.append(token)\n",
        "            xs.append(tokens)\n",
        "    return xs, ys\n",
        "        \n",
        "ssttrainxs, ssttrainys = loadsst(\"/tmp/trees/train.txt\")\n",
        "sstvalidxs, sstvalidys = loadsst(\"/tmp/trees/dev.txt\")\n",
        "ssttestxs, ssttestys   = loadsst(\"/tmp/trees/test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FeiHkx8Ru6z",
        "colab": {}
      },
      "source": [
        "trainx = pd.DataFrame.from_records([[' '.join(x)] for x in ssttrainxs])\n",
        "trainy = pd.DataFrame(ssttrainys)\n",
        "validx = pd.DataFrame.from_records([[' '.join(x)] for x in sstvalidxs])\n",
        "validy = pd.DataFrame(sstvalidys)\n",
        "testx = pd.DataFrame.from_records([[' '.join(x)] for x in ssttestxs])\n",
        "testy = pd.DataFrame(ssttestys)\n",
        "train = pd.concat([trainx, trainy], axis=1)\n",
        "valid = pd.concat([validx, validy], axis=1)\n",
        "test = pd.concat([testx, testy], axis=1)\n",
        "train.to_csv('/tmp/train.csv', index=False)\n",
        "valid.to_csv('/tmp/valid.csv', index=False)\n",
        "test.to_csv('/tmp/test.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNKPmaHuyQU3",
        "colab_type": "text"
      },
      "source": [
        "Use PyTorch's TorchText library to load the training, validation and testing dataset. Here, we define our fields, where TEXT are our reviews and LABEL are our sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7vO2qAZ8Ru61",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(include_lengths=True)\n",
        "LABEL = data.Field(\n",
        "    use_vocab=False,\n",
        "    sequential=False,\n",
        "    pad_token=None,\n",
        "    unk_token=None\n",
        ")\n",
        "fields = [('Text', TEXT), ('Label', LABEL)]\n",
        "\n",
        "trainds, valds, testds = data.TabularDataset.splits(path='/tmp', \n",
        "                                            format='csv', \n",
        "                                            train='train.csv', \n",
        "                                            validation='valid.csv', \n",
        "                                            test='test.csv',\n",
        "                                            fields=fields, \n",
        "                                            skip_header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETyNSPVbyQU6",
        "colab_type": "text"
      },
      "source": [
        "Download embeddings and load it into notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bwJ9x1OlRu65",
        "colab": {}
      },
      "source": [
        "! `curl -fsS https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz -o /tmp/GoogleNews-vectors-negative300.bin.gz`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w8yJY5_VRu69",
        "outputId": "1716ee99-0e89-4c64-d678-9c578d00e3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = KeyedVectors.load_word2vec_format('/tmp/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "model.save_word2vec_format('/tmp/GoogleNews-vectors-negative300.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VrUrcGqyQU_",
        "colab_type": "text"
      },
      "source": [
        "We use build_vocab function in TorchText to build the vocabulary for our dataset using the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jt_HaSLGUq3y",
        "outputId": "280dd060-8bd6-4e55-a9be-9e70a453f288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "TEXT.build_vocab(trainds, vectors=vocab.Vectors('GoogleNews-vectors-negative300.txt', '/tmp'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3000000 [00:00<?, ?it/s]Skipping token b'3000000' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|█████████▉| 2999813/3000000 [06:43<00:00, 8197.36it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9Gurpf8yQVE",
        "colab_type": "text"
      },
      "source": [
        "We can inspect our vocabulary and observe that we have a 18254 x 300 dictionary, where each word is represented by a vector of size 300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cp-5yp-jebKI",
        "outputId": "ea0b853d-8813-427d-970f-e601c773290e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TEXT.vocab.vectors.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18254, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kFHWGZzdaL8P",
        "outputId": "5a6e9677-6a86-4b92-f266-15872731d72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "TEXT.vocab.vectors[TEXT.vocab.stoi['the']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0801,  0.1050,  0.0498,  0.0535, -0.0674, -0.1206,  0.0352, -0.1187,\n",
              "         0.0439,  0.0302, -0.0569, -0.0762,  0.0129,  0.0498, -0.0850, -0.0635,\n",
              "         0.0063, -0.0432,  0.0203,  0.0133, -0.0195,  0.0928, -0.1719, -0.0013,\n",
              "         0.0654,  0.0583, -0.0825,  0.0859, -0.0032,  0.0586, -0.0349, -0.0123,\n",
              "        -0.0481, -0.0030,  0.0564,  0.0150, -0.0723, -0.0522,  0.0967,  0.0430,\n",
              "        -0.0354, -0.0732,  0.0327, -0.0618,  0.0079,  0.0036, -0.0088,  0.0391,\n",
              "         0.0383,  0.0444,  0.0698,  0.0126, -0.0045, -0.0332, -0.0427,  0.0977,\n",
              "        -0.0216, -0.0378,  0.0119, -0.0139, -0.1133,  0.0933, -0.0393, -0.1162,\n",
              "         0.0233, -0.0160,  0.0264,  0.1074, -0.0047,  0.0962,  0.0280, -0.0540,\n",
              "         0.0854, -0.0369, -0.0203, -0.0854,  0.1250,  0.1445,  0.0267,  0.1504,\n",
              "         0.0527, -0.1865,  0.0815, -0.0106, -0.0374, -0.0732, -0.0752,  0.0361,\n",
              "        -0.1318,  0.0062,  0.0508,  0.0452,  0.0101, -0.1504, -0.0601,  0.0576,\n",
              "        -0.0069,  0.0159, -0.0214,  0.1035, -0.0003, -0.0469, -0.0164, -0.0786,\n",
              "        -0.0693,  0.0164, -0.0315, -0.0137, -0.0366, -0.0889, -0.0481, -0.0132,\n",
              "        -0.0718,  0.0059, -0.0461,  0.0398,  0.1006, -0.0493,  0.0757,  0.0388,\n",
              "        -0.1670, -0.0962, -0.1011,  0.0291, -0.0579, -0.0193, -0.0430, -0.0840,\n",
              "        -0.0199,  0.0515,  0.0085, -0.0361, -0.1494, -0.0186, -0.0364, -0.0767,\n",
              "        -0.0396, -0.0615, -0.0200,  0.0415,  0.0369, -0.0723,  0.0059, -0.0630,\n",
              "         0.0074, -0.0159,  0.0161, -0.0145,  0.0077,  0.1011, -0.0056,  0.0143,\n",
              "        -0.0762,  0.0564, -0.0129,  0.0306, -0.0249, -0.0986,  0.0325, -0.0281,\n",
              "        -0.0811,  0.0206,  0.0161, -0.0420, -0.0349, -0.0376,  0.0549,  0.0137,\n",
              "         0.0269, -0.0586, -0.0718, -0.1201, -0.0228, -0.1641, -0.0036, -0.0598,\n",
              "         0.0708, -0.0771,  0.0518, -0.0430, -0.0483,  0.0300, -0.0659, -0.0317,\n",
              "        -0.0488, -0.0349,  0.0588, -0.0146,  0.1807,  0.0569,  0.0525,  0.0579,\n",
              "         0.1167,  0.0520, -0.0535,  0.0187, -0.0156,  0.0058, -0.0732, -0.1162,\n",
              "         0.0405,  0.0625, -0.0432,  0.0106,  0.0217,  0.0425,  0.0327,  0.0442,\n",
              "         0.0576,  0.0261, -0.0183, -0.0270, -0.0067,  0.0051, -0.1162,  0.0036,\n",
              "         0.0576, -0.0596, -0.0884,  0.0135,  0.0454, -0.0464, -0.0177, -0.0625,\n",
              "         0.0344, -0.0242,  0.0309,  0.0957,  0.0796,  0.0393,  0.0280, -0.0859,\n",
              "         0.0811,  0.0664, -0.0004, -0.0693,  0.0359, -0.0342,  0.0449, -0.0077,\n",
              "        -0.0074, -0.0476,  0.0140, -0.0996,  0.0247, -0.0996,  0.1147,  0.0317,\n",
              "         0.0221,  0.0723,  0.0369,  0.0256,  0.0137, -0.0273,  0.0059, -0.0674,\n",
              "         0.0505, -0.0283, -0.0452, -0.0173,  0.0211,  0.0352, -0.0430,  0.0664,\n",
              "         0.1221,  0.1235,  0.0040,  0.0452, -0.0186,  0.0483,  0.0452,  0.0869,\n",
              "         0.0294,  0.0376,  0.0344, -0.0737, -0.0403, -0.1465, -0.0244, -0.0195,\n",
              "         0.0066, -0.0018, -0.0109,  0.0933,  0.0654,  0.0184, -0.0933, -0.0157,\n",
              "        -0.0713, -0.0894, -0.0713, -0.0302, -0.0130,  0.0164, -0.0183,  0.0148,\n",
              "         0.0050,  0.0037,  0.0476, -0.0688])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mfR8zt3yQVP",
        "colab_type": "text"
      },
      "source": [
        "Using TorchText's BucketIterator, we can load our training and validation set into a DataLoader, which helps in batching of our data and padding of sequences to match the longest sequence in the batch. Sequences of similar lengths are batched together, so we don't end up with too much padding.\n",
        "\n",
        "Here, we show an example of a batch of size 3 being created, where each column in the batch is a sequence converted into a vector of vocabulary indexes, with padding if necessary, and the corresponding labels in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mMRj2PAvabW2",
        "colab": {}
      },
      "source": [
        "traindl, valdl = data.BucketIterator.splits(datasets=(trainds, testds),\n",
        "                                            batch_sizes=(3,3),\n",
        "                                            sort_key=lambda x: len(x.Text),\n",
        "                                            device=None,\n",
        "                                            sort_within_batch=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8_Fi_OaTeiEL",
        "outputId": "27c2aa8d-a888-4886-c7c8-926c98068493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "batch = next(iter(traindl))\n",
        "print(batch.Text)\n",
        "print(batch.Label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 6442,  2921,    27],\n",
            "        [   14,     3,  1744],\n",
            "        [   39,   331,   155],\n",
            "        [    6,     9,     6],\n",
            "        [    3,   119,     3],\n",
            "        [  238,  4012,   147],\n",
            "        [    8,     2,   124],\n",
            "        [   58,    71,    37],\n",
            "        [  537,    96,     7],\n",
            "        [   19,     3,   738],\n",
            "        [ 1316,    19,   233],\n",
            "        [    2,   469,     4],\n",
            "        [ 2034,     9,   425],\n",
            "        [   20,   400,     5],\n",
            "        [ 1589,   588,   801],\n",
            "        [ 3465,     2,     6],\n",
            "        [   18,  5656,   150],\n",
            "        [   12,    69,   227],\n",
            "        [  195,     2, 13978],\n",
            "        [   12,     4,    12],\n",
            "        [ 3253,     3,    57],\n",
            "        [   23,   342,     1],\n",
            "        [    7,   159,     1],\n",
            "        [ 2390,    31,     1],\n",
            "        [11524,  6192,     1],\n",
            "        [   71,  4569,     1],\n",
            "        [    5,     1,     1],\n",
            "        [   19,     1,     1],\n",
            "        [   63,     1,     1],\n",
            "        [   26,     1,     1]]), tensor([30, 26, 21]))\n",
            "tensor([4, 4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx5G8-TIyQVV",
        "colab_type": "text"
      },
      "source": [
        "Here, we create a wrapper class around the BucketIterator, since it returns a Batch object instead of the text and labels in each batch. This will help when accessing the text and labels in each batch directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tuQAFa8wq2gK",
        "colab": {}
      },
      "source": [
        "class BatchGenerator:\n",
        "    def __init__(self, dl, x_field, y_field):\n",
        "        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            X = getattr(batch, self.x_field)\n",
        "            y = getattr(batch, self.y_field)\n",
        "            yield (X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-sawGndyQVY",
        "colab_type": "text"
      },
      "source": [
        "Definition of our Sentiment Classification model, using RNN, followed by a MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xPyLn5kRt7RX",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, embed_dim, pretrained_vec, \n",
        "        num_hidden_rnn, num_rnn_layers, \n",
        "        mlp_layers, num_classes,\n",
        "        rec_unit_type, train_embeddings=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_hidden_rnn = num_hidden_rnn\n",
        "        self.num_rnn_layers = num_rnn_layers\n",
        "        self.mlp_layers = mlp_layers\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.embed_dim)\n",
        "        self.embeddings.weight.data.copy_(pretrained_vec) # Load pretrained embeddings\n",
        "        self.embeddings.weight.requires_grad = train_embeddings  # Decide if embeddings get updated or not\n",
        "\n",
        "        # Define RNN layers using \"vanilla\" RNN, GRU or LSTM\n",
        "        if (rec_unit_type == \"RNN\"):\n",
        "            self.rec = nn.RNN(\n",
        "                input_size=self.embed_dim, \n",
        "                hidden_size=self.num_hidden_rnn, \n",
        "                num_layers=num_rnn_layers)\n",
        "        elif (rec_unit_type == \"GRU\"):\n",
        "            self.rec = nn.GRU(\n",
        "                input_size=self.embed_dim, \n",
        "                hidden_size=self.num_hidden_rnn, \n",
        "                num_layers=num_rnn_layers)\n",
        "        elif (rec_unit_type == \"LSTM\"):\n",
        "            self.rec = nn.LSTM(\n",
        "                input_size=self.embed_dim, \n",
        "                hidden_size=self.num_hidden_rnn,\n",
        "                num_layers=num_rnn_layers)\n",
        "\n",
        "        # Define MLP layers\n",
        "        self.mlp = nn.ModuleList()\n",
        "        for i, hidden_layer in enumerate(mlp_layers):\n",
        "            if i == 0:\n",
        "                self.mlp.append(nn.Linear(self.num_hidden_rnn, hidden_layer))\n",
        "            else:\n",
        "                self.mlp.append(nn.Linear(mlp_layers[i-1], hidden_layer))\n",
        "\n",
        "        # Define final output layer\n",
        "        self.out = nn.Linear(mlp_layers[-1], self.num_classes)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        # Re-initialize hidden states for each batch, so we are not sharing hidden states across batches\n",
        "        self.h = self.init_hidden(self.num_rnn_layers, X.size(1))\n",
        "        \n",
        "        # Convert words into embeddings\n",
        "        embeddings = self.embeddings(X)\n",
        "        \n",
        "        # Pass through RNN layer and get hidden state at last timestep\n",
        "        output, self.h = self.rec(embeddings, self.h)\n",
        "        \n",
        "        # LSTM returns a tuple of hidden state and cell state, so pick hidden state only\n",
        "        if (rec_unit_type == \"LSTM\"):\n",
        "            self.h = self.h[0]\n",
        "            \n",
        "        # Pass through MLP layer with RELU activation function\n",
        "        out = F.relu(self.mlp[0](self.h[-1]))\n",
        "        for i in range(1, len(self.mlp)):\n",
        "            out = F.relu(self.mlp[i](out))\n",
        "        \n",
        "        return self.out(out)\n",
        "    \n",
        "    def init_hidden(self, num_layers, batch_size): \n",
        "        if (rec_unit_type == \"LSTM\"):\n",
        "            self.h = (Variable(torch.zeros((num_layers,batch_size,self.num_hidden_rnn))).to(device),\n",
        "                      Variable(torch.zeros((num_layers,batch_size,self.num_hidden_rnn))).to(device))\n",
        "        else:\n",
        "            self.h = Variable(torch.zeros((num_layers,batch_size,self.num_hidden_rnn))).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X-lTtQ0yQVc",
        "colab_type": "text"
      },
      "source": [
        "Definition of training loop, where we return the model at the lowest validation loss during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QhZ_myRvuv1B",
        "colab": {}
      },
      "source": [
        "def fit(model, train_dl, val_dl, loss_fn, opt, epochs, batch_size):\n",
        "    measurements = {\n",
        "        \"Train Loss\": [],\n",
        "        \"Train Acc\": [],\n",
        "        \"Val Loss\": [],\n",
        "        \"Val Acc\": [],\n",
        "        \"Lowest Val Loss\": np.Inf,\n",
        "        \"Lowest Val Loss Epoch\": np.Inf\n",
        "    }\n",
        "    lowest_val_loss = np.Inf\n",
        "    lowest_val_loss_epoch = np.Inf\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        y_true_train = list()\n",
        "        y_pred_train = list()\n",
        "        total_loss_train = 0  \n",
        "        \n",
        "        model.train() # Set model in train mode\n",
        "        \n",
        "        for (X,_),y in iter(train_dl):\n",
        "            opt.zero_grad() # Clear old gradients\n",
        "            pred = model(X) # Make prediction using model\n",
        "            loss = loss_fn(pred, y)\n",
        "            loss.backward() # Compute derivatives of loss w.r.t. parameters using backpropagation\n",
        "            opt.step() # Take a step using computed gradients\n",
        "            pred_idx = torch.max(pred, 1)[1]\n",
        "            \n",
        "            y_true_train += list(y.cpu().data.numpy())\n",
        "            y_pred_train += list(pred_idx.cpu().data.numpy())\n",
        "            total_loss_train += loss.item()\n",
        "        \n",
        "        train_acc = accuracy_score(y_true_train, y_pred_train)\n",
        "        train_loss = total_loss_train/len(train_dl)\n",
        "        measurements[\"Train Acc\"].append(train_acc)\n",
        "        measurements[\"Train Loss\"].append(train_loss)\n",
        "        \n",
        "        # Validation\n",
        "        y_true_val = list()\n",
        "        y_pred_val = list()\n",
        "        total_loss_val = 0\n",
        "        \n",
        "        model.eval() # Set model in eval mode\n",
        "\n",
        "        for (X,_),y in iter(val_dl):\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            pred_idx = torch.max(pred, 1)[1]\n",
        "\n",
        "            y_true_val += list(y.cpu().data.numpy())\n",
        "            y_pred_val += list(pred_idx.cpu().data.numpy())\n",
        "            total_loss_val += loss.item()\n",
        "        val_acc = accuracy_score(y_true_val, y_pred_val)\n",
        "        val_loss = total_loss_val/len(val_dl)\n",
        "        measurements[\"Val Acc\"].append(val_acc)\n",
        "        measurements[\"Val Loss\"].append(val_loss)\n",
        "        \n",
        "        if (val_loss < measurements[\"Lowest Val Loss\"]):\n",
        "            torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "            measurements[\"Lowest Val Loss\"] = val_loss\n",
        "            measurements[\"Lowest Val Loss Epoch\"] = epoch\n",
        "        \n",
        "        print(f'Epoch {epoch}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
        "        \n",
        "    # Return model checkpoint stored at lowest validation loss\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "    print(f'Lowest val_loss: {measurements[\"Lowest Val Loss\"]:.4f}, at epoch {measurements[\"Lowest Val Loss Epoch\"]}')\n",
        "    \n",
        "    return model, measurements"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iMCXvI0PtQjU",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds),\n",
        "                                            batch_sizes=(batch_size, batch_size),\n",
        "                                            sort_key=lambda x: len(x.Text),\n",
        "                                            device=device,\n",
        "                                            sort_within_batch=False)\n",
        "train_batch_it = BatchGenerator(traindl, 'Text', 'Label')\n",
        "val_batch_it = BatchGenerator(valdl, 'Text', 'Label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLCSo2rQyQVx",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTLHOPVqyQVy",
        "colab_type": "text"
      },
      "source": [
        "The hyperparameters that we can tune with this model are:\n",
        "\n",
        "1.   Type of recurrent unit (RNN, GRU, LSTM)\n",
        "2.   Recurrent layer size\n",
        "3.   Depth of recurrent network\n",
        "4.   MLP layer size\n",
        "5.   Depth of MLP\n",
        "6.   Whether to train embeddings\n",
        "\n",
        "To limit the search space via grid-search, we did some preliminary testing to eliminate certain variables and determine the size of the search space for each hyperparameter. We noticed the following:\n",
        "\n",
        "1.   RNN did not achieve validation accuracy comparable to GRU or LSTM under all scenarios.\n",
        "2.   Training embeddings did not help at all.\n",
        "3.   Using anything more than 2 layers of recurrent units or MLP did not improve the validation accuracy. The depth and layer size of MLP did not contribute as much to the performance of the model, compared to the recurrent network.\n",
        "\n",
        "Thus, we decided to conduct grid search with the following hyperparameter search space:\n",
        "\n",
        "1.   Type of recurrent unit: [GRU, LSTM]\n",
        "2.   Recurrent layer size: [30, 40, 50, 60, 70, 80, 100, 150, 200, 250]\n",
        "3.   Depth of recurrent network: [1, 2]\n",
        "4.   MLP layer size: [30, 40, 50, 60, 70]\n",
        "\n",
        "Note: Code below is commented out since this takes a long time to run and only used for exploration purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq3mBQtY2Krb",
        "colab_type": "code",
        "outputId": "b4876f09-c39d-4f9f-aad0-45818db38fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# vocab_size = len(TEXT.vocab)\n",
        "# embedding_dim = TEXT.vocab.vectors.size()[1]\n",
        "# num_classes = 5\n",
        "# train_embeddings = False\n",
        "\n",
        "# for rec_unit_type in [\"GRU\", \"LSTM\"]:\n",
        "#   for num_hidden_rnn in [30, 40, 50, 60, 70, 80, 100, 150, 200, 250]:\n",
        "#     for num_rnn_layers in [1,2]:\n",
        "#       for mlp_layers in [[30],[40],[50],[60],[70]]:\n",
        "#         print(rec_unit_type, num_hidden_rnn, num_rnn_layers, mlp_layers)\n",
        "\n",
        "#         m = Model(\n",
        "#             vocab_size, \n",
        "#             embedding_dim, \n",
        "#             TEXT.vocab.vectors, \n",
        "#             num_hidden_rnn, \n",
        "#             num_rnn_layers, \n",
        "#             mlp_layers, \n",
        "#             num_classes, \n",
        "#             rec_unit_type, \n",
        "#             train_embeddings).to(device)\n",
        "#         opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), 1e-3)\n",
        "\n",
        "#         m, measurements = fit(\n",
        "#             model=m,\n",
        "#             train_dl=train_batch_it, \n",
        "#             val_dl=val_batch_it, \n",
        "#             loss_fn=F.cross_entropy,\n",
        "#             opt=opt,\n",
        "#             epochs=25,\n",
        "#             batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GRU 30 1 [30]\n",
            "Epoch 0: train_loss: 1.5867 train_acc: 0.2375 | val_loss: 1.5776 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2698 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2705 | val_loss: 1.5710 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5672 train_acc: 0.2722 | val_loss: 1.5688 val_acc: 0.2498\n",
            "Epoch 4: train_loss: 1.4661 train_acc: 0.3415 | val_loss: 1.3933 val_acc: 0.3678\n",
            "Epoch 5: train_loss: 1.2974 train_acc: 0.4189 | val_loss: 1.3636 val_acc: 0.3824\n",
            "Epoch 6: train_loss: 1.2423 train_acc: 0.4421 | val_loss: 1.3533 val_acc: 0.3833\n",
            "Epoch 7: train_loss: 1.2077 train_acc: 0.4559 | val_loss: 1.3519 val_acc: 0.3933\n",
            "Epoch 8: train_loss: 1.1835 train_acc: 0.4703 | val_loss: 1.3489 val_acc: 0.4033\n",
            "Epoch 9: train_loss: 1.1545 train_acc: 0.4800 | val_loss: 1.3550 val_acc: 0.3969\n",
            "Epoch 10: train_loss: 1.1401 train_acc: 0.4970 | val_loss: 1.3474 val_acc: 0.3996\n",
            "Epoch 11: train_loss: 1.1102 train_acc: 0.5075 | val_loss: 1.3432 val_acc: 0.4069\n",
            "Epoch 12: train_loss: 1.0867 train_acc: 0.5185 | val_loss: 1.3511 val_acc: 0.3915\n",
            "Epoch 13: train_loss: 1.0594 train_acc: 0.5412 | val_loss: 1.3641 val_acc: 0.4024\n",
            "Epoch 14: train_loss: 1.0343 train_acc: 0.5496 | val_loss: 1.3903 val_acc: 0.4033\n",
            "Epoch 15: train_loss: 1.0137 train_acc: 0.5647 | val_loss: 1.4102 val_acc: 0.3942\n",
            "Epoch 16: train_loss: 0.9877 train_acc: 0.5772 | val_loss: 1.3925 val_acc: 0.4042\n",
            "Epoch 17: train_loss: 0.9673 train_acc: 0.5846 | val_loss: 1.4255 val_acc: 0.4024\n",
            "Epoch 18: train_loss: 0.9433 train_acc: 0.6003 | val_loss: 1.4378 val_acc: 0.4078\n",
            "Epoch 19: train_loss: 0.9141 train_acc: 0.6152 | val_loss: 1.4476 val_acc: 0.4033\n",
            "Epoch 20: train_loss: 0.8920 train_acc: 0.6335 | val_loss: 1.4682 val_acc: 0.4005\n",
            "Epoch 21: train_loss: 0.8583 train_acc: 0.6540 | val_loss: 1.5142 val_acc: 0.4060\n",
            "Epoch 22: train_loss: 0.8294 train_acc: 0.6634 | val_loss: 1.4892 val_acc: 0.4060\n",
            "Epoch 23: train_loss: 0.8018 train_acc: 0.6777 | val_loss: 1.5682 val_acc: 0.3896\n",
            "Epoch 24: train_loss: 0.7793 train_acc: 0.6978 | val_loss: 1.5721 val_acc: 0.4051\n",
            "Lowest val_loss: 1.3432, at epoch 11\n",
            "GRU 30 1 [40]\n",
            "Epoch 0: train_loss: 1.5738 train_acc: 0.2622 | val_loss: 1.5753 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5680 train_acc: 0.2687 | val_loss: 1.5746 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5674 train_acc: 0.2666 | val_loss: 1.5695 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5657 train_acc: 0.2694 | val_loss: 1.5682 val_acc: 0.2589\n",
            "Epoch 4: train_loss: 1.4521 train_acc: 0.3565 | val_loss: 1.3592 val_acc: 0.3933\n",
            "Epoch 5: train_loss: 1.3049 train_acc: 0.4155 | val_loss: 1.3139 val_acc: 0.4114\n",
            "Epoch 6: train_loss: 1.2423 train_acc: 0.4414 | val_loss: 1.3189 val_acc: 0.3978\n",
            "Epoch 7: train_loss: 1.2099 train_acc: 0.4614 | val_loss: 1.3006 val_acc: 0.4160\n",
            "Epoch 8: train_loss: 1.1862 train_acc: 0.4711 | val_loss: 1.3144 val_acc: 0.4096\n",
            "Epoch 9: train_loss: 1.1671 train_acc: 0.4847 | val_loss: 1.3066 val_acc: 0.4078\n",
            "Epoch 10: train_loss: 1.1470 train_acc: 0.4943 | val_loss: 1.3386 val_acc: 0.3951\n",
            "Epoch 11: train_loss: 1.1279 train_acc: 0.5040 | val_loss: 1.3736 val_acc: 0.4005\n",
            "Epoch 12: train_loss: 1.1097 train_acc: 0.5154 | val_loss: 1.3234 val_acc: 0.4205\n",
            "Epoch 13: train_loss: 1.0858 train_acc: 0.5234 | val_loss: 1.3622 val_acc: 0.4142\n",
            "Epoch 14: train_loss: 1.0669 train_acc: 0.5362 | val_loss: 1.3403 val_acc: 0.4069\n",
            "Epoch 15: train_loss: 1.0405 train_acc: 0.5508 | val_loss: 1.4042 val_acc: 0.4124\n",
            "Epoch 16: train_loss: 1.0289 train_acc: 0.5522 | val_loss: 1.3943 val_acc: 0.4033\n",
            "Epoch 17: train_loss: 0.9984 train_acc: 0.5698 | val_loss: 1.3605 val_acc: 0.4251\n",
            "Epoch 18: train_loss: 0.9744 train_acc: 0.5864 | val_loss: 1.4035 val_acc: 0.4105\n",
            "Epoch 19: train_loss: 0.9508 train_acc: 0.6000 | val_loss: 1.3846 val_acc: 0.4142\n",
            "Epoch 20: train_loss: 0.9279 train_acc: 0.6080 | val_loss: 1.4195 val_acc: 0.4069\n",
            "Epoch 21: train_loss: 0.8982 train_acc: 0.6225 | val_loss: 1.4462 val_acc: 0.4096\n",
            "Epoch 22: train_loss: 0.8757 train_acc: 0.6371 | val_loss: 1.4570 val_acc: 0.4042\n",
            "Epoch 23: train_loss: 0.8556 train_acc: 0.6523 | val_loss: 1.4628 val_acc: 0.4033\n",
            "Epoch 24: train_loss: 0.8269 train_acc: 0.6692 | val_loss: 1.4701 val_acc: 0.4051\n",
            "Lowest val_loss: 1.3006, at epoch 7\n",
            "GRU 30 1 [50]\n",
            "Epoch 0: train_loss: 1.5746 train_acc: 0.2604 | val_loss: 1.5789 val_acc: 0.2570\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2673 | val_loss: 1.5670 val_acc: 0.3034\n",
            "Epoch 2: train_loss: 1.5674 train_acc: 0.2677 | val_loss: 1.5800 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2699 | val_loss: 1.5678 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5508 train_acc: 0.2907 | val_loss: 1.4561 val_acc: 0.3497\n",
            "Epoch 5: train_loss: 1.3539 train_acc: 0.4075 | val_loss: 1.3922 val_acc: 0.3515\n",
            "Epoch 6: train_loss: 1.2557 train_acc: 0.4380 | val_loss: 1.3953 val_acc: 0.3760\n",
            "Epoch 7: train_loss: 1.2155 train_acc: 0.4553 | val_loss: 1.3210 val_acc: 0.4096\n",
            "Epoch 8: train_loss: 1.1905 train_acc: 0.4621 | val_loss: 1.3165 val_acc: 0.4233\n",
            "Epoch 9: train_loss: 1.1731 train_acc: 0.4738 | val_loss: 1.3193 val_acc: 0.4160\n",
            "Epoch 10: train_loss: 1.1532 train_acc: 0.4834 | val_loss: 1.3322 val_acc: 0.4142\n",
            "Epoch 11: train_loss: 1.1330 train_acc: 0.4896 | val_loss: 1.3242 val_acc: 0.4296\n",
            "Epoch 12: train_loss: 1.1096 train_acc: 0.5080 | val_loss: 1.3476 val_acc: 0.4142\n",
            "Epoch 13: train_loss: 1.0906 train_acc: 0.5135 | val_loss: 1.3524 val_acc: 0.4287\n",
            "Epoch 14: train_loss: 1.0660 train_acc: 0.5259 | val_loss: 1.3457 val_acc: 0.4096\n",
            "Epoch 15: train_loss: 1.0452 train_acc: 0.5373 | val_loss: 1.3584 val_acc: 0.4214\n",
            "Epoch 16: train_loss: 1.0250 train_acc: 0.5478 | val_loss: 1.3473 val_acc: 0.4269\n",
            "Epoch 17: train_loss: 0.9958 train_acc: 0.5631 | val_loss: 1.3646 val_acc: 0.4142\n",
            "Epoch 18: train_loss: 0.9792 train_acc: 0.5682 | val_loss: 1.3880 val_acc: 0.4233\n",
            "Epoch 19: train_loss: 0.9498 train_acc: 0.5845 | val_loss: 1.4291 val_acc: 0.4078\n",
            "Epoch 20: train_loss: 0.9202 train_acc: 0.5988 | val_loss: 1.3987 val_acc: 0.4187\n",
            "Epoch 21: train_loss: 0.8946 train_acc: 0.6160 | val_loss: 1.4157 val_acc: 0.4133\n",
            "Epoch 22: train_loss: 0.8732 train_acc: 0.6254 | val_loss: 1.4381 val_acc: 0.4051\n",
            "Epoch 23: train_loss: 0.8454 train_acc: 0.6447 | val_loss: 1.4570 val_acc: 0.4105\n",
            "Epoch 24: train_loss: 0.8346 train_acc: 0.6452 | val_loss: 1.4884 val_acc: 0.4151\n",
            "Lowest val_loss: 1.3165, at epoch 8\n",
            "GRU 30 1 [60]\n",
            "Epoch 0: train_loss: 1.5774 train_acc: 0.2656 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2733 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5680 train_acc: 0.2670 | val_loss: 1.5706 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5664 train_acc: 0.2653 | val_loss: 1.5722 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5644 train_acc: 0.2725 | val_loss: 1.5611 val_acc: 0.2752\n",
            "Epoch 5: train_loss: 1.4894 train_acc: 0.3379 | val_loss: 1.3772 val_acc: 0.3778\n",
            "Epoch 6: train_loss: 1.3056 train_acc: 0.4160 | val_loss: 1.3372 val_acc: 0.3987\n",
            "Epoch 7: train_loss: 1.2381 train_acc: 0.4451 | val_loss: 1.3163 val_acc: 0.4042\n",
            "Epoch 8: train_loss: 1.2068 train_acc: 0.4614 | val_loss: 1.3297 val_acc: 0.4042\n",
            "Epoch 9: train_loss: 1.1809 train_acc: 0.4731 | val_loss: 1.3235 val_acc: 0.4151\n",
            "Epoch 10: train_loss: 1.1594 train_acc: 0.4865 | val_loss: 1.3253 val_acc: 0.4069\n",
            "Epoch 11: train_loss: 1.1354 train_acc: 0.4985 | val_loss: 1.3523 val_acc: 0.4069\n",
            "Epoch 12: train_loss: 1.1176 train_acc: 0.5096 | val_loss: 1.3516 val_acc: 0.4051\n",
            "Epoch 13: train_loss: 1.1020 train_acc: 0.5172 | val_loss: 1.3666 val_acc: 0.4087\n",
            "Epoch 14: train_loss: 1.0769 train_acc: 0.5276 | val_loss: 1.3748 val_acc: 0.3987\n",
            "Epoch 15: train_loss: 1.0644 train_acc: 0.5329 | val_loss: 1.3727 val_acc: 0.4033\n",
            "Epoch 16: train_loss: 1.0371 train_acc: 0.5474 | val_loss: 1.3908 val_acc: 0.4024\n",
            "Epoch 17: train_loss: 1.0223 train_acc: 0.5599 | val_loss: 1.3910 val_acc: 0.4015\n",
            "Epoch 18: train_loss: 1.0062 train_acc: 0.5686 | val_loss: 1.3863 val_acc: 0.4042\n",
            "Epoch 19: train_loss: 0.9755 train_acc: 0.5854 | val_loss: 1.4318 val_acc: 0.3960\n",
            "Epoch 20: train_loss: 0.9515 train_acc: 0.5954 | val_loss: 1.4305 val_acc: 0.4087\n",
            "Epoch 21: train_loss: 0.9319 train_acc: 0.6167 | val_loss: 1.4264 val_acc: 0.4051\n",
            "Epoch 22: train_loss: 0.9055 train_acc: 0.6266 | val_loss: 1.4355 val_acc: 0.4051\n",
            "Epoch 23: train_loss: 0.8800 train_acc: 0.6323 | val_loss: 1.4871 val_acc: 0.3996\n",
            "Epoch 24: train_loss: 0.8557 train_acc: 0.6498 | val_loss: 1.5061 val_acc: 0.3969\n",
            "Lowest val_loss: 1.3163, at epoch 7\n",
            "GRU 30 1 [70]\n",
            "Epoch 0: train_loss: 1.5709 train_acc: 0.2731 | val_loss: 1.5724 val_acc: 0.2888\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2628 | val_loss: 1.5705 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5672 train_acc: 0.2686 | val_loss: 1.5703 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5662 train_acc: 0.2671 | val_loss: 1.5699 val_acc: 0.2589\n",
            "Epoch 4: train_loss: 1.5376 train_acc: 0.2981 | val_loss: 1.5533 val_acc: 0.2761\n",
            "Epoch 5: train_loss: 1.3660 train_acc: 0.3944 | val_loss: 1.3408 val_acc: 0.4096\n",
            "Epoch 6: train_loss: 1.2702 train_acc: 0.4352 | val_loss: 1.3229 val_acc: 0.4051\n",
            "Epoch 7: train_loss: 1.2244 train_acc: 0.4483 | val_loss: 1.3238 val_acc: 0.4024\n",
            "Epoch 8: train_loss: 1.2061 train_acc: 0.4661 | val_loss: 1.3046 val_acc: 0.4078\n",
            "Epoch 9: train_loss: 1.1819 train_acc: 0.4738 | val_loss: 1.3355 val_acc: 0.4233\n",
            "Epoch 10: train_loss: 1.1549 train_acc: 0.4823 | val_loss: 1.3298 val_acc: 0.4278\n",
            "Epoch 11: train_loss: 1.1346 train_acc: 0.4981 | val_loss: 1.3641 val_acc: 0.4223\n",
            "Epoch 12: train_loss: 1.1252 train_acc: 0.5001 | val_loss: 1.3378 val_acc: 0.4178\n",
            "Epoch 13: train_loss: 1.0986 train_acc: 0.5112 | val_loss: 1.3398 val_acc: 0.4287\n",
            "Epoch 14: train_loss: 1.0812 train_acc: 0.5240 | val_loss: 1.3544 val_acc: 0.4205\n",
            "Epoch 15: train_loss: 1.0673 train_acc: 0.5328 | val_loss: 1.3641 val_acc: 0.4214\n",
            "Epoch 16: train_loss: 1.0367 train_acc: 0.5476 | val_loss: 1.3585 val_acc: 0.4142\n",
            "Epoch 17: train_loss: 1.0178 train_acc: 0.5620 | val_loss: 1.3831 val_acc: 0.4114\n",
            "Epoch 18: train_loss: 0.9980 train_acc: 0.5700 | val_loss: 1.3862 val_acc: 0.4133\n",
            "Epoch 19: train_loss: 0.9707 train_acc: 0.5861 | val_loss: 1.4150 val_acc: 0.4214\n",
            "Epoch 20: train_loss: 0.9499 train_acc: 0.5976 | val_loss: 1.4085 val_acc: 0.4233\n",
            "Epoch 21: train_loss: 0.9331 train_acc: 0.6036 | val_loss: 1.4328 val_acc: 0.4169\n",
            "Epoch 22: train_loss: 0.8981 train_acc: 0.6237 | val_loss: 1.4599 val_acc: 0.4169\n",
            "Epoch 23: train_loss: 0.8859 train_acc: 0.6271 | val_loss: 1.5118 val_acc: 0.4223\n",
            "Epoch 24: train_loss: 0.8557 train_acc: 0.6509 | val_loss: 1.5108 val_acc: 0.4151\n",
            "Lowest val_loss: 1.3046, at epoch 8\n",
            "GRU 30 2 [30]\n",
            "Epoch 0: train_loss: 1.5719 train_acc: 0.2629 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2671 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2707 | val_loss: 1.5688 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.4831 train_acc: 0.3345 | val_loss: 1.3680 val_acc: 0.3978\n",
            "Epoch 4: train_loss: 1.2811 train_acc: 0.4315 | val_loss: 1.3301 val_acc: 0.4096\n",
            "Epoch 5: train_loss: 1.2346 train_acc: 0.4548 | val_loss: 1.3282 val_acc: 0.4151\n",
            "Epoch 6: train_loss: 1.2012 train_acc: 0.4680 | val_loss: 1.3489 val_acc: 0.4042\n",
            "Epoch 7: train_loss: 1.1794 train_acc: 0.4801 | val_loss: 1.3292 val_acc: 0.4142\n",
            "Epoch 8: train_loss: 1.1589 train_acc: 0.4849 | val_loss: 1.3305 val_acc: 0.4187\n",
            "Epoch 9: train_loss: 1.1372 train_acc: 0.4963 | val_loss: 1.3249 val_acc: 0.4187\n",
            "Epoch 10: train_loss: 1.1184 train_acc: 0.5089 | val_loss: 1.3346 val_acc: 0.4096\n",
            "Epoch 11: train_loss: 1.0925 train_acc: 0.5235 | val_loss: 1.3452 val_acc: 0.4187\n",
            "Epoch 12: train_loss: 1.0766 train_acc: 0.5314 | val_loss: 1.3596 val_acc: 0.4205\n",
            "Epoch 13: train_loss: 1.0510 train_acc: 0.5411 | val_loss: 1.3613 val_acc: 0.4169\n",
            "Epoch 14: train_loss: 1.0350 train_acc: 0.5515 | val_loss: 1.3729 val_acc: 0.4087\n",
            "Epoch 15: train_loss: 1.0143 train_acc: 0.5641 | val_loss: 1.3474 val_acc: 0.4096\n",
            "Epoch 16: train_loss: 0.9879 train_acc: 0.5785 | val_loss: 1.3669 val_acc: 0.4078\n",
            "Epoch 17: train_loss: 0.9628 train_acc: 0.5911 | val_loss: 1.3906 val_acc: 0.4251\n",
            "Epoch 18: train_loss: 0.9465 train_acc: 0.5973 | val_loss: 1.3959 val_acc: 0.4251\n",
            "Epoch 19: train_loss: 0.9135 train_acc: 0.6151 | val_loss: 1.4511 val_acc: 0.4278\n",
            "Epoch 20: train_loss: 0.8875 train_acc: 0.6269 | val_loss: 1.5034 val_acc: 0.4233\n",
            "Epoch 21: train_loss: 0.8639 train_acc: 0.6435 | val_loss: 1.4710 val_acc: 0.4296\n",
            "Epoch 22: train_loss: 0.8333 train_acc: 0.6570 | val_loss: 1.5315 val_acc: 0.4260\n",
            "Epoch 23: train_loss: 0.8047 train_acc: 0.6746 | val_loss: 1.5049 val_acc: 0.4205\n",
            "Epoch 24: train_loss: 0.7832 train_acc: 0.6866 | val_loss: 1.5743 val_acc: 0.4278\n",
            "Lowest val_loss: 1.3249, at epoch 9\n",
            "GRU 30 2 [40]\n",
            "Epoch 0: train_loss: 1.5722 train_acc: 0.2702 | val_loss: 1.5798 val_acc: 0.2598\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2717 | val_loss: 1.5725 val_acc: 0.2634\n",
            "Epoch 2: train_loss: 1.5688 train_acc: 0.2695 | val_loss: 1.5681 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5490 train_acc: 0.2903 | val_loss: 1.4378 val_acc: 0.3688\n",
            "Epoch 4: train_loss: 1.3484 train_acc: 0.4045 | val_loss: 1.3886 val_acc: 0.3724\n",
            "Epoch 5: train_loss: 1.2643 train_acc: 0.4301 | val_loss: 1.3281 val_acc: 0.4024\n",
            "Epoch 6: train_loss: 1.2257 train_acc: 0.4513 | val_loss: 1.3330 val_acc: 0.4105\n",
            "Epoch 7: train_loss: 1.1921 train_acc: 0.4693 | val_loss: 1.3280 val_acc: 0.4124\n",
            "Epoch 8: train_loss: 1.1712 train_acc: 0.4773 | val_loss: 1.3428 val_acc: 0.4178\n",
            "Epoch 9: train_loss: 1.1501 train_acc: 0.4930 | val_loss: 1.3210 val_acc: 0.3996\n",
            "Epoch 10: train_loss: 1.1274 train_acc: 0.5032 | val_loss: 1.3313 val_acc: 0.4205\n",
            "Epoch 11: train_loss: 1.1085 train_acc: 0.5069 | val_loss: 1.3365 val_acc: 0.4142\n",
            "Epoch 12: train_loss: 1.0813 train_acc: 0.5226 | val_loss: 1.3244 val_acc: 0.4060\n",
            "Epoch 13: train_loss: 1.0684 train_acc: 0.5283 | val_loss: 1.3346 val_acc: 0.4105\n",
            "Epoch 14: train_loss: 1.0393 train_acc: 0.5424 | val_loss: 1.3538 val_acc: 0.4205\n",
            "Epoch 15: train_loss: 1.0104 train_acc: 0.5558 | val_loss: 1.3555 val_acc: 0.4187\n",
            "Epoch 16: train_loss: 0.9883 train_acc: 0.5720 | val_loss: 1.4043 val_acc: 0.4160\n",
            "Epoch 17: train_loss: 0.9684 train_acc: 0.5809 | val_loss: 1.3803 val_acc: 0.4169\n",
            "Epoch 18: train_loss: 0.9466 train_acc: 0.5885 | val_loss: 1.3958 val_acc: 0.4114\n",
            "Epoch 19: train_loss: 0.9129 train_acc: 0.6132 | val_loss: 1.4149 val_acc: 0.4114\n",
            "Epoch 20: train_loss: 0.8885 train_acc: 0.6276 | val_loss: 1.4076 val_acc: 0.4105\n",
            "Epoch 21: train_loss: 0.8567 train_acc: 0.6438 | val_loss: 1.4393 val_acc: 0.4096\n",
            "Epoch 22: train_loss: 0.8347 train_acc: 0.6530 | val_loss: 1.4608 val_acc: 0.4087\n",
            "Epoch 23: train_loss: 0.8135 train_acc: 0.6685 | val_loss: 1.5001 val_acc: 0.3996\n",
            "Epoch 24: train_loss: 0.7775 train_acc: 0.6845 | val_loss: 1.5758 val_acc: 0.4114\n",
            "Lowest val_loss: 1.3210, at epoch 9\n",
            "GRU 30 2 [50]\n",
            "Epoch 0: train_loss: 1.5762 train_acc: 0.2599 | val_loss: 1.5731 val_acc: 0.2679\n",
            "Epoch 1: train_loss: 1.5696 train_acc: 0.2674 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5677 train_acc: 0.2700 | val_loss: 1.5780 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5654 train_acc: 0.2732 | val_loss: 1.5375 val_acc: 0.3243\n",
            "Epoch 4: train_loss: 1.3830 train_acc: 0.3928 | val_loss: 1.3335 val_acc: 0.4005\n",
            "Epoch 5: train_loss: 1.2611 train_acc: 0.4346 | val_loss: 1.3279 val_acc: 0.3987\n",
            "Epoch 6: train_loss: 1.2175 train_acc: 0.4600 | val_loss: 1.3507 val_acc: 0.3969\n",
            "Epoch 7: train_loss: 1.1911 train_acc: 0.4688 | val_loss: 1.3289 val_acc: 0.4078\n",
            "Epoch 8: train_loss: 1.1754 train_acc: 0.4769 | val_loss: 1.3263 val_acc: 0.3987\n",
            "Epoch 9: train_loss: 1.1534 train_acc: 0.4882 | val_loss: 1.3423 val_acc: 0.4069\n",
            "Epoch 10: train_loss: 1.1374 train_acc: 0.4965 | val_loss: 1.3817 val_acc: 0.3860\n",
            "Epoch 11: train_loss: 1.1115 train_acc: 0.5132 | val_loss: 1.3473 val_acc: 0.4105\n",
            "Epoch 12: train_loss: 1.0943 train_acc: 0.5226 | val_loss: 1.3561 val_acc: 0.4142\n",
            "Epoch 13: train_loss: 1.0825 train_acc: 0.5321 | val_loss: 1.3459 val_acc: 0.4142\n",
            "Epoch 14: train_loss: 1.0494 train_acc: 0.5445 | val_loss: 1.3650 val_acc: 0.4151\n",
            "Epoch 15: train_loss: 1.0322 train_acc: 0.5566 | val_loss: 1.3668 val_acc: 0.4160\n",
            "Epoch 16: train_loss: 1.0188 train_acc: 0.5640 | val_loss: 1.3566 val_acc: 0.4078\n",
            "Epoch 17: train_loss: 0.9822 train_acc: 0.5833 | val_loss: 1.3965 val_acc: 0.4142\n",
            "Epoch 18: train_loss: 0.9692 train_acc: 0.5954 | val_loss: 1.4147 val_acc: 0.4024\n",
            "Epoch 19: train_loss: 0.9350 train_acc: 0.6098 | val_loss: 1.3925 val_acc: 0.4042\n",
            "Epoch 20: train_loss: 0.9138 train_acc: 0.6224 | val_loss: 1.4124 val_acc: 0.4133\n",
            "Epoch 21: train_loss: 0.8947 train_acc: 0.6355 | val_loss: 1.4438 val_acc: 0.4060\n",
            "Epoch 22: train_loss: 0.8641 train_acc: 0.6550 | val_loss: 1.4614 val_acc: 0.3969\n",
            "Epoch 23: train_loss: 0.8373 train_acc: 0.6688 | val_loss: 1.4999 val_acc: 0.3978\n",
            "Epoch 24: train_loss: 0.8117 train_acc: 0.6794 | val_loss: 1.4957 val_acc: 0.3887\n",
            "Lowest val_loss: 1.3263, at epoch 8\n",
            "GRU 30 2 [60]\n",
            "Epoch 0: train_loss: 1.5757 train_acc: 0.2639 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2714 | val_loss: 1.5700 val_acc: 0.2607\n",
            "Epoch 2: train_loss: 1.5244 train_acc: 0.3120 | val_loss: 1.4066 val_acc: 0.3742\n",
            "Epoch 3: train_loss: 1.3222 train_acc: 0.4079 | val_loss: 1.3466 val_acc: 0.4042\n",
            "Epoch 4: train_loss: 1.2450 train_acc: 0.4393 | val_loss: 1.3523 val_acc: 0.3924\n",
            "Epoch 5: train_loss: 1.2141 train_acc: 0.4610 | val_loss: 1.3335 val_acc: 0.4133\n",
            "Epoch 6: train_loss: 1.1894 train_acc: 0.4705 | val_loss: 1.3238 val_acc: 0.4096\n",
            "Epoch 7: train_loss: 1.1681 train_acc: 0.4824 | val_loss: 1.3470 val_acc: 0.4151\n",
            "Epoch 8: train_loss: 1.1430 train_acc: 0.4919 | val_loss: 1.3490 val_acc: 0.4205\n",
            "Epoch 9: train_loss: 1.1292 train_acc: 0.5062 | val_loss: 1.3437 val_acc: 0.4260\n",
            "Epoch 10: train_loss: 1.1053 train_acc: 0.5123 | val_loss: 1.3563 val_acc: 0.4251\n",
            "Epoch 11: train_loss: 1.0798 train_acc: 0.5279 | val_loss: 1.3740 val_acc: 0.3996\n",
            "Epoch 12: train_loss: 1.0600 train_acc: 0.5346 | val_loss: 1.3484 val_acc: 0.4142\n",
            "Epoch 13: train_loss: 1.0322 train_acc: 0.5533 | val_loss: 1.3589 val_acc: 0.4223\n",
            "Epoch 14: train_loss: 1.0178 train_acc: 0.5590 | val_loss: 1.3771 val_acc: 0.4160\n",
            "Epoch 15: train_loss: 0.9888 train_acc: 0.5767 | val_loss: 1.3697 val_acc: 0.4223\n",
            "Epoch 16: train_loss: 0.9753 train_acc: 0.5775 | val_loss: 1.4026 val_acc: 0.4005\n",
            "Epoch 17: train_loss: 0.9414 train_acc: 0.5985 | val_loss: 1.3930 val_acc: 0.4105\n",
            "Epoch 18: train_loss: 0.9152 train_acc: 0.6093 | val_loss: 1.3938 val_acc: 0.4151\n",
            "Epoch 19: train_loss: 0.8901 train_acc: 0.6227 | val_loss: 1.4262 val_acc: 0.4105\n",
            "Epoch 20: train_loss: 0.8645 train_acc: 0.6347 | val_loss: 1.4720 val_acc: 0.4051\n",
            "Epoch 21: train_loss: 0.8424 train_acc: 0.6525 | val_loss: 1.4902 val_acc: 0.4060\n",
            "Epoch 22: train_loss: 0.8220 train_acc: 0.6602 | val_loss: 1.4790 val_acc: 0.4060\n",
            "Epoch 23: train_loss: 0.7922 train_acc: 0.6778 | val_loss: 1.5254 val_acc: 0.3887\n",
            "Epoch 24: train_loss: 0.7543 train_acc: 0.6923 | val_loss: 1.5521 val_acc: 0.4005\n",
            "Lowest val_loss: 1.3238, at epoch 6\n",
            "GRU 30 2 [70]\n",
            "Epoch 0: train_loss: 1.5768 train_acc: 0.2571 | val_loss: 1.5880 val_acc: 0.2788\n",
            "Epoch 1: train_loss: 1.5696 train_acc: 0.2759 | val_loss: 1.5754 val_acc: 0.2543\n",
            "Epoch 2: train_loss: 1.5687 train_acc: 0.2681 | val_loss: 1.5711 val_acc: 0.2788\n",
            "Epoch 3: train_loss: 1.5675 train_acc: 0.2702 | val_loss: 1.5576 val_acc: 0.3025\n",
            "Epoch 4: train_loss: 1.4219 train_acc: 0.3643 | val_loss: 1.3370 val_acc: 0.4160\n",
            "Epoch 5: train_loss: 1.2601 train_acc: 0.4258 | val_loss: 1.3600 val_acc: 0.3769\n",
            "Epoch 6: train_loss: 1.2171 train_acc: 0.4576 | val_loss: 1.3050 val_acc: 0.4169\n",
            "Epoch 7: train_loss: 1.1867 train_acc: 0.4675 | val_loss: 1.3449 val_acc: 0.3987\n",
            "Epoch 8: train_loss: 1.1637 train_acc: 0.4830 | val_loss: 1.3144 val_acc: 0.4205\n",
            "Epoch 9: train_loss: 1.1431 train_acc: 0.4885 | val_loss: 1.3284 val_acc: 0.4069\n",
            "Epoch 10: train_loss: 1.1315 train_acc: 0.4956 | val_loss: 1.3207 val_acc: 0.4087\n",
            "Epoch 11: train_loss: 1.0975 train_acc: 0.5157 | val_loss: 1.3406 val_acc: 0.4105\n",
            "Epoch 12: train_loss: 1.0839 train_acc: 0.5218 | val_loss: 1.3230 val_acc: 0.4260\n",
            "Epoch 13: train_loss: 1.0587 train_acc: 0.5413 | val_loss: 1.3578 val_acc: 0.4242\n",
            "Epoch 14: train_loss: 1.0387 train_acc: 0.5453 | val_loss: 1.3784 val_acc: 0.4160\n",
            "Epoch 15: train_loss: 1.0206 train_acc: 0.5522 | val_loss: 1.3674 val_acc: 0.4305\n",
            "Epoch 16: train_loss: 0.9867 train_acc: 0.5763 | val_loss: 1.3784 val_acc: 0.4287\n",
            "Epoch 17: train_loss: 0.9685 train_acc: 0.5845 | val_loss: 1.4019 val_acc: 0.4260\n",
            "Epoch 18: train_loss: 0.9322 train_acc: 0.6062 | val_loss: 1.4155 val_acc: 0.4332\n",
            "Epoch 19: train_loss: 0.9167 train_acc: 0.6140 | val_loss: 1.4137 val_acc: 0.4233\n",
            "Epoch 20: train_loss: 0.8781 train_acc: 0.6400 | val_loss: 1.4880 val_acc: 0.4024\n",
            "Epoch 21: train_loss: 0.8533 train_acc: 0.6476 | val_loss: 1.4923 val_acc: 0.4205\n",
            "Epoch 22: train_loss: 0.8268 train_acc: 0.6670 | val_loss: 1.4911 val_acc: 0.4369\n",
            "Epoch 23: train_loss: 0.7964 train_acc: 0.6804 | val_loss: 1.5336 val_acc: 0.4251\n",
            "Epoch 24: train_loss: 0.7623 train_acc: 0.6959 | val_loss: 1.6069 val_acc: 0.4196\n",
            "Lowest val_loss: 1.3050, at epoch 6\n",
            "GRU 40 1 [30]\n",
            "Epoch 0: train_loss: 1.5800 train_acc: 0.2502 | val_loss: 1.5836 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5680 train_acc: 0.2658 | val_loss: 1.5771 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5674 train_acc: 0.2683 | val_loss: 1.5717 val_acc: 0.2643\n",
            "Epoch 3: train_loss: 1.5667 train_acc: 0.2721 | val_loss: 1.5679 val_acc: 0.2561\n",
            "Epoch 4: train_loss: 1.5649 train_acc: 0.2722 | val_loss: 1.5568 val_acc: 0.2707\n",
            "Epoch 5: train_loss: 1.4996 train_acc: 0.3272 | val_loss: 1.3603 val_acc: 0.3951\n",
            "Epoch 6: train_loss: 1.2963 train_acc: 0.4203 | val_loss: 1.3139 val_acc: 0.4205\n",
            "Epoch 7: train_loss: 1.2328 train_acc: 0.4482 | val_loss: 1.3006 val_acc: 0.4342\n",
            "Epoch 8: train_loss: 1.1960 train_acc: 0.4648 | val_loss: 1.3008 val_acc: 0.4360\n",
            "Epoch 9: train_loss: 1.1646 train_acc: 0.4864 | val_loss: 1.3158 val_acc: 0.4223\n",
            "Epoch 10: train_loss: 1.1426 train_acc: 0.5041 | val_loss: 1.3290 val_acc: 0.4278\n",
            "Epoch 11: train_loss: 1.1200 train_acc: 0.5022 | val_loss: 1.3276 val_acc: 0.4287\n",
            "Epoch 12: train_loss: 1.0957 train_acc: 0.5307 | val_loss: 1.3510 val_acc: 0.4196\n",
            "Epoch 13: train_loss: 1.0794 train_acc: 0.5331 | val_loss: 1.3605 val_acc: 0.4251\n",
            "Epoch 14: train_loss: 1.0497 train_acc: 0.5447 | val_loss: 1.3797 val_acc: 0.4160\n",
            "Epoch 15: train_loss: 1.0267 train_acc: 0.5579 | val_loss: 1.3517 val_acc: 0.4342\n",
            "Epoch 16: train_loss: 1.0043 train_acc: 0.5713 | val_loss: 1.3616 val_acc: 0.4323\n",
            "Epoch 17: train_loss: 0.9760 train_acc: 0.5826 | val_loss: 1.4209 val_acc: 0.4160\n",
            "Epoch 18: train_loss: 0.9496 train_acc: 0.6024 | val_loss: 1.3934 val_acc: 0.4205\n",
            "Epoch 19: train_loss: 0.9266 train_acc: 0.6104 | val_loss: 1.4152 val_acc: 0.4078\n",
            "Epoch 20: train_loss: 0.8890 train_acc: 0.6342 | val_loss: 1.4394 val_acc: 0.4078\n",
            "Epoch 21: train_loss: 0.8624 train_acc: 0.6493 | val_loss: 1.4646 val_acc: 0.4114\n",
            "Epoch 22: train_loss: 0.8406 train_acc: 0.6588 | val_loss: 1.5042 val_acc: 0.4078\n",
            "Epoch 23: train_loss: 0.7960 train_acc: 0.6811 | val_loss: 1.4764 val_acc: 0.3878\n",
            "Epoch 24: train_loss: 0.7691 train_acc: 0.6964 | val_loss: 1.5491 val_acc: 0.3951\n",
            "Lowest val_loss: 1.3006, at epoch 7\n",
            "GRU 40 1 [40]\n",
            "Epoch 0: train_loss: 1.5733 train_acc: 0.2692 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2708 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5671 train_acc: 0.2711 | val_loss: 1.5720 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5661 train_acc: 0.2750 | val_loss: 1.5504 val_acc: 0.2988\n",
            "Epoch 4: train_loss: 1.4518 train_acc: 0.3631 | val_loss: 1.3942 val_acc: 0.3942\n",
            "Epoch 5: train_loss: 1.3070 train_acc: 0.4154 | val_loss: 1.3150 val_acc: 0.4114\n",
            "Epoch 6: train_loss: 1.2445 train_acc: 0.4403 | val_loss: 1.3311 val_acc: 0.4178\n",
            "Epoch 7: train_loss: 1.2067 train_acc: 0.4616 | val_loss: 1.3289 val_acc: 0.4187\n",
            "Epoch 8: train_loss: 1.1791 train_acc: 0.4692 | val_loss: 1.3087 val_acc: 0.4233\n",
            "Epoch 9: train_loss: 1.1528 train_acc: 0.4850 | val_loss: 1.3152 val_acc: 0.4196\n",
            "Epoch 10: train_loss: 1.1311 train_acc: 0.4984 | val_loss: 1.3316 val_acc: 0.4024\n",
            "Epoch 11: train_loss: 1.1058 train_acc: 0.5089 | val_loss: 1.3231 val_acc: 0.4105\n",
            "Epoch 12: train_loss: 1.0770 train_acc: 0.5252 | val_loss: 1.4186 val_acc: 0.4096\n",
            "Epoch 13: train_loss: 1.0527 train_acc: 0.5332 | val_loss: 1.3665 val_acc: 0.4169\n",
            "Epoch 14: train_loss: 1.0262 train_acc: 0.5500 | val_loss: 1.4054 val_acc: 0.4187\n",
            "Epoch 15: train_loss: 1.0050 train_acc: 0.5634 | val_loss: 1.3761 val_acc: 0.4060\n",
            "Epoch 16: train_loss: 0.9770 train_acc: 0.5794 | val_loss: 1.3819 val_acc: 0.4151\n",
            "Epoch 17: train_loss: 0.9349 train_acc: 0.6010 | val_loss: 1.4278 val_acc: 0.4169\n",
            "Epoch 18: train_loss: 0.9141 train_acc: 0.6148 | val_loss: 1.4390 val_acc: 0.4087\n",
            "Epoch 19: train_loss: 0.8794 train_acc: 0.6291 | val_loss: 1.4501 val_acc: 0.4160\n",
            "Epoch 20: train_loss: 0.8354 train_acc: 0.6566 | val_loss: 1.5173 val_acc: 0.4169\n",
            "Epoch 21: train_loss: 0.8001 train_acc: 0.6756 | val_loss: 1.5702 val_acc: 0.4124\n",
            "Epoch 22: train_loss: 0.7661 train_acc: 0.6960 | val_loss: 1.5326 val_acc: 0.4160\n",
            "Epoch 23: train_loss: 0.7404 train_acc: 0.7055 | val_loss: 1.6115 val_acc: 0.4160\n",
            "Epoch 24: train_loss: 0.6988 train_acc: 0.7333 | val_loss: 1.5993 val_acc: 0.4133\n",
            "Lowest val_loss: 1.3087, at epoch 8\n",
            "GRU 40 1 [50]\n",
            "Epoch 0: train_loss: 1.5766 train_acc: 0.2592 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2690 | val_loss: 1.5701 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5676 train_acc: 0.2699 | val_loss: 1.5659 val_acc: 0.2625\n",
            "Epoch 3: train_loss: 1.5523 train_acc: 0.2848 | val_loss: 1.4665 val_acc: 0.3597\n",
            "Epoch 4: train_loss: 1.3681 train_acc: 0.3979 | val_loss: 1.3231 val_acc: 0.4078\n",
            "Epoch 5: train_loss: 1.2606 train_acc: 0.4329 | val_loss: 1.3219 val_acc: 0.4105\n",
            "Epoch 6: train_loss: 1.2197 train_acc: 0.4511 | val_loss: 1.2918 val_acc: 0.4269\n",
            "Epoch 7: train_loss: 1.1875 train_acc: 0.4676 | val_loss: 1.3055 val_acc: 0.4223\n",
            "Epoch 8: train_loss: 1.1648 train_acc: 0.4809 | val_loss: 1.3197 val_acc: 0.4196\n",
            "Epoch 9: train_loss: 1.1390 train_acc: 0.4885 | val_loss: 1.3482 val_acc: 0.4169\n",
            "Epoch 10: train_loss: 1.1108 train_acc: 0.5085 | val_loss: 1.3460 val_acc: 0.4087\n",
            "Epoch 11: train_loss: 1.0876 train_acc: 0.5225 | val_loss: 1.3613 val_acc: 0.4233\n",
            "Epoch 12: train_loss: 1.0630 train_acc: 0.5346 | val_loss: 1.3567 val_acc: 0.4187\n",
            "Epoch 13: train_loss: 1.0462 train_acc: 0.5430 | val_loss: 1.3609 val_acc: 0.4196\n",
            "Epoch 14: train_loss: 1.0151 train_acc: 0.5618 | val_loss: 1.3719 val_acc: 0.4196\n",
            "Epoch 15: train_loss: 0.9820 train_acc: 0.5860 | val_loss: 1.4241 val_acc: 0.4187\n",
            "Epoch 16: train_loss: 0.9531 train_acc: 0.5938 | val_loss: 1.4568 val_acc: 0.4133\n",
            "Epoch 17: train_loss: 0.9177 train_acc: 0.6124 | val_loss: 1.4633 val_acc: 0.4051\n",
            "Epoch 18: train_loss: 0.8930 train_acc: 0.6216 | val_loss: 1.4941 val_acc: 0.4196\n",
            "Epoch 19: train_loss: 0.8648 train_acc: 0.6412 | val_loss: 1.5296 val_acc: 0.4096\n",
            "Epoch 20: train_loss: 0.8235 train_acc: 0.6622 | val_loss: 1.5789 val_acc: 0.4033\n",
            "Epoch 21: train_loss: 0.7970 train_acc: 0.6745 | val_loss: 1.5737 val_acc: 0.4105\n",
            "Epoch 22: train_loss: 0.7588 train_acc: 0.6982 | val_loss: 1.6156 val_acc: 0.4114\n",
            "Epoch 23: train_loss: 0.7310 train_acc: 0.7069 | val_loss: 1.6802 val_acc: 0.4078\n",
            "Epoch 24: train_loss: 0.6867 train_acc: 0.7349 | val_loss: 1.6719 val_acc: 0.4042\n",
            "Lowest val_loss: 1.2918, at epoch 6\n",
            "GRU 40 1 [60]\n",
            "Epoch 0: train_loss: 1.5749 train_acc: 0.2710 | val_loss: 1.5751 val_acc: 0.2516\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2704 | val_loss: 1.5766 val_acc: 0.2470\n",
            "Epoch 2: train_loss: 1.5676 train_acc: 0.2706 | val_loss: 1.5669 val_acc: 0.3015\n",
            "Epoch 3: train_loss: 1.5662 train_acc: 0.2743 | val_loss: 1.5359 val_acc: 0.2952\n",
            "Epoch 4: train_loss: 1.3800 train_acc: 0.3897 | val_loss: 1.3340 val_acc: 0.4033\n",
            "Epoch 5: train_loss: 1.2649 train_acc: 0.4357 | val_loss: 1.3108 val_acc: 0.4105\n",
            "Epoch 6: train_loss: 1.2230 train_acc: 0.4534 | val_loss: 1.3172 val_acc: 0.4142\n",
            "Epoch 7: train_loss: 1.1905 train_acc: 0.4688 | val_loss: 1.3203 val_acc: 0.4196\n",
            "Epoch 8: train_loss: 1.1687 train_acc: 0.4816 | val_loss: 1.2889 val_acc: 0.4233\n",
            "Epoch 9: train_loss: 1.1463 train_acc: 0.4927 | val_loss: 1.3277 val_acc: 0.4096\n",
            "Epoch 10: train_loss: 1.1256 train_acc: 0.5020 | val_loss: 1.3396 val_acc: 0.4169\n",
            "Epoch 11: train_loss: 1.0969 train_acc: 0.5186 | val_loss: 1.3367 val_acc: 0.4242\n",
            "Epoch 12: train_loss: 1.0768 train_acc: 0.5276 | val_loss: 1.3455 val_acc: 0.4078\n",
            "Epoch 13: train_loss: 1.0567 train_acc: 0.5351 | val_loss: 1.3079 val_acc: 0.4378\n",
            "Epoch 14: train_loss: 1.0240 train_acc: 0.5572 | val_loss: 1.3330 val_acc: 0.4251\n",
            "Epoch 15: train_loss: 0.9967 train_acc: 0.5692 | val_loss: 1.3512 val_acc: 0.4223\n",
            "Epoch 16: train_loss: 0.9670 train_acc: 0.5868 | val_loss: 1.3985 val_acc: 0.4169\n",
            "Epoch 17: train_loss: 0.9373 train_acc: 0.5945 | val_loss: 1.4106 val_acc: 0.4105\n",
            "Epoch 18: train_loss: 0.9003 train_acc: 0.6179 | val_loss: 1.4230 val_acc: 0.4233\n",
            "Epoch 19: train_loss: 0.8734 train_acc: 0.6338 | val_loss: 1.4537 val_acc: 0.4169\n",
            "Epoch 20: train_loss: 0.8372 train_acc: 0.6509 | val_loss: 1.4734 val_acc: 0.4214\n",
            "Epoch 21: train_loss: 0.8059 train_acc: 0.6719 | val_loss: 1.5054 val_acc: 0.4305\n",
            "Epoch 22: train_loss: 0.7683 train_acc: 0.6883 | val_loss: 1.5839 val_acc: 0.4060\n",
            "Epoch 23: train_loss: 0.7287 train_acc: 0.7102 | val_loss: 1.5727 val_acc: 0.4015\n",
            "Epoch 24: train_loss: 0.6998 train_acc: 0.7226 | val_loss: 1.7264 val_acc: 0.4078\n",
            "Lowest val_loss: 1.2889, at epoch 8\n",
            "GRU 40 1 [70]\n",
            "Epoch 0: train_loss: 1.5761 train_acc: 0.2612 | val_loss: 1.5706 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2694 | val_loss: 1.5685 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5680 train_acc: 0.2677 | val_loss: 1.5645 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5664 train_acc: 0.2725 | val_loss: 1.5573 val_acc: 0.3088\n",
            "Epoch 4: train_loss: 1.5054 train_acc: 0.3153 | val_loss: 1.3501 val_acc: 0.3824\n",
            "Epoch 5: train_loss: 1.2871 train_acc: 0.4222 | val_loss: 1.3102 val_acc: 0.4169\n",
            "Epoch 6: train_loss: 1.2293 train_acc: 0.4465 | val_loss: 1.3279 val_acc: 0.4114\n",
            "Epoch 7: train_loss: 1.1933 train_acc: 0.4664 | val_loss: 1.3007 val_acc: 0.4178\n",
            "Epoch 8: train_loss: 1.1680 train_acc: 0.4752 | val_loss: 1.3102 val_acc: 0.4214\n",
            "Epoch 9: train_loss: 1.1420 train_acc: 0.4937 | val_loss: 1.3136 val_acc: 0.4260\n",
            "Epoch 10: train_loss: 1.1208 train_acc: 0.5076 | val_loss: 1.3478 val_acc: 0.4033\n",
            "Epoch 11: train_loss: 1.0964 train_acc: 0.5171 | val_loss: 1.3363 val_acc: 0.4124\n",
            "Epoch 12: train_loss: 1.0741 train_acc: 0.5282 | val_loss: 1.3208 val_acc: 0.4178\n",
            "Epoch 13: train_loss: 1.0543 train_acc: 0.5321 | val_loss: 1.3460 val_acc: 0.4069\n",
            "Epoch 14: train_loss: 1.0202 train_acc: 0.5607 | val_loss: 1.3381 val_acc: 0.4187\n",
            "Epoch 15: train_loss: 0.9997 train_acc: 0.5676 | val_loss: 1.3923 val_acc: 0.4060\n",
            "Epoch 16: train_loss: 0.9643 train_acc: 0.5861 | val_loss: 1.3897 val_acc: 0.4105\n",
            "Epoch 17: train_loss: 0.9312 train_acc: 0.6062 | val_loss: 1.3896 val_acc: 0.4069\n",
            "Epoch 18: train_loss: 0.8960 train_acc: 0.6257 | val_loss: 1.4477 val_acc: 0.3987\n",
            "Epoch 19: train_loss: 0.8662 train_acc: 0.6420 | val_loss: 1.4804 val_acc: 0.4078\n",
            "Epoch 20: train_loss: 0.8352 train_acc: 0.6571 | val_loss: 1.4810 val_acc: 0.3933\n",
            "Epoch 21: train_loss: 0.7977 train_acc: 0.6816 | val_loss: 1.5491 val_acc: 0.3842\n",
            "Epoch 22: train_loss: 0.7602 train_acc: 0.6924 | val_loss: 1.5300 val_acc: 0.3933\n",
            "Epoch 23: train_loss: 0.7242 train_acc: 0.7164 | val_loss: 1.6116 val_acc: 0.3878\n",
            "Epoch 24: train_loss: 0.6946 train_acc: 0.7315 | val_loss: 1.6336 val_acc: 0.3996\n",
            "Lowest val_loss: 1.3007, at epoch 7\n",
            "GRU 40 2 [30]\n",
            "Epoch 0: train_loss: 1.5720 train_acc: 0.2715 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2644 | val_loss: 1.5809 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5548 train_acc: 0.2846 | val_loss: 1.4653 val_acc: 0.3560\n",
            "Epoch 3: train_loss: 1.3622 train_acc: 0.4009 | val_loss: 1.3630 val_acc: 0.3933\n",
            "Epoch 4: train_loss: 1.2632 train_acc: 0.4362 | val_loss: 1.3301 val_acc: 0.4151\n",
            "Epoch 5: train_loss: 1.2182 train_acc: 0.4602 | val_loss: 1.3346 val_acc: 0.4124\n",
            "Epoch 6: train_loss: 1.1938 train_acc: 0.4683 | val_loss: 1.3599 val_acc: 0.4205\n",
            "Epoch 7: train_loss: 1.1758 train_acc: 0.4751 | val_loss: 1.3337 val_acc: 0.4242\n",
            "Epoch 8: train_loss: 1.1484 train_acc: 0.4924 | val_loss: 1.3150 val_acc: 0.4096\n",
            "Epoch 9: train_loss: 1.1307 train_acc: 0.5030 | val_loss: 1.3243 val_acc: 0.4278\n",
            "Epoch 10: train_loss: 1.1075 train_acc: 0.5158 | val_loss: 1.3329 val_acc: 0.4205\n",
            "Epoch 11: train_loss: 1.0904 train_acc: 0.5243 | val_loss: 1.3204 val_acc: 0.4233\n",
            "Epoch 12: train_loss: 1.0619 train_acc: 0.5473 | val_loss: 1.3465 val_acc: 0.4205\n",
            "Epoch 13: train_loss: 1.0351 train_acc: 0.5548 | val_loss: 1.3553 val_acc: 0.4187\n",
            "Epoch 14: train_loss: 1.0076 train_acc: 0.5693 | val_loss: 1.3698 val_acc: 0.4178\n",
            "Epoch 15: train_loss: 0.9891 train_acc: 0.5808 | val_loss: 1.3922 val_acc: 0.4169\n",
            "Epoch 16: train_loss: 0.9555 train_acc: 0.6021 | val_loss: 1.3894 val_acc: 0.3951\n",
            "Epoch 17: train_loss: 0.9232 train_acc: 0.6209 | val_loss: 1.3747 val_acc: 0.4178\n",
            "Epoch 18: train_loss: 0.9010 train_acc: 0.6332 | val_loss: 1.3927 val_acc: 0.4223\n",
            "Epoch 19: train_loss: 0.8612 train_acc: 0.6505 | val_loss: 1.4402 val_acc: 0.4087\n",
            "Epoch 20: train_loss: 0.8231 train_acc: 0.6784 | val_loss: 1.4652 val_acc: 0.4124\n",
            "Epoch 21: train_loss: 0.7973 train_acc: 0.6910 | val_loss: 1.4994 val_acc: 0.4105\n",
            "Epoch 22: train_loss: 0.7724 train_acc: 0.7051 | val_loss: 1.5259 val_acc: 0.4087\n",
            "Epoch 23: train_loss: 0.7318 train_acc: 0.7322 | val_loss: 1.5600 val_acc: 0.4124\n",
            "Epoch 24: train_loss: 0.6915 train_acc: 0.7509 | val_loss: 1.5916 val_acc: 0.3987\n",
            "Lowest val_loss: 1.3150, at epoch 8\n",
            "GRU 40 2 [40]\n",
            "Epoch 0: train_loss: 1.5724 train_acc: 0.2644 | val_loss: 1.5736 val_acc: 0.2543\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2712 | val_loss: 1.5719 val_acc: 0.2661\n",
            "Epoch 2: train_loss: 1.5476 train_acc: 0.2885 | val_loss: 1.4577 val_acc: 0.3497\n",
            "Epoch 3: train_loss: 1.3532 train_acc: 0.3948 | val_loss: 1.3446 val_acc: 0.3887\n",
            "Epoch 4: train_loss: 1.2574 train_acc: 0.4339 | val_loss: 1.3152 val_acc: 0.4069\n",
            "Epoch 5: train_loss: 1.2196 train_acc: 0.4520 | val_loss: 1.3027 val_acc: 0.4214\n",
            "Epoch 6: train_loss: 1.1952 train_acc: 0.4630 | val_loss: 1.3625 val_acc: 0.4005\n",
            "Epoch 7: train_loss: 1.1717 train_acc: 0.4823 | val_loss: 1.3022 val_acc: 0.4214\n",
            "Epoch 8: train_loss: 1.1485 train_acc: 0.4899 | val_loss: 1.3545 val_acc: 0.4096\n",
            "Epoch 9: train_loss: 1.1289 train_acc: 0.4993 | val_loss: 1.3137 val_acc: 0.4178\n",
            "Epoch 10: train_loss: 1.1081 train_acc: 0.5124 | val_loss: 1.3294 val_acc: 0.4251\n",
            "Epoch 11: train_loss: 1.0855 train_acc: 0.5218 | val_loss: 1.3157 val_acc: 0.4342\n",
            "Epoch 12: train_loss: 1.0667 train_acc: 0.5327 | val_loss: 1.3157 val_acc: 0.4214\n",
            "Epoch 13: train_loss: 1.0302 train_acc: 0.5571 | val_loss: 1.3725 val_acc: 0.4114\n",
            "Epoch 15: train_loss: 0.9862 train_acc: 0.5795 | val_loss: 1.3706 val_acc: 0.4124\n",
            "Epoch 16: train_loss: 0.9567 train_acc: 0.5973 | val_loss: 1.3334 val_acc: 0.4305\n",
            "Epoch 17: train_loss: 0.9184 train_acc: 0.6121 | val_loss: 1.3609 val_acc: 0.4296\n",
            "Epoch 18: train_loss: 0.8874 train_acc: 0.6294 | val_loss: 1.4089 val_acc: 0.4133\n",
            "Epoch 19: train_loss: 0.8592 train_acc: 0.6500 | val_loss: 1.4083 val_acc: 0.4214\n",
            "Epoch 20: train_loss: 0.8211 train_acc: 0.6725 | val_loss: 1.4363 val_acc: 0.4296\n",
            "Epoch 21: train_loss: 0.7932 train_acc: 0.6879 | val_loss: 1.4436 val_acc: 0.4214\n",
            "Epoch 22: train_loss: 0.7601 train_acc: 0.6985 | val_loss: 1.4898 val_acc: 0.4178\n",
            "Epoch 23: train_loss: 0.7287 train_acc: 0.7198 | val_loss: 1.5065 val_acc: 0.4205\n",
            "Epoch 24: train_loss: 0.6886 train_acc: 0.7426 | val_loss: 1.5416 val_acc: 0.4069\n",
            "Lowest val_loss: 1.3022, at epoch 7\n",
            "GRU 40 2 [50]\n",
            "Epoch 0: train_loss: 1.5741 train_acc: 0.2602 | val_loss: 1.5743 val_acc: 0.2897\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2664 | val_loss: 1.5719 val_acc: 0.2543\n",
            "Epoch 2: train_loss: 1.5522 train_acc: 0.2845 | val_loss: 1.4615 val_acc: 0.3624\n",
            "Epoch 3: train_loss: 1.3787 train_acc: 0.3902 | val_loss: 1.3562 val_acc: 0.3933\n",
            "Epoch 4: train_loss: 1.2666 train_acc: 0.4324 | val_loss: 1.3408 val_acc: 0.4005\n",
            "Epoch 5: train_loss: 1.2218 train_acc: 0.4470 | val_loss: 1.3275 val_acc: 0.3978\n",
            "Epoch 6: train_loss: 1.1948 train_acc: 0.4671 | val_loss: 1.3301 val_acc: 0.4242\n",
            "Epoch 7: train_loss: 1.1721 train_acc: 0.4750 | val_loss: 1.3498 val_acc: 0.4133\n",
            "Epoch 8: train_loss: 1.1482 train_acc: 0.4920 | val_loss: 1.3448 val_acc: 0.4142\n",
            "Epoch 9: train_loss: 1.1297 train_acc: 0.4979 | val_loss: 1.3516 val_acc: 0.4260\n",
            "Epoch 10: train_loss: 1.1065 train_acc: 0.5122 | val_loss: 1.3376 val_acc: 0.4233\n",
            "Epoch 11: train_loss: 1.0821 train_acc: 0.5262 | val_loss: 1.3454 val_acc: 0.4287\n",
            "Epoch 12: train_loss: 1.0614 train_acc: 0.5334 | val_loss: 1.3613 val_acc: 0.4105\n",
            "Epoch 13: train_loss: 1.0300 train_acc: 0.5499 | val_loss: 1.3513 val_acc: 0.4196\n",
            "Epoch 14: train_loss: 1.0034 train_acc: 0.5660 | val_loss: 1.3591 val_acc: 0.4269\n",
            "Epoch 15: train_loss: 0.9771 train_acc: 0.5854 | val_loss: 1.3761 val_acc: 0.4323\n",
            "Epoch 16: train_loss: 0.9480 train_acc: 0.5982 | val_loss: 1.3851 val_acc: 0.4323\n",
            "Epoch 17: train_loss: 0.9147 train_acc: 0.6154 | val_loss: 1.4525 val_acc: 0.4323\n",
            "Epoch 18: train_loss: 0.8885 train_acc: 0.6246 | val_loss: 1.4613 val_acc: 0.4278\n",
            "Epoch 19: train_loss: 0.8598 train_acc: 0.6375 | val_loss: 1.4569 val_acc: 0.4287\n",
            "Epoch 20: train_loss: 0.8231 train_acc: 0.6579 | val_loss: 1.4911 val_acc: 0.4342\n",
            "Epoch 21: train_loss: 0.7879 train_acc: 0.6834 | val_loss: 1.5238 val_acc: 0.4414\n",
            "Epoch 22: train_loss: 0.7464 train_acc: 0.7092 | val_loss: 1.5650 val_acc: 0.4187\n",
            "Epoch 23: train_loss: 0.7135 train_acc: 0.7198 | val_loss: 1.6033 val_acc: 0.4260\n",
            "Epoch 24: train_loss: 0.6903 train_acc: 0.7274 | val_loss: 1.6507 val_acc: 0.4260\n",
            "Lowest val_loss: 1.3275, at epoch 5\n",
            "GRU 40 2 [60]\n",
            "Epoch 0: train_loss: 1.5737 train_acc: 0.2632 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2706 | val_loss: 1.5690 val_acc: 0.2934\n",
            "Epoch 2: train_loss: 1.5675 train_acc: 0.2640 | val_loss: 1.5379 val_acc: 0.2979\n",
            "Epoch 3: train_loss: 1.4146 train_acc: 0.3654 | val_loss: 1.3840 val_acc: 0.3778\n",
            "Epoch 4: train_loss: 1.2846 train_acc: 0.4233 | val_loss: 1.3267 val_acc: 0.4124\n",
            "Epoch 5: train_loss: 1.2351 train_acc: 0.4432 | val_loss: 1.3365 val_acc: 0.4187\n",
            "Epoch 6: train_loss: 1.2089 train_acc: 0.4595 | val_loss: 1.3298 val_acc: 0.4251\n",
            "Epoch 7: train_loss: 1.1850 train_acc: 0.4731 | val_loss: 1.3283 val_acc: 0.4169\n",
            "Epoch 8: train_loss: 1.1654 train_acc: 0.4798 | val_loss: 1.3173 val_acc: 0.4160\n",
            "Epoch 9: train_loss: 1.1425 train_acc: 0.4910 | val_loss: 1.3483 val_acc: 0.4314\n",
            "Epoch 10: train_loss: 1.1174 train_acc: 0.5036 | val_loss: 1.3143 val_acc: 0.4233\n",
            "Epoch 11: train_loss: 1.0928 train_acc: 0.5094 | val_loss: 1.3696 val_acc: 0.4223\n",
            "Epoch 12: train_loss: 1.0769 train_acc: 0.5239 | val_loss: 1.3762 val_acc: 0.4133\n",
            "Epoch 13: train_loss: 1.0495 train_acc: 0.5400 | val_loss: 1.3536 val_acc: 0.4223\n",
            "Epoch 14: train_loss: 1.0213 train_acc: 0.5502 | val_loss: 1.3569 val_acc: 0.4160\n",
            "Epoch 15: train_loss: 0.9953 train_acc: 0.5727 | val_loss: 1.3403 val_acc: 0.4387\n",
            "Epoch 16: train_loss: 0.9632 train_acc: 0.5887 | val_loss: 1.3703 val_acc: 0.4278\n",
            "Epoch 17: train_loss: 0.9343 train_acc: 0.6032 | val_loss: 1.4020 val_acc: 0.4332\n",
            "Epoch 18: train_loss: 0.9022 train_acc: 0.6236 | val_loss: 1.5624 val_acc: 0.4133\n",
            "Epoch 19: train_loss: 0.8841 train_acc: 0.6328 | val_loss: 1.4455 val_acc: 0.4223\n",
            "Epoch 20: train_loss: 0.8411 train_acc: 0.6539 | val_loss: 1.4844 val_acc: 0.4278\n",
            "Epoch 21: train_loss: 0.8080 train_acc: 0.6718 | val_loss: 1.5406 val_acc: 0.4214\n",
            "Epoch 22: train_loss: 0.7847 train_acc: 0.6814 | val_loss: 1.5260 val_acc: 0.4214\n",
            "Epoch 23: train_loss: 0.7374 train_acc: 0.7130 | val_loss: 1.5761 val_acc: 0.4196\n",
            "Epoch 24: train_loss: 0.7073 train_acc: 0.7286 | val_loss: 1.5866 val_acc: 0.4278\n",
            "Lowest val_loss: 1.3143, at epoch 10\n",
            "GRU 40 2 [70]\n",
            "Epoch 0: train_loss: 1.5745 train_acc: 0.2640 | val_loss: 1.5742 val_acc: 0.2625\n",
            "Epoch 1: train_loss: 1.5696 train_acc: 0.2699 | val_loss: 1.5726 val_acc: 0.2916\n",
            "Epoch 2: train_loss: 1.5685 train_acc: 0.2658 | val_loss: 1.5701 val_acc: 0.2707\n",
            "Epoch 3: train_loss: 1.5674 train_acc: 0.2714 | val_loss: 1.5606 val_acc: 0.2752\n",
            "Epoch 4: train_loss: 1.4229 train_acc: 0.3629 | val_loss: 1.3737 val_acc: 0.3878\n",
            "Epoch 5: train_loss: 1.2507 train_acc: 0.4353 | val_loss: 1.3274 val_acc: 0.4069\n",
            "Epoch 6: train_loss: 1.2081 train_acc: 0.4599 | val_loss: 1.3322 val_acc: 0.4096\n",
            "Epoch 7: train_loss: 1.1786 train_acc: 0.4789 | val_loss: 1.3460 val_acc: 0.4069\n",
            "Epoch 8: train_loss: 1.1595 train_acc: 0.4885 | val_loss: 1.3401 val_acc: 0.4187\n",
            "Epoch 9: train_loss: 1.1277 train_acc: 0.5077 | val_loss: 1.3514 val_acc: 0.4314\n",
            "Epoch 10: train_loss: 1.1029 train_acc: 0.5152 | val_loss: 1.3512 val_acc: 0.4187\n",
            "Epoch 11: train_loss: 1.0805 train_acc: 0.5242 | val_loss: 1.3499 val_acc: 0.4278\n",
            "Epoch 12: train_loss: 1.0509 train_acc: 0.5463 | val_loss: 1.3413 val_acc: 0.4205\n",
            "Epoch 13: train_loss: 1.0310 train_acc: 0.5506 | val_loss: 1.3890 val_acc: 0.4223\n",
            "Epoch 14: train_loss: 1.0131 train_acc: 0.5684 | val_loss: 1.3920 val_acc: 0.4342\n",
            "Epoch 15: train_loss: 0.9742 train_acc: 0.5886 | val_loss: 1.3864 val_acc: 0.4223\n",
            "Epoch 16: train_loss: 0.9468 train_acc: 0.6037 | val_loss: 1.4067 val_acc: 0.4278\n",
            "Epoch 17: train_loss: 0.9161 train_acc: 0.6152 | val_loss: 1.4522 val_acc: 0.4178\n",
            "Epoch 18: train_loss: 0.8855 train_acc: 0.6313 | val_loss: 1.4432 val_acc: 0.4160\n",
            "Epoch 19: train_loss: 0.8537 train_acc: 0.6428 | val_loss: 1.5080 val_acc: 0.4114\n",
            "Epoch 20: train_loss: 0.8181 train_acc: 0.6641 | val_loss: 1.4952 val_acc: 0.4124\n",
            "Epoch 21: train_loss: 0.7819 train_acc: 0.6820 | val_loss: 1.5082 val_acc: 0.4151\n",
            "Epoch 22: train_loss: 0.7499 train_acc: 0.6980 | val_loss: 1.6416 val_acc: 0.3987\n",
            "Epoch 23: train_loss: 0.7082 train_acc: 0.7228 | val_loss: 1.6314 val_acc: 0.4015\n",
            "Epoch 24: train_loss: 0.6800 train_acc: 0.7289 | val_loss: 1.6786 val_acc: 0.4096\n",
            "Lowest val_loss: 1.3274, at epoch 5\n",
            "GRU 50 1 [30]\n",
            "Epoch 0: train_loss: 1.5737 train_acc: 0.2704 | val_loss: 1.5848 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5682 train_acc: 0.2662 | val_loss: 1.5773 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5676 train_acc: 0.2693 | val_loss: 1.5695 val_acc: 0.2552\n",
            "Epoch 3: train_loss: 1.5657 train_acc: 0.2738 | val_loss: 1.5587 val_acc: 0.2979\n",
            "Epoch 4: train_loss: 1.4241 train_acc: 0.3736 | val_loss: 1.3394 val_acc: 0.4214\n",
            "Epoch 5: train_loss: 1.2855 train_acc: 0.4285 | val_loss: 1.3125 val_acc: 0.3996\n",
            "Epoch 6: train_loss: 1.2281 train_acc: 0.4494 | val_loss: 1.3038 val_acc: 0.4151\n",
            "Epoch 7: train_loss: 1.1968 train_acc: 0.4669 | val_loss: 1.3156 val_acc: 0.4160\n",
            "Epoch 8: train_loss: 1.1722 train_acc: 0.4783 | val_loss: 1.2966 val_acc: 0.4133\n",
            "Epoch 9: train_loss: 1.1425 train_acc: 0.5033 | val_loss: 1.3021 val_acc: 0.4196\n",
            "Epoch 10: train_loss: 1.1206 train_acc: 0.5066 | val_loss: 1.3515 val_acc: 0.4105\n",
            "Epoch 11: train_loss: 1.0938 train_acc: 0.5207 | val_loss: 1.3490 val_acc: 0.4133\n",
            "Epoch 12: train_loss: 1.0646 train_acc: 0.5359 | val_loss: 1.3608 val_acc: 0.4233\n",
            "Epoch 13: train_loss: 1.0352 train_acc: 0.5556 | val_loss: 1.3849 val_acc: 0.4233\n",
            "Epoch 14: train_loss: 1.0027 train_acc: 0.5715 | val_loss: 1.3739 val_acc: 0.4233\n",
            "Epoch 15: train_loss: 0.9650 train_acc: 0.5918 | val_loss: 1.4553 val_acc: 0.4042\n",
            "Epoch 16: train_loss: 0.9327 train_acc: 0.6073 | val_loss: 1.4179 val_acc: 0.4033\n",
            "Epoch 17: train_loss: 0.8814 train_acc: 0.6317 | val_loss: 1.5043 val_acc: 0.4124\n",
            "Epoch 18: train_loss: 0.8453 train_acc: 0.6575 | val_loss: 1.4950 val_acc: 0.4105\n",
            "Epoch 19: train_loss: 0.8007 train_acc: 0.6752 | val_loss: 1.5258 val_acc: 0.4033\n",
            "Epoch 20: train_loss: 0.7613 train_acc: 0.6955 | val_loss: 1.5780 val_acc: 0.4078\n",
            "Epoch 21: train_loss: 0.7108 train_acc: 0.7225 | val_loss: 1.5902 val_acc: 0.4033\n",
            "Epoch 22: train_loss: 0.6821 train_acc: 0.7389 | val_loss: 1.7019 val_acc: 0.3878\n",
            "Epoch 23: train_loss: 0.6199 train_acc: 0.7652 | val_loss: 1.7044 val_acc: 0.3887\n",
            "Epoch 24: train_loss: 0.5922 train_acc: 0.7804 | val_loss: 1.7070 val_acc: 0.3969\n",
            "Lowest val_loss: 1.2966, at epoch 8\n",
            "GRU 50 1 [40]\n",
            "Epoch 0: train_loss: 1.5754 train_acc: 0.2540 | val_loss: 1.5762 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2688 | val_loss: 1.5804 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5682 train_acc: 0.2685 | val_loss: 1.5770 val_acc: 0.2507\n",
            "Epoch 3: train_loss: 1.5667 train_acc: 0.2702 | val_loss: 1.5795 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5638 train_acc: 0.2727 | val_loss: 1.5711 val_acc: 0.2825\n",
            "Epoch 5: train_loss: 1.4628 train_acc: 0.3504 | val_loss: 1.3667 val_acc: 0.3942\n",
            "Epoch 6: train_loss: 1.2728 train_acc: 0.4308 | val_loss: 1.3488 val_acc: 0.3833\n",
            "Epoch 7: train_loss: 1.2141 train_acc: 0.4567 | val_loss: 1.3029 val_acc: 0.4124\n",
            "Epoch 8: train_loss: 1.1836 train_acc: 0.4773 | val_loss: 1.3138 val_acc: 0.4114\n",
            "Epoch 9: train_loss: 1.1480 train_acc: 0.4898 | val_loss: 1.3260 val_acc: 0.4251\n",
            "Epoch 10: train_loss: 1.1247 train_acc: 0.5028 | val_loss: 1.3322 val_acc: 0.4160\n",
            "Epoch 11: train_loss: 1.0995 train_acc: 0.5184 | val_loss: 1.3521 val_acc: 0.4060\n",
            "Epoch 12: train_loss: 1.0719 train_acc: 0.5293 | val_loss: 1.3678 val_acc: 0.3987\n",
            "Epoch 13: train_loss: 1.0362 train_acc: 0.5488 | val_loss: 1.3834 val_acc: 0.4051\n",
            "Epoch 14: train_loss: 1.0014 train_acc: 0.5705 | val_loss: 1.4728 val_acc: 0.3906\n",
            "Epoch 15: train_loss: 0.9740 train_acc: 0.5790 | val_loss: 1.4162 val_acc: 0.3978\n",
            "Epoch 16: train_loss: 0.9378 train_acc: 0.6030 | val_loss: 1.4289 val_acc: 0.4024\n",
            "Epoch 17: train_loss: 0.9021 train_acc: 0.6195 | val_loss: 1.4756 val_acc: 0.3960\n",
            "Epoch 18: train_loss: 0.8654 train_acc: 0.6438 | val_loss: 1.4907 val_acc: 0.4005\n",
            "Epoch 19: train_loss: 0.8357 train_acc: 0.6593 | val_loss: 1.4772 val_acc: 0.4051\n",
            "Epoch 20: train_loss: 0.7980 train_acc: 0.6821 | val_loss: 1.5154 val_acc: 0.3996\n",
            "Epoch 21: train_loss: 0.7573 train_acc: 0.7014 | val_loss: 1.5687 val_acc: 0.3924\n",
            "Epoch 22: train_loss: 0.7087 train_acc: 0.7269 | val_loss: 1.6055 val_acc: 0.3942\n",
            "Epoch 23: train_loss: 0.6750 train_acc: 0.7443 | val_loss: 1.6114 val_acc: 0.4060\n",
            "Epoch 24: train_loss: 0.6395 train_acc: 0.7651 | val_loss: 1.6608 val_acc: 0.3878\n",
            "Lowest val_loss: 1.3029, at epoch 7\n",
            "GRU 50 1 [50]\n",
            "Epoch 0: train_loss: 1.5721 train_acc: 0.2664 | val_loss: 1.5719 val_acc: 0.2598\n",
            "Epoch 1: train_loss: 1.5682 train_acc: 0.2699 | val_loss: 1.5685 val_acc: 0.2661\n",
            "Epoch 2: train_loss: 1.5678 train_acc: 0.2665 | val_loss: 1.5641 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5669 train_acc: 0.2666 | val_loss: 1.5576 val_acc: 0.2561\n",
            "Epoch 4: train_loss: 1.5359 train_acc: 0.3031 | val_loss: 1.4530 val_acc: 0.3497\n",
            "Epoch 5: train_loss: 1.3838 train_acc: 0.3919 | val_loss: 1.3590 val_acc: 0.3851\n",
            "Epoch 6: train_loss: 1.2878 train_acc: 0.4202 | val_loss: 1.3279 val_acc: 0.4015\n",
            "Epoch 7: train_loss: 1.2267 train_acc: 0.4505 | val_loss: 1.3248 val_acc: 0.4015\n",
            "Epoch 8: train_loss: 1.1942 train_acc: 0.4670 | val_loss: 1.3210 val_acc: 0.4151\n",
            "Epoch 9: train_loss: 1.1649 train_acc: 0.4815 | val_loss: 1.3208 val_acc: 0.4096\n",
            "Epoch 10: train_loss: 1.1376 train_acc: 0.4936 | val_loss: 1.3259 val_acc: 0.4178\n",
            "Epoch 11: train_loss: 1.1121 train_acc: 0.5088 | val_loss: 1.3295 val_acc: 0.4160\n",
            "Epoch 12: train_loss: 1.0794 train_acc: 0.5305 | val_loss: 1.3285 val_acc: 0.4087\n",
            "Epoch 13: train_loss: 1.0500 train_acc: 0.5419 | val_loss: 1.3501 val_acc: 0.4242\n",
            "Epoch 14: train_loss: 1.0147 train_acc: 0.5667 | val_loss: 1.3577 val_acc: 0.4060\n",
            "Epoch 15: train_loss: 0.9803 train_acc: 0.5808 | val_loss: 1.3804 val_acc: 0.4260\n",
            "Epoch 16: train_loss: 0.9542 train_acc: 0.5989 | val_loss: 1.3965 val_acc: 0.4151\n",
            "Epoch 17: train_loss: 0.9153 train_acc: 0.6160 | val_loss: 1.4364 val_acc: 0.4051\n",
            "Epoch 18: train_loss: 0.8802 train_acc: 0.6381 | val_loss: 1.4458 val_acc: 0.4351\n",
            "Epoch 19: train_loss: 0.8382 train_acc: 0.6625 | val_loss: 1.4657 val_acc: 0.4187\n",
            "Epoch 20: train_loss: 0.7989 train_acc: 0.6790 | val_loss: 1.5101 val_acc: 0.4151\n",
            "Epoch 21: train_loss: 0.7688 train_acc: 0.6989 | val_loss: 1.5673 val_acc: 0.4214\n",
            "Epoch 22: train_loss: 0.7216 train_acc: 0.7219 | val_loss: 1.5811 val_acc: 0.4105\n",
            "Epoch 23: train_loss: 0.6974 train_acc: 0.7305 | val_loss: 1.6198 val_acc: 0.4033\n",
            "Epoch 24: train_loss: 0.6580 train_acc: 0.7520 | val_loss: 1.6379 val_acc: 0.4169\n",
            "Lowest val_loss: 1.3208, at epoch 9\n",
            "GRU 50 1 [60]\n",
            "Epoch 0: train_loss: 1.5721 train_acc: 0.2614 | val_loss: 1.5718 val_acc: 0.2970\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2638 | val_loss: 1.5778 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5668 train_acc: 0.2754 | val_loss: 1.5646 val_acc: 0.2807\n",
            "Epoch 3: train_loss: 1.5658 train_acc: 0.2720 | val_loss: 1.5657 val_acc: 0.2761\n",
            "Epoch 4: train_loss: 1.4272 train_acc: 0.3725 | val_loss: 1.3802 val_acc: 0.3833\n",
            "Epoch 5: train_loss: 1.2744 train_acc: 0.4247 | val_loss: 1.3148 val_acc: 0.4078\n",
            "Epoch 6: train_loss: 1.2422 train_acc: 0.4424 | val_loss: 1.3015 val_acc: 0.4223\n",
            "Epoch 7: train_loss: 1.1949 train_acc: 0.4679 | val_loss: 1.2996 val_acc: 0.4187\n",
            "Epoch 8: train_loss: 1.1689 train_acc: 0.4781 | val_loss: 1.3126 val_acc: 0.4114\n",
            "Epoch 9: train_loss: 1.1417 train_acc: 0.4936 | val_loss: 1.3193 val_acc: 0.4314\n",
            "Epoch 10: train_loss: 1.1278 train_acc: 0.5023 | val_loss: 1.3131 val_acc: 0.4205\n",
            "Epoch 11: train_loss: 1.0909 train_acc: 0.5201 | val_loss: 1.3224 val_acc: 0.4187\n",
            "Epoch 12: train_loss: 1.0670 train_acc: 0.5301 | val_loss: 1.3490 val_acc: 0.4160\n",
            "Epoch 13: train_loss: 1.0397 train_acc: 0.5492 | val_loss: 1.3468 val_acc: 0.4196\n",
            "Epoch 14: train_loss: 1.0014 train_acc: 0.5620 | val_loss: 1.3687 val_acc: 0.4169\n",
            "Epoch 15: train_loss: 0.9716 train_acc: 0.5746 | val_loss: 1.4460 val_acc: 0.4142\n",
            "Epoch 16: train_loss: 0.9332 train_acc: 0.5981 | val_loss: 1.4277 val_acc: 0.4042\n",
            "Epoch 17: train_loss: 0.9016 train_acc: 0.6236 | val_loss: 1.4183 val_acc: 0.4124\n",
            "Epoch 18: train_loss: 0.8678 train_acc: 0.6345 | val_loss: 1.5444 val_acc: 0.4151\n",
            "Epoch 19: train_loss: 0.8192 train_acc: 0.6654 | val_loss: 1.5335 val_acc: 0.4060\n",
            "Epoch 20: train_loss: 0.7698 train_acc: 0.6914 | val_loss: 1.5586 val_acc: 0.4033\n",
            "Epoch 21: train_loss: 0.7398 train_acc: 0.7038 | val_loss: 1.6218 val_acc: 0.4142\n",
            "Epoch 22: train_loss: 0.6912 train_acc: 0.7348 | val_loss: 1.6608 val_acc: 0.4096\n",
            "Epoch 23: train_loss: 0.6454 train_acc: 0.7553 | val_loss: 1.7248 val_acc: 0.4024\n",
            "Epoch 24: train_loss: 0.6084 train_acc: 0.7736 | val_loss: 1.7681 val_acc: 0.4087\n",
            "Lowest val_loss: 1.2996, at epoch 7\n",
            "GRU 50 1 [70]\n",
            "Epoch 0: train_loss: 1.5717 train_acc: 0.2679 | val_loss: 1.5794 val_acc: 0.2598\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2662 | val_loss: 1.5724 val_acc: 0.2371\n",
            "Epoch 2: train_loss: 1.5677 train_acc: 0.2697 | val_loss: 1.5746 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5662 train_acc: 0.2711 | val_loss: 1.5656 val_acc: 0.2552\n",
            "Epoch 4: train_loss: 1.4894 train_acc: 0.3248 | val_loss: 1.3941 val_acc: 0.3606\n",
            "Epoch 5: train_loss: 1.2890 train_acc: 0.4261 | val_loss: 1.3165 val_acc: 0.4151\n",
            "Epoch 6: train_loss: 1.2304 train_acc: 0.4534 | val_loss: 1.3345 val_acc: 0.4187\n",
            "Epoch 7: train_loss: 1.1931 train_acc: 0.4684 | val_loss: 1.3239 val_acc: 0.3960\n",
            "Epoch 8: train_loss: 1.1618 train_acc: 0.4875 | val_loss: 1.3237 val_acc: 0.4133\n",
            "Epoch 9: train_loss: 1.1378 train_acc: 0.4964 | val_loss: 1.3428 val_acc: 0.4151\n",
            "Epoch 10: train_loss: 1.1109 train_acc: 0.5087 | val_loss: 1.3348 val_acc: 0.4124\n",
            "Epoch 11: train_loss: 1.0901 train_acc: 0.5208 | val_loss: 1.3224 val_acc: 0.4223\n",
            "Epoch 12: train_loss: 1.0593 train_acc: 0.5345 | val_loss: 1.3903 val_acc: 0.4142\n",
            "Epoch 13: train_loss: 1.0307 train_acc: 0.5489 | val_loss: 1.3485 val_acc: 0.4169\n",
            "Epoch 14: train_loss: 0.9915 train_acc: 0.5758 | val_loss: 1.3555 val_acc: 0.4151\n",
            "Epoch 15: train_loss: 0.9547 train_acc: 0.5950 | val_loss: 1.3911 val_acc: 0.4151\n",
            "Epoch 16: train_loss: 0.9156 train_acc: 0.6125 | val_loss: 1.4203 val_acc: 0.4187\n",
            "Epoch 17: train_loss: 0.8765 train_acc: 0.6354 | val_loss: 1.4575 val_acc: 0.4223\n",
            "Epoch 18: train_loss: 0.8256 train_acc: 0.6594 | val_loss: 1.5161 val_acc: 0.4024\n",
            "Epoch 19: train_loss: 0.7855 train_acc: 0.6743 | val_loss: 1.5578 val_acc: 0.4114\n",
            "Epoch 20: train_loss: 0.7448 train_acc: 0.7021 | val_loss: 1.5576 val_acc: 0.3987\n",
            "Epoch 21: train_loss: 0.6966 train_acc: 0.7258 | val_loss: 1.6252 val_acc: 0.4005\n",
            "Epoch 22: train_loss: 0.6463 train_acc: 0.7515 | val_loss: 1.6325 val_acc: 0.3915\n",
            "Epoch 23: train_loss: 0.6024 train_acc: 0.7698 | val_loss: 1.7389 val_acc: 0.3778\n",
            "Epoch 24: train_loss: 0.5733 train_acc: 0.7818 | val_loss: 1.7718 val_acc: 0.3851\n",
            "Lowest val_loss: 1.3165, at epoch 5\n",
            "GRU 50 2 [30]\n",
            "Epoch 0: train_loss: 1.5765 train_acc: 0.2687 | val_loss: 1.5729 val_acc: 0.2788\n",
            "Epoch 1: train_loss: 1.5648 train_acc: 0.2811 | val_loss: 1.5177 val_acc: 0.3460\n",
            "Epoch 2: train_loss: 1.3628 train_acc: 0.3986 | val_loss: 1.3766 val_acc: 0.3896\n",
            "Epoch 3: train_loss: 1.2584 train_acc: 0.4283 | val_loss: 1.3112 val_acc: 0.4214\n",
            "Epoch 4: train_loss: 1.2170 train_acc: 0.4567 | val_loss: 1.3066 val_acc: 0.4142\n",
            "Epoch 5: train_loss: 1.1871 train_acc: 0.4709 | val_loss: 1.3432 val_acc: 0.4024\n",
            "Epoch 6: train_loss: 1.1652 train_acc: 0.4830 | val_loss: 1.3220 val_acc: 0.4042\n",
            "Epoch 7: train_loss: 1.1421 train_acc: 0.4929 | val_loss: 1.2970 val_acc: 0.4223\n",
            "Epoch 8: train_loss: 1.1182 train_acc: 0.5061 | val_loss: 1.3355 val_acc: 0.4196\n",
            "Epoch 9: train_loss: 1.0976 train_acc: 0.5222 | val_loss: 1.3501 val_acc: 0.4060\n",
            "Epoch 10: train_loss: 1.0670 train_acc: 0.5314 | val_loss: 1.3554 val_acc: 0.4223\n",
            "Epoch 11: train_loss: 1.0468 train_acc: 0.5510 | val_loss: 1.3661 val_acc: 0.4114\n",
            "Epoch 12: train_loss: 1.0151 train_acc: 0.5682 | val_loss: 1.3481 val_acc: 0.4214\n",
            "Epoch 13: train_loss: 0.9840 train_acc: 0.5851 | val_loss: 1.3769 val_acc: 0.4214\n",
            "Epoch 14: train_loss: 0.9471 train_acc: 0.5984 | val_loss: 1.4433 val_acc: 0.4015\n",
            "Epoch 15: train_loss: 0.9118 train_acc: 0.6169 | val_loss: 1.4016 val_acc: 0.4124\n",
            "Epoch 16: train_loss: 0.8832 train_acc: 0.6357 | val_loss: 1.3878 val_acc: 0.4223\n",
            "Epoch 17: train_loss: 0.8427 train_acc: 0.6591 | val_loss: 1.4489 val_acc: 0.4160\n",
            "Epoch 18: train_loss: 0.8013 train_acc: 0.6791 | val_loss: 1.4419 val_acc: 0.4160\n",
            "Epoch 19: train_loss: 0.7691 train_acc: 0.6953 | val_loss: 1.4820 val_acc: 0.4087\n",
            "Epoch 20: train_loss: 0.7256 train_acc: 0.7214 | val_loss: 1.4927 val_acc: 0.4151\n",
            "Epoch 21: train_loss: 0.6912 train_acc: 0.7392 | val_loss: 1.5636 val_acc: 0.4051\n",
            "Epoch 22: train_loss: 0.6702 train_acc: 0.7478 | val_loss: 1.5873 val_acc: 0.4205\n",
            "Epoch 23: train_loss: 0.6102 train_acc: 0.7814 | val_loss: 1.6034 val_acc: 0.4251\n",
            "Epoch 24: train_loss: 0.5734 train_acc: 0.7937 | val_loss: 1.6843 val_acc: 0.4015\n",
            "Lowest val_loss: 1.2970, at epoch 7\n",
            "GRU 50 2 [40]\n",
            "Epoch 0: train_loss: 1.5715 train_acc: 0.2707 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5684 train_acc: 0.2659 | val_loss: 1.5716 val_acc: 0.2552\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2708 | val_loss: 1.5746 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.4376 train_acc: 0.3569 | val_loss: 1.3505 val_acc: 0.4033\n",
            "Epoch 4: train_loss: 1.2698 train_acc: 0.4352 | val_loss: 1.3337 val_acc: 0.3942\n",
            "Epoch 5: train_loss: 1.2241 train_acc: 0.4565 | val_loss: 1.3163 val_acc: 0.4233\n",
            "Epoch 6: train_loss: 1.1971 train_acc: 0.4680 | val_loss: 1.3439 val_acc: 0.4178\n",
            "Epoch 7: train_loss: 1.1669 train_acc: 0.4821 | val_loss: 1.3680 val_acc: 0.4223\n",
            "Epoch 8: train_loss: 1.1464 train_acc: 0.4912 | val_loss: 1.3414 val_acc: 0.4151\n",
            "Epoch 9: train_loss: 1.1196 train_acc: 0.5078 | val_loss: 1.3285 val_acc: 0.4178\n",
            "Epoch 10: train_loss: 1.1023 train_acc: 0.5193 | val_loss: 1.3308 val_acc: 0.4187\n",
            "Epoch 11: train_loss: 1.0726 train_acc: 0.5336 | val_loss: 1.3663 val_acc: 0.4142\n",
            "Epoch 12: train_loss: 1.0387 train_acc: 0.5508 | val_loss: 1.3533 val_acc: 0.4205\n",
            "Epoch 13: train_loss: 1.0133 train_acc: 0.5592 | val_loss: 1.3377 val_acc: 0.4142\n",
            "Epoch 14: train_loss: 0.9803 train_acc: 0.5816 | val_loss: 1.3683 val_acc: 0.4242\n",
            "Epoch 15: train_loss: 0.9433 train_acc: 0.6039 | val_loss: 1.4034 val_acc: 0.4105\n",
            "Epoch 16: train_loss: 0.9172 train_acc: 0.6187 | val_loss: 1.3954 val_acc: 0.4169\n",
            "Epoch 17: train_loss: 0.8759 train_acc: 0.6345 | val_loss: 1.4655 val_acc: 0.4133\n",
            "Epoch 18: train_loss: 0.8453 train_acc: 0.6477 | val_loss: 1.4573 val_acc: 0.4233\n",
            "Epoch 19: train_loss: 0.8007 train_acc: 0.6725 | val_loss: 1.4349 val_acc: 0.4205\n",
            "Epoch 20: train_loss: 0.7735 train_acc: 0.6918 | val_loss: 1.5244 val_acc: 0.4169\n",
            "Epoch 21: train_loss: 0.7234 train_acc: 0.7144 | val_loss: 1.5632 val_acc: 0.4033\n",
            "Epoch 22: train_loss: 0.6743 train_acc: 0.7433 | val_loss: 1.6237 val_acc: 0.4096\n",
            "Epoch 23: train_loss: 0.6405 train_acc: 0.7540 | val_loss: 1.6636 val_acc: 0.4033\n",
            "Epoch 24: train_loss: 0.6254 train_acc: 0.7630 | val_loss: 1.6384 val_acc: 0.4114\n",
            "Lowest val_loss: 1.3163, at epoch 5\n",
            "GRU 50 2 [50]\n",
            "Epoch 0: train_loss: 1.5761 train_acc: 0.2550 | val_loss: 1.5804 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2693 | val_loss: 1.5714 val_acc: 0.2552\n",
            "Epoch 2: train_loss: 1.5689 train_acc: 0.2757 | val_loss: 1.5675 val_acc: 0.2943\n",
            "Epoch 3: train_loss: 1.4814 train_acc: 0.3311 | val_loss: 1.3568 val_acc: 0.4105\n",
            "Epoch 4: train_loss: 1.2687 train_acc: 0.4308 | val_loss: 1.3331 val_acc: 0.4124\n",
            "Epoch 5: train_loss: 1.2208 train_acc: 0.4533 | val_loss: 1.4043 val_acc: 0.3942\n",
            "Epoch 6: train_loss: 1.1919 train_acc: 0.4778 | val_loss: 1.3058 val_acc: 0.4287\n",
            "Epoch 7: train_loss: 1.1728 train_acc: 0.4783 | val_loss: 1.3205 val_acc: 0.4278\n",
            "Epoch 8: train_loss: 1.1487 train_acc: 0.4977 | val_loss: 1.3338 val_acc: 0.4151\n",
            "Epoch 9: train_loss: 1.1221 train_acc: 0.5177 | val_loss: 1.3425 val_acc: 0.4214\n",
            "Epoch 10: train_loss: 1.1032 train_acc: 0.5204 | val_loss: 1.3080 val_acc: 0.4251\n",
            "Epoch 11: train_loss: 1.0813 train_acc: 0.5400 | val_loss: 1.3273 val_acc: 0.4087\n",
            "Epoch 12: train_loss: 1.0478 train_acc: 0.5511 | val_loss: 1.3356 val_acc: 0.4114\n",
            "Epoch 13: train_loss: 1.0183 train_acc: 0.5688 | val_loss: 1.3346 val_acc: 0.4151\n",
            "Epoch 14: train_loss: 0.9889 train_acc: 0.5837 | val_loss: 1.3362 val_acc: 0.4323\n",
            "Epoch 15: train_loss: 0.9553 train_acc: 0.6035 | val_loss: 1.3447 val_acc: 0.4332\n",
            "Epoch 16: train_loss: 0.9344 train_acc: 0.6136 | val_loss: 1.3942 val_acc: 0.4332\n",
            "Epoch 17: train_loss: 0.8872 train_acc: 0.6400 | val_loss: 1.3687 val_acc: 0.4296\n",
            "Epoch 18: train_loss: 0.8516 train_acc: 0.6559 | val_loss: 1.4235 val_acc: 0.4205\n",
            "Epoch 19: train_loss: 0.8171 train_acc: 0.6743 | val_loss: 1.4719 val_acc: 0.4305\n",
            "Epoch 20: train_loss: 0.7753 train_acc: 0.7029 | val_loss: 1.5108 val_acc: 0.4169\n",
            "Epoch 21: train_loss: 0.7320 train_acc: 0.7244 | val_loss: 1.5002 val_acc: 0.4323\n",
            "Epoch 22: train_loss: 0.7088 train_acc: 0.7288 | val_loss: 1.5456 val_acc: 0.4151\n",
            "Epoch 23: train_loss: 0.6510 train_acc: 0.7616 | val_loss: 1.5923 val_acc: 0.4305\n",
            "Epoch 24: train_loss: 0.6266 train_acc: 0.7698 | val_loss: 1.5657 val_acc: 0.4078\n",
            "Lowest val_loss: 1.3058, at epoch 6\n",
            "GRU 50 2 [60]\n",
            "Epoch 0: train_loss: 1.5749 train_acc: 0.2603 | val_loss: 1.5822 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2678 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5496 train_acc: 0.2963 | val_loss: 1.4598 val_acc: 0.3615\n",
            "Epoch 3: train_loss: 1.3636 train_acc: 0.3904 | val_loss: 1.3867 val_acc: 0.3660\n",
            "Epoch 4: train_loss: 1.2582 train_acc: 0.4324 | val_loss: 1.3306 val_acc: 0.3960\n",
            "Epoch 5: train_loss: 1.2222 train_acc: 0.4465 | val_loss: 1.3879 val_acc: 0.3987\n",
            "Epoch 6: train_loss: 1.1945 train_acc: 0.4657 | val_loss: 1.3342 val_acc: 0.4024\n",
            "Epoch 7: train_loss: 1.1661 train_acc: 0.4788 | val_loss: 1.3382 val_acc: 0.4105\n",
            "Epoch 8: train_loss: 1.1459 train_acc: 0.4925 | val_loss: 1.3334 val_acc: 0.4060\n",
            "Epoch 9: train_loss: 1.1210 train_acc: 0.5036 | val_loss: 1.3288 val_acc: 0.4269\n",
            "Epoch 10: train_loss: 1.0943 train_acc: 0.5119 | val_loss: 1.3205 val_acc: 0.4223\n",
            "Epoch 11: train_loss: 1.0659 train_acc: 0.5332 | val_loss: 1.3651 val_acc: 0.4196\n",
            "Epoch 12: train_loss: 1.0373 train_acc: 0.5492 | val_loss: 1.3695 val_acc: 0.4133\n",
            "Epoch 13: train_loss: 1.0055 train_acc: 0.5609 | val_loss: 1.3664 val_acc: 0.4314\n",
            "Epoch 14: train_loss: 0.9692 train_acc: 0.5845 | val_loss: 1.3789 val_acc: 0.4187\n",
            "Epoch 15: train_loss: 0.9399 train_acc: 0.5948 | val_loss: 1.3599 val_acc: 0.4278\n",
            "Epoch 16: train_loss: 0.8981 train_acc: 0.6199 | val_loss: 1.3882 val_acc: 0.4205\n",
            "Epoch 17: train_loss: 0.8723 train_acc: 0.6340 | val_loss: 1.3832 val_acc: 0.4214\n",
            "Epoch 18: train_loss: 0.8319 train_acc: 0.6566 | val_loss: 1.4516 val_acc: 0.4251\n",
            "Epoch 19: train_loss: 0.7958 train_acc: 0.6821 | val_loss: 1.5123 val_acc: 0.4223\n",
            "Epoch 20: train_loss: 0.7515 train_acc: 0.6971 | val_loss: 1.5262 val_acc: 0.4051\n",
            "Epoch 21: train_loss: 0.7190 train_acc: 0.7143 | val_loss: 1.5455 val_acc: 0.4033\n",
            "Epoch 22: train_loss: 0.6886 train_acc: 0.7287 | val_loss: 1.5234 val_acc: 0.4187\n",
            "Epoch 23: train_loss: 0.6338 train_acc: 0.7609 | val_loss: 1.6137 val_acc: 0.4142\n",
            "Epoch 24: train_loss: 0.6029 train_acc: 0.7747 | val_loss: 1.6298 val_acc: 0.3978\n",
            "Lowest val_loss: 1.3205, at epoch 10\n",
            "GRU 50 2 [70]\n",
            "Epoch 0: train_loss: 1.5715 train_acc: 0.2656 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2701 | val_loss: 1.5708 val_acc: 0.2543\n",
            "Epoch 2: train_loss: 1.5678 train_acc: 0.2698 | val_loss: 1.5562 val_acc: 0.2716\n",
            "Epoch 3: train_loss: 1.3688 train_acc: 0.3909 | val_loss: 1.3585 val_acc: 0.4087\n",
            "Epoch 4: train_loss: 1.2533 train_acc: 0.4356 | val_loss: 1.3164 val_acc: 0.4242\n",
            "Epoch 5: train_loss: 1.2161 train_acc: 0.4558 | val_loss: 1.3183 val_acc: 0.4151\n",
            "Epoch 6: train_loss: 1.1923 train_acc: 0.4613 | val_loss: 1.3219 val_acc: 0.4332\n",
            "Epoch 7: train_loss: 1.1634 train_acc: 0.4817 | val_loss: 1.3495 val_acc: 0.4124\n",
            "Epoch 8: train_loss: 1.1349 train_acc: 0.4954 | val_loss: 1.3284 val_acc: 0.4342\n",
            "Epoch 9: train_loss: 1.1160 train_acc: 0.5054 | val_loss: 1.3178 val_acc: 0.4196\n",
            "Epoch 10: train_loss: 1.0929 train_acc: 0.5138 | val_loss: 1.3593 val_acc: 0.4287\n",
            "Epoch 11: train_loss: 1.0678 train_acc: 0.5366 | val_loss: 1.3473 val_acc: 0.4360\n",
            "Epoch 12: train_loss: 1.0336 train_acc: 0.5518 | val_loss: 1.3367 val_acc: 0.4360\n",
            "Epoch 13: train_loss: 1.0113 train_acc: 0.5658 | val_loss: 1.3567 val_acc: 0.4251\n",
            "Epoch 14: train_loss: 0.9679 train_acc: 0.5824 | val_loss: 1.3533 val_acc: 0.4450\n",
            "Epoch 15: train_loss: 0.9307 train_acc: 0.6113 | val_loss: 1.3927 val_acc: 0.4314\n",
            "Epoch 16: train_loss: 0.8993 train_acc: 0.6209 | val_loss: 1.4414 val_acc: 0.4151\n",
            "Epoch 17: train_loss: 0.8665 train_acc: 0.6387 | val_loss: 1.4787 val_acc: 0.4105\n",
            "Epoch 18: train_loss: 0.8201 train_acc: 0.6704 | val_loss: 1.4610 val_acc: 0.4360\n",
            "Epoch 19: train_loss: 0.7883 train_acc: 0.6836 | val_loss: 1.4592 val_acc: 0.4187\n",
            "Epoch 20: train_loss: 0.7482 train_acc: 0.7069 | val_loss: 1.5308 val_acc: 0.4223\n",
            "Epoch 21: train_loss: 0.7100 train_acc: 0.7221 | val_loss: 1.5659 val_acc: 0.3942\n",
            "Epoch 22: train_loss: 0.6579 train_acc: 0.7516 | val_loss: 1.6185 val_acc: 0.4187\n",
            "Epoch 23: train_loss: 0.6293 train_acc: 0.7625 | val_loss: 1.6274 val_acc: 0.4133\n",
            "Epoch 24: train_loss: 0.5841 train_acc: 0.7863 | val_loss: 1.7532 val_acc: 0.3978\n",
            "Lowest val_loss: 1.3164, at epoch 4\n",
            "GRU 60 1 [30]\n",
            "Epoch 0: train_loss: 1.5873 train_acc: 0.2374 | val_loss: 1.5725 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2705 | val_loss: 1.5635 val_acc: 0.2716\n",
            "Epoch 2: train_loss: 1.5544 train_acc: 0.2937 | val_loss: 1.4751 val_acc: 0.3697\n",
            "Epoch 3: train_loss: 1.3248 train_acc: 0.4139 | val_loss: 1.3117 val_acc: 0.4323\n",
            "Epoch 4: train_loss: 1.2420 train_acc: 0.4382 | val_loss: 1.3047 val_acc: 0.4360\n",
            "Epoch 5: train_loss: 1.1973 train_acc: 0.4682 | val_loss: 1.3020 val_acc: 0.4405\n",
            "Epoch 6: train_loss: 1.1694 train_acc: 0.4817 | val_loss: 1.2972 val_acc: 0.4396\n",
            "Epoch 7: train_loss: 1.1378 train_acc: 0.4937 | val_loss: 1.3223 val_acc: 0.4169\n",
            "Epoch 8: train_loss: 1.1180 train_acc: 0.5091 | val_loss: 1.3402 val_acc: 0.4205\n",
            "Epoch 9: train_loss: 1.0882 train_acc: 0.5240 | val_loss: 1.3196 val_acc: 0.4233\n",
            "Epoch 10: train_loss: 1.0612 train_acc: 0.5377 | val_loss: 1.3265 val_acc: 0.4287\n",
            "Epoch 11: train_loss: 1.0335 train_acc: 0.5541 | val_loss: 1.3371 val_acc: 0.4278\n",
            "Epoch 12: train_loss: 0.9985 train_acc: 0.5699 | val_loss: 1.3499 val_acc: 0.4142\n",
            "Epoch 13: train_loss: 0.9708 train_acc: 0.5861 | val_loss: 1.3880 val_acc: 0.4169\n",
            "Epoch 14: train_loss: 0.9250 train_acc: 0.6111 | val_loss: 1.4005 val_acc: 0.4223\n",
            "Epoch 15: train_loss: 0.8973 train_acc: 0.6283 | val_loss: 1.3657 val_acc: 0.4069\n",
            "Epoch 16: train_loss: 0.8548 train_acc: 0.6490 | val_loss: 1.4347 val_acc: 0.4142\n",
            "Epoch 17: train_loss: 0.8053 train_acc: 0.6778 | val_loss: 1.4616 val_acc: 0.4015\n",
            "Epoch 18: train_loss: 0.7675 train_acc: 0.6966 | val_loss: 1.5026 val_acc: 0.4015\n",
            "Epoch 19: train_loss: 0.7294 train_acc: 0.7185 | val_loss: 1.5307 val_acc: 0.4105\n",
            "Epoch 20: train_loss: 0.6820 train_acc: 0.7432 | val_loss: 1.6046 val_acc: 0.4042\n",
            "Epoch 21: train_loss: 0.6354 train_acc: 0.7614 | val_loss: 1.5844 val_acc: 0.3887\n",
            "Epoch 22: train_loss: 0.5936 train_acc: 0.7825 | val_loss: 1.6401 val_acc: 0.4042\n",
            "Epoch 23: train_loss: 0.5465 train_acc: 0.8047 | val_loss: 1.7150 val_acc: 0.4005\n",
            "Epoch 24: train_loss: 0.5202 train_acc: 0.8131 | val_loss: 1.7565 val_acc: 0.3942\n",
            "Lowest val_loss: 1.2972, at epoch 6\n",
            "GRU 60 1 [40]\n",
            "Epoch 0: train_loss: 1.5749 train_acc: 0.2597 | val_loss: 1.5710 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5682 train_acc: 0.2691 | val_loss: 1.5694 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5668 train_acc: 0.2719 | val_loss: 1.5634 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5651 train_acc: 0.2736 | val_loss: 1.5590 val_acc: 0.2634\n",
            "Epoch 4: train_loss: 1.5323 train_acc: 0.3027 | val_loss: 1.4434 val_acc: 0.3497\n",
            "Epoch 5: train_loss: 1.3170 train_acc: 0.4164 | val_loss: 1.3619 val_acc: 0.3933\n",
            "Epoch 6: train_loss: 1.2337 train_acc: 0.4469 | val_loss: 1.3472 val_acc: 0.4124\n",
            "Epoch 7: train_loss: 1.1876 train_acc: 0.4714 | val_loss: 1.3162 val_acc: 0.4205\n",
            "Epoch 8: train_loss: 1.1545 train_acc: 0.4838 | val_loss: 1.3898 val_acc: 0.4005\n",
            "Epoch 9: train_loss: 1.1295 train_acc: 0.5101 | val_loss: 1.3773 val_acc: 0.4087\n",
            "Epoch 10: train_loss: 1.0999 train_acc: 0.5211 | val_loss: 1.3705 val_acc: 0.4105\n",
            "Epoch 11: train_loss: 1.0765 train_acc: 0.5348 | val_loss: 1.3490 val_acc: 0.4015\n",
            "Epoch 12: train_loss: 1.0355 train_acc: 0.5520 | val_loss: 1.3792 val_acc: 0.4042\n",
            "Epoch 13: train_loss: 0.9956 train_acc: 0.5781 | val_loss: 1.4071 val_acc: 0.3915\n",
            "Epoch 14: train_loss: 0.9637 train_acc: 0.5927 | val_loss: 1.4174 val_acc: 0.4024\n",
            "Epoch 15: train_loss: 0.9251 train_acc: 0.6088 | val_loss: 1.4161 val_acc: 0.4033\n",
            "Epoch 16: train_loss: 0.8870 train_acc: 0.6309 | val_loss: 1.4649 val_acc: 0.3996\n",
            "Epoch 17: train_loss: 0.8365 train_acc: 0.6621 | val_loss: 1.5044 val_acc: 0.4042\n",
            "Epoch 18: train_loss: 0.7920 train_acc: 0.6786 | val_loss: 1.5813 val_acc: 0.3942\n",
            "Epoch 19: train_loss: 0.7493 train_acc: 0.7025 | val_loss: 1.6049 val_acc: 0.4051\n",
            "Epoch 20: train_loss: 0.7022 train_acc: 0.7298 | val_loss: 1.6173 val_acc: 0.4105\n",
            "Epoch 21: train_loss: 0.6599 train_acc: 0.7472 | val_loss: 1.6495 val_acc: 0.4015\n",
            "Epoch 22: train_loss: 0.6089 train_acc: 0.7721 | val_loss: 1.7768 val_acc: 0.3896\n",
            "Epoch 23: train_loss: 0.5671 train_acc: 0.7912 | val_loss: 1.8060 val_acc: 0.3815\n",
            "Epoch 24: train_loss: 0.5317 train_acc: 0.8068 | val_loss: 1.8720 val_acc: 0.3860\n",
            "Lowest val_loss: 1.3162, at epoch 7\n",
            "GRU 60 1 [50]\n",
            "Epoch 0: train_loss: 1.5742 train_acc: 0.2614 | val_loss: 1.5878 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2707 | val_loss: 1.5690 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5674 train_acc: 0.2721 | val_loss: 1.5678 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5663 train_acc: 0.2707 | val_loss: 1.5608 val_acc: 0.2716\n",
            "Epoch 4: train_loss: 1.5438 train_acc: 0.2947 | val_loss: 1.4720 val_acc: 0.3624\n",
            "Epoch 5: train_loss: 1.3472 train_acc: 0.4023 | val_loss: 1.3324 val_acc: 0.4015\n",
            "Epoch 6: train_loss: 1.2420 train_acc: 0.4485 | val_loss: 1.3156 val_acc: 0.4105\n",
            "Epoch 7: train_loss: 1.2058 train_acc: 0.4615 | val_loss: 1.3283 val_acc: 0.4160\n",
            "Epoch 8: train_loss: 1.1707 train_acc: 0.4795 | val_loss: 1.3222 val_acc: 0.4160\n",
            "Epoch 9: train_loss: 1.1448 train_acc: 0.4951 | val_loss: 1.3132 val_acc: 0.4242\n",
            "Epoch 10: train_loss: 1.1220 train_acc: 0.5112 | val_loss: 1.3341 val_acc: 0.4151\n",
            "Epoch 11: train_loss: 1.0828 train_acc: 0.5288 | val_loss: 1.3630 val_acc: 0.4051\n",
            "Epoch 12: train_loss: 1.0552 train_acc: 0.5488 | val_loss: 1.3637 val_acc: 0.4133\n",
            "Epoch 13: train_loss: 1.0158 train_acc: 0.5721 | val_loss: 1.4015 val_acc: 0.4124\n",
            "Epoch 14: train_loss: 0.9903 train_acc: 0.5808 | val_loss: 1.4372 val_acc: 0.4015\n",
            "Epoch 15: train_loss: 0.9501 train_acc: 0.5995 | val_loss: 1.4683 val_acc: 0.4060\n",
            "Epoch 16: train_loss: 0.9164 train_acc: 0.6194 | val_loss: 1.4567 val_acc: 0.4005\n",
            "Epoch 17: train_loss: 0.8683 train_acc: 0.6400 | val_loss: 1.4870 val_acc: 0.4005\n",
            "Epoch 18: train_loss: 0.8342 train_acc: 0.6654 | val_loss: 1.5243 val_acc: 0.4105\n",
            "Epoch 19: train_loss: 0.7878 train_acc: 0.6831 | val_loss: 1.5583 val_acc: 0.3942\n",
            "Epoch 20: train_loss: 0.7535 train_acc: 0.7055 | val_loss: 1.6197 val_acc: 0.4060\n",
            "Epoch 21: train_loss: 0.6977 train_acc: 0.7330 | val_loss: 1.6685 val_acc: 0.4105\n",
            "Epoch 22: train_loss: 0.6562 train_acc: 0.7554 | val_loss: 1.6915 val_acc: 0.4069\n",
            "Epoch 23: train_loss: 0.6121 train_acc: 0.7733 | val_loss: 1.7978 val_acc: 0.3996\n",
            "Epoch 24: train_loss: 0.5755 train_acc: 0.7913 | val_loss: 1.7659 val_acc: 0.3960\n",
            "Lowest val_loss: 1.3132, at epoch 9\n",
            "GRU 60 1 [60]\n",
            "Epoch 0: train_loss: 1.5727 train_acc: 0.2660 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2711 | val_loss: 1.5662 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5671 train_acc: 0.2692 | val_loss: 1.5630 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5655 train_acc: 0.2666 | val_loss: 1.5748 val_acc: 0.2925\n",
            "Epoch 4: train_loss: 1.4235 train_acc: 0.3669 | val_loss: 1.3413 val_acc: 0.3896\n",
            "Epoch 5: train_loss: 1.2668 train_acc: 0.4286 | val_loss: 1.3132 val_acc: 0.4251\n",
            "Epoch 6: train_loss: 1.2130 train_acc: 0.4607 | val_loss: 1.3214 val_acc: 0.4069\n",
            "Epoch 7: train_loss: 1.1804 train_acc: 0.4790 | val_loss: 1.3403 val_acc: 0.4015\n",
            "Epoch 8: train_loss: 1.1556 train_acc: 0.4837 | val_loss: 1.3295 val_acc: 0.4096\n",
            "Epoch 9: train_loss: 1.1273 train_acc: 0.4994 | val_loss: 1.3499 val_acc: 0.4060\n",
            "Epoch 10: train_loss: 1.0996 train_acc: 0.5177 | val_loss: 1.3537 val_acc: 0.3960\n",
            "Epoch 11: train_loss: 1.0723 train_acc: 0.5336 | val_loss: 1.4166 val_acc: 0.3915\n",
            "Epoch 12: train_loss: 1.0378 train_acc: 0.5461 | val_loss: 1.4158 val_acc: 0.3906\n",
            "Epoch 13: train_loss: 1.0047 train_acc: 0.5712 | val_loss: 1.4086 val_acc: 0.3960\n",
            "Epoch 14: train_loss: 0.9696 train_acc: 0.5853 | val_loss: 1.4363 val_acc: 0.3933\n",
            "Epoch 15: train_loss: 0.9261 train_acc: 0.6077 | val_loss: 1.4430 val_acc: 0.3969\n",
            "Epoch 16: train_loss: 0.8952 train_acc: 0.6214 | val_loss: 1.4479 val_acc: 0.3996\n",
            "Epoch 17: train_loss: 0.8458 train_acc: 0.6478 | val_loss: 1.4794 val_acc: 0.4005\n",
            "Epoch 18: train_loss: 0.8044 train_acc: 0.6706 | val_loss: 1.5748 val_acc: 0.3933\n",
            "Epoch 19: train_loss: 0.7667 train_acc: 0.6894 | val_loss: 1.5893 val_acc: 0.3878\n",
            "Epoch 20: train_loss: 0.7112 train_acc: 0.7161 | val_loss: 1.6248 val_acc: 0.3860\n",
            "Epoch 21: train_loss: 0.6728 train_acc: 0.7382 | val_loss: 1.7109 val_acc: 0.3815\n",
            "Epoch 22: train_loss: 0.6258 train_acc: 0.7594 | val_loss: 1.7044 val_acc: 0.3915\n",
            "Epoch 23: train_loss: 0.5827 train_acc: 0.7842 | val_loss: 1.7612 val_acc: 0.3760\n",
            "Epoch 24: train_loss: 0.5381 train_acc: 0.8009 | val_loss: 1.8226 val_acc: 0.3724\n",
            "Lowest val_loss: 1.3132, at epoch 5\n",
            "GRU 60 1 [70]\n",
            "Epoch 0: train_loss: 1.5734 train_acc: 0.2715 | val_loss: 1.5710 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2719 | val_loss: 1.5676 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5671 train_acc: 0.2713 | val_loss: 1.5651 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5652 train_acc: 0.2657 | val_loss: 1.5408 val_acc: 0.2897\n",
            "Epoch 4: train_loss: 1.3865 train_acc: 0.3895 | val_loss: 1.3422 val_acc: 0.4187\n",
            "Epoch 5: train_loss: 1.2576 train_acc: 0.4423 | val_loss: 1.3365 val_acc: 0.4124\n",
            "Epoch 6: train_loss: 1.2092 train_acc: 0.4606 | val_loss: 1.3202 val_acc: 0.4124\n",
            "Epoch 7: train_loss: 1.1726 train_acc: 0.4773 | val_loss: 1.3286 val_acc: 0.4024\n",
            "Epoch 8: train_loss: 1.1487 train_acc: 0.4923 | val_loss: 1.3407 val_acc: 0.4151\n",
            "Epoch 9: train_loss: 1.1179 train_acc: 0.5057 | val_loss: 1.3546 val_acc: 0.4142\n",
            "Epoch 10: train_loss: 1.0929 train_acc: 0.5200 | val_loss: 1.3657 val_acc: 0.4178\n",
            "Epoch 11: train_loss: 1.0649 train_acc: 0.5351 | val_loss: 1.3883 val_acc: 0.4178\n",
            "Epoch 12: train_loss: 1.0328 train_acc: 0.5533 | val_loss: 1.4155 val_acc: 0.4124\n",
            "Epoch 13: train_loss: 0.9991 train_acc: 0.5732 | val_loss: 1.4320 val_acc: 0.4042\n",
            "Epoch 14: train_loss: 0.9574 train_acc: 0.5970 | val_loss: 1.4743 val_acc: 0.4005\n",
            "Epoch 15: train_loss: 0.9229 train_acc: 0.6122 | val_loss: 1.4630 val_acc: 0.4005\n",
            "Epoch 16: train_loss: 0.8889 train_acc: 0.6276 | val_loss: 1.4900 val_acc: 0.4151\n",
            "Epoch 17: train_loss: 0.8325 train_acc: 0.6599 | val_loss: 1.6017 val_acc: 0.4060\n",
            "Epoch 18: train_loss: 0.7985 train_acc: 0.6770 | val_loss: 1.6205 val_acc: 0.3996\n",
            "Epoch 19: train_loss: 0.7462 train_acc: 0.7056 | val_loss: 1.6626 val_acc: 0.4060\n",
            "Epoch 20: train_loss: 0.6962 train_acc: 0.7278 | val_loss: 1.7421 val_acc: 0.4060\n",
            "Epoch 21: train_loss: 0.6564 train_acc: 0.7478 | val_loss: 1.7447 val_acc: 0.4060\n",
            "Epoch 22: train_loss: 0.6066 train_acc: 0.7705 | val_loss: 1.7901 val_acc: 0.4060\n",
            "Epoch 23: train_loss: 0.5645 train_acc: 0.7911 | val_loss: 1.8505 val_acc: 0.4096\n",
            "Epoch 24: train_loss: 0.5185 train_acc: 0.8146 | val_loss: 1.9241 val_acc: 0.3987\n",
            "Lowest val_loss: 1.3202, at epoch 6\n",
            "GRU 60 2 [30]\n",
            "Epoch 0: train_loss: 1.5793 train_acc: 0.2494 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2712 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5691 train_acc: 0.2701 | val_loss: 1.5817 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5673 train_acc: 0.2685 | val_loss: 1.5827 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5034 train_acc: 0.3194 | val_loss: 1.5168 val_acc: 0.3542\n",
            "Epoch 5: train_loss: 1.2916 train_acc: 0.4276 | val_loss: 1.3114 val_acc: 0.4305\n",
            "Epoch 6: train_loss: 1.2260 train_acc: 0.4544 | val_loss: 1.3518 val_acc: 0.3960\n",
            "Epoch 7: train_loss: 1.1822 train_acc: 0.4837 | val_loss: 1.3516 val_acc: 0.4251\n",
            "Epoch 8: train_loss: 1.1493 train_acc: 0.5021 | val_loss: 1.3308 val_acc: 0.4169\n",
            "Epoch 9: train_loss: 1.1294 train_acc: 0.5078 | val_loss: 1.3667 val_acc: 0.4287\n",
            "Epoch 10: train_loss: 1.0943 train_acc: 0.5226 | val_loss: 1.3608 val_acc: 0.4233\n",
            "Epoch 11: train_loss: 1.0645 train_acc: 0.5415 | val_loss: 1.3334 val_acc: 0.4396\n",
            "Epoch 12: train_loss: 1.0279 train_acc: 0.5634 | val_loss: 1.3855 val_acc: 0.4305\n",
            "Epoch 13: train_loss: 0.9945 train_acc: 0.5802 | val_loss: 1.3604 val_acc: 0.4278\n",
            "Epoch 14: train_loss: 0.9570 train_acc: 0.5967 | val_loss: 1.4186 val_acc: 0.4369\n",
            "Epoch 15: train_loss: 0.9123 train_acc: 0.6209 | val_loss: 1.4018 val_acc: 0.4214\n",
            "Epoch 16: train_loss: 0.8656 train_acc: 0.6463 | val_loss: 1.4749 val_acc: 0.4160\n",
            "Epoch 17: train_loss: 0.8142 train_acc: 0.6763 | val_loss: 1.5336 val_acc: 0.4223\n",
            "Epoch 18: train_loss: 0.7786 train_acc: 0.6951 | val_loss: 1.5496 val_acc: 0.4187\n",
            "Epoch 19: train_loss: 0.7238 train_acc: 0.7230 | val_loss: 1.6124 val_acc: 0.4142\n",
            "Epoch 20: train_loss: 0.6743 train_acc: 0.7501 | val_loss: 1.6742 val_acc: 0.4133\n",
            "Epoch 21: train_loss: 0.6287 train_acc: 0.7662 | val_loss: 1.6827 val_acc: 0.4124\n",
            "Epoch 22: train_loss: 0.5639 train_acc: 0.8021 | val_loss: 1.7301 val_acc: 0.4278\n",
            "Epoch 23: train_loss: 0.5303 train_acc: 0.8130 | val_loss: 1.8533 val_acc: 0.4178\n",
            "Epoch 24: train_loss: 0.4882 train_acc: 0.8326 | val_loss: 1.8681 val_acc: 0.4142\n",
            "Lowest val_loss: 1.3114, at epoch 5\n",
            "GRU 60 2 [40]\n",
            "Epoch 0: train_loss: 1.5736 train_acc: 0.2721 | val_loss: 1.5760 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5703 train_acc: 0.2670 | val_loss: 1.5691 val_acc: 0.3261\n",
            "Epoch 2: train_loss: 1.5689 train_acc: 0.2735 | val_loss: 1.5673 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5627 train_acc: 0.2766 | val_loss: 1.5155 val_acc: 0.3188\n",
            "Epoch 4: train_loss: 1.3759 train_acc: 0.3926 | val_loss: 1.3867 val_acc: 0.3760\n",
            "Epoch 5: train_loss: 1.2518 train_acc: 0.4417 | val_loss: 1.3257 val_acc: 0.4015\n",
            "Epoch 6: train_loss: 1.2075 train_acc: 0.4618 | val_loss: 1.3363 val_acc: 0.4151\n",
            "Epoch 7: train_loss: 1.1742 train_acc: 0.4795 | val_loss: 1.3383 val_acc: 0.4196\n",
            "Epoch 8: train_loss: 1.1476 train_acc: 0.4937 | val_loss: 1.3240 val_acc: 0.4269\n",
            "Epoch 9: train_loss: 1.1256 train_acc: 0.5029 | val_loss: 1.3264 val_acc: 0.4342\n",
            "Epoch 10: train_loss: 1.0828 train_acc: 0.5330 | val_loss: 1.4006 val_acc: 0.3787\n",
            "Epoch 11: train_loss: 1.0501 train_acc: 0.5415 | val_loss: 1.3523 val_acc: 0.3951\n",
            "Epoch 12: train_loss: 1.0186 train_acc: 0.5620 | val_loss: 1.3425 val_acc: 0.4387\n",
            "Epoch 13: train_loss: 0.9719 train_acc: 0.5854 | val_loss: 1.3484 val_acc: 0.4205\n",
            "Epoch 14: train_loss: 0.9399 train_acc: 0.6021 | val_loss: 1.3943 val_acc: 0.4378\n",
            "Epoch 15: train_loss: 0.8853 train_acc: 0.6272 | val_loss: 1.4082 val_acc: 0.4078\n",
            "Epoch 16: train_loss: 0.8428 train_acc: 0.6547 | val_loss: 1.4708 val_acc: 0.3942\n",
            "Epoch 17: train_loss: 0.7969 train_acc: 0.6828 | val_loss: 1.4802 val_acc: 0.4069\n",
            "Epoch 18: train_loss: 0.7325 train_acc: 0.7085 | val_loss: 1.5278 val_acc: 0.4078\n",
            "Epoch 19: train_loss: 0.6855 train_acc: 0.7368 | val_loss: 1.6091 val_acc: 0.4114\n",
            "Epoch 20: train_loss: 0.6487 train_acc: 0.7506 | val_loss: 1.6020 val_acc: 0.4205\n",
            "Epoch 21: train_loss: 0.5822 train_acc: 0.7808 | val_loss: 1.7128 val_acc: 0.4096\n",
            "Epoch 22: train_loss: 0.5366 train_acc: 0.8028 | val_loss: 1.7506 val_acc: 0.4015\n",
            "Epoch 23: train_loss: 0.5001 train_acc: 0.8166 | val_loss: 1.8179 val_acc: 0.4060\n",
            "Epoch 24: train_loss: 0.4631 train_acc: 0.8312 | val_loss: 1.9409 val_acc: 0.4060\n",
            "Lowest val_loss: 1.3240, at epoch 8\n",
            "GRU 60 2 [50]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2622 | val_loss: 1.5781 val_acc: 0.2570\n",
            "Epoch 1: train_loss: 1.5684 train_acc: 0.2760 | val_loss: 1.5725 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5685 train_acc: 0.2681 | val_loss: 1.5706 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5636 train_acc: 0.2677 | val_loss: 1.5573 val_acc: 0.2925\n",
            "Epoch 4: train_loss: 1.4084 train_acc: 0.3806 | val_loss: 1.3529 val_acc: 0.4015\n",
            "Epoch 5: train_loss: 1.2554 train_acc: 0.4398 | val_loss: 1.3495 val_acc: 0.4033\n",
            "Epoch 6: train_loss: 1.1998 train_acc: 0.4696 | val_loss: 1.3433 val_acc: 0.4060\n",
            "Epoch 7: train_loss: 1.1599 train_acc: 0.4933 | val_loss: 1.3109 val_acc: 0.4169\n",
            "Epoch 8: train_loss: 1.1346 train_acc: 0.5004 | val_loss: 1.3213 val_acc: 0.4042\n",
            "Epoch 9: train_loss: 1.1040 train_acc: 0.5275 | val_loss: 1.3191 val_acc: 0.4142\n",
            "Epoch 10: train_loss: 1.0706 train_acc: 0.5426 | val_loss: 1.3452 val_acc: 0.3996\n",
            "Epoch 11: train_loss: 1.0418 train_acc: 0.5586 | val_loss: 1.3639 val_acc: 0.4160\n",
            "Epoch 12: train_loss: 1.0128 train_acc: 0.5709 | val_loss: 1.3557 val_acc: 0.4169\n",
            "Epoch 13: train_loss: 0.9707 train_acc: 0.5930 | val_loss: 1.3906 val_acc: 0.4042\n",
            "Epoch 14: train_loss: 0.9409 train_acc: 0.6069 | val_loss: 1.4455 val_acc: 0.4187\n",
            "Epoch 15: train_loss: 0.8985 train_acc: 0.6372 | val_loss: 1.4736 val_acc: 0.3987\n",
            "Epoch 16: train_loss: 0.8448 train_acc: 0.6630 | val_loss: 1.5051 val_acc: 0.4078\n",
            "Epoch 17: train_loss: 0.7954 train_acc: 0.6862 | val_loss: 1.5770 val_acc: 0.4078\n",
            "Epoch 18: train_loss: 0.7485 train_acc: 0.7080 | val_loss: 1.5907 val_acc: 0.4096\n",
            "Epoch 19: train_loss: 0.6882 train_acc: 0.7409 | val_loss: 1.6655 val_acc: 0.3996\n",
            "Epoch 20: train_loss: 0.6559 train_acc: 0.7550 | val_loss: 1.6982 val_acc: 0.3960\n",
            "Epoch 21: train_loss: 0.5950 train_acc: 0.7844 | val_loss: 1.8064 val_acc: 0.3906\n",
            "Epoch 22: train_loss: 0.5540 train_acc: 0.7988 | val_loss: 1.8526 val_acc: 0.4069\n",
            "Epoch 23: train_loss: 0.4988 train_acc: 0.8258 | val_loss: 1.9737 val_acc: 0.3960\n",
            "Epoch 24: train_loss: 0.4547 train_acc: 0.8409 | val_loss: 1.9902 val_acc: 0.3878\n",
            "Lowest val_loss: 1.3109, at epoch 7\n",
            "GRU 60 2 [60]\n",
            "Epoch 0: train_loss: 1.5742 train_acc: 0.2595 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2647 | val_loss: 1.5852 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5501 train_acc: 0.2914 | val_loss: 1.4818 val_acc: 0.3451\n",
            "Epoch 3: train_loss: 1.3132 train_acc: 0.4070 | val_loss: 1.3295 val_acc: 0.4142\n",
            "Epoch 4: train_loss: 1.2374 train_acc: 0.4416 | val_loss: 1.3364 val_acc: 0.4051\n",
            "Epoch 5: train_loss: 1.1949 train_acc: 0.4669 | val_loss: 1.3560 val_acc: 0.4015\n",
            "Epoch 6: train_loss: 1.1702 train_acc: 0.4801 | val_loss: 1.3032 val_acc: 0.4242\n",
            "Epoch 7: train_loss: 1.1433 train_acc: 0.4919 | val_loss: 1.3310 val_acc: 0.4214\n",
            "Epoch 8: train_loss: 1.1167 train_acc: 0.5040 | val_loss: 1.3232 val_acc: 0.4214\n",
            "Epoch 9: train_loss: 1.0923 train_acc: 0.5235 | val_loss: 1.3157 val_acc: 0.4251\n",
            "Epoch 10: train_loss: 1.0630 train_acc: 0.5385 | val_loss: 1.3211 val_acc: 0.4296\n",
            "Epoch 11: train_loss: 1.0301 train_acc: 0.5586 | val_loss: 1.4041 val_acc: 0.4087\n",
            "Epoch 12: train_loss: 0.9987 train_acc: 0.5688 | val_loss: 1.3783 val_acc: 0.4196\n",
            "Epoch 13: train_loss: 0.9605 train_acc: 0.5878 | val_loss: 1.3977 val_acc: 0.4178\n",
            "Epoch 14: train_loss: 0.9224 train_acc: 0.6145 | val_loss: 1.3938 val_acc: 0.4151\n",
            "Epoch 15: train_loss: 0.8853 train_acc: 0.6342 | val_loss: 1.4432 val_acc: 0.4269\n",
            "Epoch 16: train_loss: 0.8515 train_acc: 0.6496 | val_loss: 1.4964 val_acc: 0.4223\n",
            "Epoch 17: train_loss: 0.7983 train_acc: 0.6758 | val_loss: 1.5370 val_acc: 0.4251\n",
            "Epoch 18: train_loss: 0.7503 train_acc: 0.6986 | val_loss: 1.6095 val_acc: 0.4196\n",
            "Epoch 19: train_loss: 0.6994 train_acc: 0.7321 | val_loss: 1.6375 val_acc: 0.4069\n",
            "Epoch 20: train_loss: 0.6721 train_acc: 0.7374 | val_loss: 1.6736 val_acc: 0.4169\n",
            "Epoch 21: train_loss: 0.6230 train_acc: 0.7617 | val_loss: 1.7169 val_acc: 0.4142\n",
            "Epoch 22: train_loss: 0.5731 train_acc: 0.7863 | val_loss: 1.7730 val_acc: 0.4124\n",
            "Epoch 23: train_loss: 0.5311 train_acc: 0.8075 | val_loss: 1.9348 val_acc: 0.4024\n",
            "Epoch 24: train_loss: 0.4950 train_acc: 0.8246 | val_loss: 1.9761 val_acc: 0.4078\n",
            "Lowest val_loss: 1.3032, at epoch 6\n",
            "GRU 60 2 [70]\n",
            "Epoch 0: train_loss: 1.5711 train_acc: 0.2659 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2708 | val_loss: 1.5784 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5427 train_acc: 0.2937 | val_loss: 1.4536 val_acc: 0.3488\n",
            "Epoch 3: train_loss: 1.3514 train_acc: 0.4024 | val_loss: 1.3386 val_acc: 0.4151\n",
            "Epoch 4: train_loss: 1.2489 train_acc: 0.4398 | val_loss: 1.3146 val_acc: 0.4223\n",
            "Epoch 5: train_loss: 1.2194 train_acc: 0.4501 | val_loss: 1.3474 val_acc: 0.4251\n",
            "Epoch 6: train_loss: 1.1872 train_acc: 0.4719 | val_loss: 1.3149 val_acc: 0.4187\n",
            "Epoch 7: train_loss: 1.1730 train_acc: 0.4790 | val_loss: 1.3366 val_acc: 0.4223\n",
            "Epoch 8: train_loss: 1.1389 train_acc: 0.4931 | val_loss: 1.3377 val_acc: 0.4296\n",
            "Epoch 9: train_loss: 1.1134 train_acc: 0.5116 | val_loss: 1.3304 val_acc: 0.4296\n",
            "Epoch 10: train_loss: 1.0885 train_acc: 0.5158 | val_loss: 1.3240 val_acc: 0.4124\n",
            "Epoch 11: train_loss: 1.0511 train_acc: 0.5414 | val_loss: 1.3766 val_acc: 0.4051\n",
            "Epoch 12: train_loss: 1.0277 train_acc: 0.5524 | val_loss: 1.3717 val_acc: 0.4178\n",
            "Epoch 13: train_loss: 0.9842 train_acc: 0.5794 | val_loss: 1.4041 val_acc: 0.4214\n",
            "Epoch 14: train_loss: 0.9588 train_acc: 0.5819 | val_loss: 1.4826 val_acc: 0.4196\n",
            "Epoch 15: train_loss: 0.9136 train_acc: 0.6108 | val_loss: 1.4490 val_acc: 0.4233\n",
            "Epoch 16: train_loss: 0.8742 train_acc: 0.6364 | val_loss: 1.4789 val_acc: 0.4124\n",
            "Epoch 17: train_loss: 0.8326 train_acc: 0.6548 | val_loss: 1.5658 val_acc: 0.4242\n",
            "Epoch 18: train_loss: 0.7895 train_acc: 0.6842 | val_loss: 1.5579 val_acc: 0.4214\n",
            "Epoch 19: train_loss: 0.7470 train_acc: 0.6991 | val_loss: 1.5651 val_acc: 0.4169\n",
            "Epoch 20: train_loss: 0.6881 train_acc: 0.7341 | val_loss: 1.6694 val_acc: 0.4087\n",
            "Epoch 21: train_loss: 0.6483 train_acc: 0.7487 | val_loss: 1.7237 val_acc: 0.4087\n",
            "Epoch 22: train_loss: 0.6078 train_acc: 0.7701 | val_loss: 1.8035 val_acc: 0.4178\n",
            "Epoch 23: train_loss: 0.5615 train_acc: 0.7933 | val_loss: 1.8447 val_acc: 0.4178\n",
            "Epoch 24: train_loss: 0.5304 train_acc: 0.8042 | val_loss: 1.8420 val_acc: 0.4114\n",
            "Lowest val_loss: 1.3146, at epoch 4\n",
            "GRU 70 1 [30]\n",
            "Epoch 0: train_loss: 1.5732 train_acc: 0.2719 | val_loss: 1.5702 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2750 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5664 train_acc: 0.2673 | val_loss: 1.5535 val_acc: 0.2743\n",
            "Epoch 3: train_loss: 1.4107 train_acc: 0.3670 | val_loss: 1.3357 val_acc: 0.4069\n",
            "Epoch 4: train_loss: 1.2478 train_acc: 0.4403 | val_loss: 1.3253 val_acc: 0.3978\n",
            "Epoch 5: train_loss: 1.2092 train_acc: 0.4649 | val_loss: 1.3091 val_acc: 0.4223\n",
            "Epoch 6: train_loss: 1.1740 train_acc: 0.4800 | val_loss: 1.3409 val_acc: 0.4142\n",
            "Epoch 7: train_loss: 1.1510 train_acc: 0.4930 | val_loss: 1.3179 val_acc: 0.4169\n",
            "Epoch 8: train_loss: 1.1241 train_acc: 0.5039 | val_loss: 1.3152 val_acc: 0.4105\n",
            "Epoch 9: train_loss: 1.0906 train_acc: 0.5263 | val_loss: 1.3401 val_acc: 0.4169\n",
            "Epoch 10: train_loss: 1.0590 train_acc: 0.5434 | val_loss: 1.3671 val_acc: 0.4178\n",
            "Epoch 11: train_loss: 1.0309 train_acc: 0.5556 | val_loss: 1.3812 val_acc: 0.4169\n",
            "Epoch 12: train_loss: 0.9915 train_acc: 0.5777 | val_loss: 1.3737 val_acc: 0.4196\n",
            "Epoch 13: train_loss: 0.9554 train_acc: 0.5954 | val_loss: 1.4199 val_acc: 0.4169\n",
            "Epoch 14: train_loss: 0.9182 train_acc: 0.6154 | val_loss: 1.4107 val_acc: 0.4042\n",
            "Epoch 15: train_loss: 0.8765 train_acc: 0.6321 | val_loss: 1.5165 val_acc: 0.4133\n",
            "Epoch 16: train_loss: 0.8353 train_acc: 0.6584 | val_loss: 1.4890 val_acc: 0.4078\n",
            "Epoch 17: train_loss: 0.7883 train_acc: 0.6828 | val_loss: 1.5112 val_acc: 0.4133\n",
            "Epoch 18: train_loss: 0.7363 train_acc: 0.7136 | val_loss: 1.5852 val_acc: 0.4096\n",
            "Epoch 19: train_loss: 0.6871 train_acc: 0.7368 | val_loss: 1.6652 val_acc: 0.4069\n",
            "Epoch 20: train_loss: 0.6630 train_acc: 0.7484 | val_loss: 1.6622 val_acc: 0.4042\n",
            "Epoch 21: train_loss: 0.6072 train_acc: 0.7747 | val_loss: 1.7371 val_acc: 0.3987\n",
            "Epoch 22: train_loss: 0.5771 train_acc: 0.7910 | val_loss: 1.7587 val_acc: 0.4015\n",
            "Epoch 23: train_loss: 0.5107 train_acc: 0.8209 | val_loss: 1.8399 val_acc: 0.4024\n",
            "Epoch 24: train_loss: 0.4629 train_acc: 0.8405 | val_loss: 1.9020 val_acc: 0.3906\n",
            "Lowest val_loss: 1.3091, at epoch 5\n",
            "GRU 70 1 [40]\n",
            "Epoch 0: train_loss: 1.5718 train_acc: 0.2691 | val_loss: 1.5751 val_acc: 0.2516\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2701 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5673 train_acc: 0.2658 | val_loss: 1.5801 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2736 | val_loss: 1.5687 val_acc: 0.2489\n",
            "Epoch 4: train_loss: 1.5642 train_acc: 0.2687 | val_loss: 1.5418 val_acc: 0.2816\n",
            "Epoch 5: train_loss: 1.5587 train_acc: 0.2863 | val_loss: 1.5702 val_acc: 0.2570\n",
            "Epoch 6: train_loss: 1.5657 train_acc: 0.2834 | val_loss: 1.5645 val_acc: 0.2598\n",
            "Epoch 7: train_loss: 1.5394 train_acc: 0.3244 | val_loss: 1.4947 val_acc: 0.3342\n",
            "Epoch 8: train_loss: 1.3869 train_acc: 0.3906 | val_loss: 1.3528 val_acc: 0.4015\n",
            "Epoch 9: train_loss: 1.2830 train_acc: 0.4304 | val_loss: 1.3284 val_acc: 0.4205\n",
            "Epoch 10: train_loss: 1.2304 train_acc: 0.4498 | val_loss: 1.3039 val_acc: 0.4169\n",
            "Epoch 11: train_loss: 1.1997 train_acc: 0.4661 | val_loss: 1.3075 val_acc: 0.4287\n",
            "Epoch 12: train_loss: 1.1807 train_acc: 0.4766 | val_loss: 1.3557 val_acc: 0.4051\n",
            "Epoch 13: train_loss: 1.1488 train_acc: 0.4925 | val_loss: 1.3476 val_acc: 0.4251\n",
            "Epoch 14: train_loss: 1.1204 train_acc: 0.5084 | val_loss: 1.3370 val_acc: 0.4169\n",
            "Epoch 15: train_loss: 1.0925 train_acc: 0.5260 | val_loss: 1.3463 val_acc: 0.4242\n",
            "Epoch 16: train_loss: 1.0761 train_acc: 0.5349 | val_loss: 1.3659 val_acc: 0.4142\n",
            "Epoch 17: train_loss: 1.0299 train_acc: 0.5540 | val_loss: 1.4721 val_acc: 0.3924\n",
            "Epoch 18: train_loss: 1.0005 train_acc: 0.5706 | val_loss: 1.4274 val_acc: 0.3933\n",
            "Epoch 19: train_loss: 0.9569 train_acc: 0.5929 | val_loss: 1.4820 val_acc: 0.3996\n",
            "Epoch 20: train_loss: 0.9207 train_acc: 0.6032 | val_loss: 1.4558 val_acc: 0.4114\n",
            "Epoch 21: train_loss: 0.8776 train_acc: 0.6292 | val_loss: 1.5387 val_acc: 0.3960\n",
            "Epoch 22: train_loss: 0.8319 train_acc: 0.6520 | val_loss: 1.5950 val_acc: 0.3824\n",
            "Epoch 23: train_loss: 0.7842 train_acc: 0.6795 | val_loss: 1.5656 val_acc: 0.3906\n",
            "Epoch 24: train_loss: 0.7434 train_acc: 0.7005 | val_loss: 1.6401 val_acc: 0.3887\n",
            "Lowest val_loss: 1.3039, at epoch 10\n",
            "GRU 70 1 [50]\n",
            "Epoch 0: train_loss: 1.5734 train_acc: 0.2642 | val_loss: 1.5716 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5684 train_acc: 0.2681 | val_loss: 1.5667 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5664 train_acc: 0.2739 | val_loss: 1.5618 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.4292 train_acc: 0.3641 | val_loss: 1.4022 val_acc: 0.3887\n",
            "Epoch 4: train_loss: 1.2627 train_acc: 0.4329 | val_loss: 1.3290 val_acc: 0.3969\n",
            "Epoch 5: train_loss: 1.2077 train_acc: 0.4609 | val_loss: 1.3215 val_acc: 0.3987\n",
            "Epoch 6: train_loss: 1.1892 train_acc: 0.4733 | val_loss: 1.3121 val_acc: 0.4233\n",
            "Epoch 7: train_loss: 1.1538 train_acc: 0.4944 | val_loss: 1.3443 val_acc: 0.4251\n",
            "Epoch 8: train_loss: 1.1250 train_acc: 0.5090 | val_loss: 1.3473 val_acc: 0.4205\n",
            "Epoch 9: train_loss: 1.0887 train_acc: 0.5265 | val_loss: 1.3650 val_acc: 0.4223\n",
            "Epoch 10: train_loss: 1.0617 train_acc: 0.5413 | val_loss: 1.3682 val_acc: 0.4187\n",
            "Epoch 11: train_loss: 1.0250 train_acc: 0.5599 | val_loss: 1.4012 val_acc: 0.4205\n",
            "Epoch 12: train_loss: 0.9916 train_acc: 0.5700 | val_loss: 1.4075 val_acc: 0.4205\n",
            "Epoch 13: train_loss: 0.9522 train_acc: 0.5975 | val_loss: 1.4200 val_acc: 0.4133\n",
            "Epoch 14: train_loss: 0.9154 train_acc: 0.6152 | val_loss: 1.4148 val_acc: 0.4205\n",
            "Epoch 15: train_loss: 0.8772 train_acc: 0.6357 | val_loss: 1.5229 val_acc: 0.4114\n",
            "Epoch 16: train_loss: 0.8269 train_acc: 0.6607 | val_loss: 1.4800 val_acc: 0.4042\n",
            "Epoch 17: train_loss: 0.7789 train_acc: 0.6824 | val_loss: 1.5583 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 0.7343 train_acc: 0.7128 | val_loss: 1.6318 val_acc: 0.4060\n",
            "Epoch 19: train_loss: 0.6885 train_acc: 0.7330 | val_loss: 1.7287 val_acc: 0.3860\n",
            "Epoch 20: train_loss: 0.6472 train_acc: 0.7528 | val_loss: 1.7729 val_acc: 0.3851\n",
            "Epoch 21: train_loss: 0.5947 train_acc: 0.7807 | val_loss: 1.7868 val_acc: 0.3833\n",
            "Epoch 22: train_loss: 0.5399 train_acc: 0.8017 | val_loss: 1.8026 val_acc: 0.3851\n",
            "Epoch 23: train_loss: 0.4888 train_acc: 0.8297 | val_loss: 1.8743 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 0.4506 train_acc: 0.8467 | val_loss: 1.9832 val_acc: 0.3787\n",
            "Lowest val_loss: 1.3121, at epoch 6\n",
            "GRU 70 1 [60]\n",
            "Epoch 0: train_loss: 1.5730 train_acc: 0.2690 | val_loss: 1.5812 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2686 | val_loss: 1.5672 val_acc: 0.2598\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2659 | val_loss: 1.5596 val_acc: 0.2688\n",
            "Epoch 3: train_loss: 1.5002 train_acc: 0.3335 | val_loss: 1.3954 val_acc: 0.3878\n",
            "Epoch 4: train_loss: 1.3225 train_acc: 0.4101 | val_loss: 1.3097 val_acc: 0.4196\n",
            "Epoch 5: train_loss: 1.2487 train_acc: 0.4395 | val_loss: 1.3163 val_acc: 0.4042\n",
            "Epoch 6: train_loss: 1.2071 train_acc: 0.4618 | val_loss: 1.2905 val_acc: 0.4314\n",
            "Epoch 7: train_loss: 1.1779 train_acc: 0.4733 | val_loss: 1.3291 val_acc: 0.4096\n",
            "Epoch 8: train_loss: 1.1492 train_acc: 0.4897 | val_loss: 1.3124 val_acc: 0.4287\n",
            "Epoch 9: train_loss: 1.1183 train_acc: 0.5115 | val_loss: 1.3431 val_acc: 0.4205\n",
            "Epoch 10: train_loss: 1.0883 train_acc: 0.5256 | val_loss: 1.3093 val_acc: 0.4342\n",
            "Epoch 11: train_loss: 1.0590 train_acc: 0.5391 | val_loss: 1.3244 val_acc: 0.4287\n",
            "Epoch 12: train_loss: 1.0168 train_acc: 0.5619 | val_loss: 1.3580 val_acc: 0.4287\n",
            "Epoch 13: train_loss: 0.9800 train_acc: 0.5787 | val_loss: 1.3496 val_acc: 0.4314\n",
            "Epoch 14: train_loss: 0.9453 train_acc: 0.5973 | val_loss: 1.4434 val_acc: 0.4142\n",
            "Epoch 15: train_loss: 0.9059 train_acc: 0.6242 | val_loss: 1.3945 val_acc: 0.4251\n",
            "Epoch 16: train_loss: 0.8559 train_acc: 0.6449 | val_loss: 1.4579 val_acc: 0.4151\n",
            "Epoch 17: train_loss: 0.8232 train_acc: 0.6561 | val_loss: 1.4918 val_acc: 0.4005\n",
            "Epoch 18: train_loss: 0.7781 train_acc: 0.6862 | val_loss: 1.5090 val_acc: 0.4142\n",
            "Epoch 19: train_loss: 0.7329 train_acc: 0.7063 | val_loss: 1.6356 val_acc: 0.3951\n",
            "Epoch 20: train_loss: 0.6949 train_acc: 0.7269 | val_loss: 1.6244 val_acc: 0.4042\n",
            "Epoch 21: train_loss: 0.6376 train_acc: 0.7516 | val_loss: 1.6550 val_acc: 0.4114\n",
            "Epoch 22: train_loss: 0.5923 train_acc: 0.7741 | val_loss: 1.7218 val_acc: 0.3887\n",
            "Epoch 23: train_loss: 0.5423 train_acc: 0.7973 | val_loss: 1.7440 val_acc: 0.4151\n",
            "Epoch 24: train_loss: 0.5073 train_acc: 0.8121 | val_loss: 1.8247 val_acc: 0.3996\n",
            "Lowest val_loss: 1.2905, at epoch 6\n",
            "GRU 70 1 [70]\n",
            "Epoch 0: train_loss: 1.5728 train_acc: 0.2678 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2719 | val_loss: 1.5718 val_acc: 0.2561\n",
            "Epoch 2: train_loss: 1.5667 train_acc: 0.2733 | val_loss: 1.5660 val_acc: 0.2870\n",
            "Epoch 3: train_loss: 1.5023 train_acc: 0.3265 | val_loss: 1.3761 val_acc: 0.3951\n",
            "Epoch 4: train_loss: 1.2868 train_acc: 0.4284 | val_loss: 1.3233 val_acc: 0.4169\n",
            "Epoch 5: train_loss: 1.2157 train_acc: 0.4611 | val_loss: 1.3103 val_acc: 0.4296\n",
            "Epoch 6: train_loss: 1.1836 train_acc: 0.4750 | val_loss: 1.3188 val_acc: 0.4233\n",
            "Epoch 7: train_loss: 1.1565 train_acc: 0.4860 | val_loss: 1.3529 val_acc: 0.4015\n",
            "Epoch 8: train_loss: 1.1238 train_acc: 0.5064 | val_loss: 1.3367 val_acc: 0.4251\n",
            "Epoch 9: train_loss: 1.0910 train_acc: 0.5262 | val_loss: 1.3534 val_acc: 0.3996\n",
            "Epoch 10: train_loss: 1.0640 train_acc: 0.5371 | val_loss: 1.3723 val_acc: 0.4078\n",
            "Epoch 11: train_loss: 1.0265 train_acc: 0.5550 | val_loss: 1.4311 val_acc: 0.4033\n",
            "Epoch 12: train_loss: 0.9964 train_acc: 0.5687 | val_loss: 1.4125 val_acc: 0.4133\n",
            "Epoch 13: train_loss: 0.9495 train_acc: 0.5913 | val_loss: 1.4541 val_acc: 0.4042\n",
            "Epoch 14: train_loss: 0.9197 train_acc: 0.6145 | val_loss: 1.5010 val_acc: 0.3915\n",
            "Epoch 15: train_loss: 0.8682 train_acc: 0.6417 | val_loss: 1.6281 val_acc: 0.3915\n",
            "Epoch 16: train_loss: 0.8308 train_acc: 0.6539 | val_loss: 1.5639 val_acc: 0.3996\n",
            "Epoch 17: train_loss: 0.7672 train_acc: 0.6852 | val_loss: 1.6515 val_acc: 0.3951\n",
            "Epoch 18: train_loss: 0.7246 train_acc: 0.7060 | val_loss: 1.6891 val_acc: 0.3915\n",
            "Epoch 19: train_loss: 0.6572 train_acc: 0.7474 | val_loss: 1.8072 val_acc: 0.3815\n",
            "Epoch 20: train_loss: 0.6128 train_acc: 0.7683 | val_loss: 1.8516 val_acc: 0.3942\n",
            "Epoch 21: train_loss: 0.5623 train_acc: 0.7928 | val_loss: 1.9708 val_acc: 0.3951\n",
            "Epoch 22: train_loss: 0.5125 train_acc: 0.8114 | val_loss: 2.0057 val_acc: 0.3833\n",
            "Epoch 23: train_loss: 0.4649 train_acc: 0.8326 | val_loss: 2.1336 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 0.4416 train_acc: 0.8408 | val_loss: 2.2000 val_acc: 0.3806\n",
            "Lowest val_loss: 1.3103, at epoch 5\n",
            "GRU 70 2 [30]\n",
            "Epoch 0: train_loss: 1.5769 train_acc: 0.2585 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2700 | val_loss: 1.5710 val_acc: 0.2552\n",
            "Epoch 2: train_loss: 1.4789 train_acc: 0.3461 | val_loss: 1.3664 val_acc: 0.3778\n",
            "Epoch 3: train_loss: 1.2672 train_acc: 0.4382 | val_loss: 1.3675 val_acc: 0.3969\n",
            "Epoch 4: train_loss: 1.2141 train_acc: 0.4582 | val_loss: 1.3509 val_acc: 0.4078\n",
            "Epoch 5: train_loss: 1.1812 train_acc: 0.4831 | val_loss: 1.3074 val_acc: 0.4287\n",
            "Epoch 6: train_loss: 1.1499 train_acc: 0.4978 | val_loss: 1.3494 val_acc: 0.4087\n",
            "Epoch 7: train_loss: 1.1171 train_acc: 0.5143 | val_loss: 1.3345 val_acc: 0.4105\n",
            "Epoch 8: train_loss: 1.0958 train_acc: 0.5242 | val_loss: 1.3476 val_acc: 0.4060\n",
            "Epoch 9: train_loss: 1.0568 train_acc: 0.5459 | val_loss: 1.3409 val_acc: 0.3996\n",
            "Epoch 10: train_loss: 1.0264 train_acc: 0.5609 | val_loss: 1.3842 val_acc: 0.4078\n",
            "Epoch 11: train_loss: 0.9850 train_acc: 0.5853 | val_loss: 1.3755 val_acc: 0.3951\n",
            "Epoch 12: train_loss: 0.9508 train_acc: 0.6011 | val_loss: 1.3589 val_acc: 0.4251\n",
            "Epoch 13: train_loss: 0.9112 train_acc: 0.6243 | val_loss: 1.3829 val_acc: 0.4124\n",
            "Epoch 14: train_loss: 0.8728 train_acc: 0.6440 | val_loss: 1.4296 val_acc: 0.4042\n",
            "Epoch 15: train_loss: 0.8290 train_acc: 0.6690 | val_loss: 1.5035 val_acc: 0.4051\n",
            "Epoch 16: train_loss: 0.7717 train_acc: 0.6974 | val_loss: 1.5268 val_acc: 0.4124\n",
            "Epoch 17: train_loss: 0.7151 train_acc: 0.7247 | val_loss: 1.5906 val_acc: 0.4096\n",
            "Epoch 18: train_loss: 0.6609 train_acc: 0.7507 | val_loss: 1.6414 val_acc: 0.4051\n",
            "Epoch 19: train_loss: 0.6141 train_acc: 0.7752 | val_loss: 1.6654 val_acc: 0.3960\n",
            "Epoch 20: train_loss: 0.5632 train_acc: 0.7956 | val_loss: 1.6783 val_acc: 0.3978\n",
            "Epoch 21: train_loss: 0.5249 train_acc: 0.8109 | val_loss: 1.7985 val_acc: 0.4105\n",
            "Epoch 22: train_loss: 0.4707 train_acc: 0.8378 | val_loss: 1.8795 val_acc: 0.4033\n",
            "Epoch 23: train_loss: 0.4447 train_acc: 0.8433 | val_loss: 1.9103 val_acc: 0.3969\n",
            "Epoch 24: train_loss: 0.4071 train_acc: 0.8646 | val_loss: 2.0270 val_acc: 0.3887\n",
            "Lowest val_loss: 1.3074, at epoch 5\n",
            "GRU 70 2 [40]\n",
            "Epoch 0: train_loss: 1.5736 train_acc: 0.2638 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5694 train_acc: 0.2718 | val_loss: 1.5765 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5690 train_acc: 0.2728 | val_loss: 1.5704 val_acc: 0.2616\n",
            "Epoch 3: train_loss: 1.5397 train_acc: 0.3123 | val_loss: 1.5563 val_acc: 0.2307\n",
            "Epoch 4: train_loss: 1.5265 train_acc: 0.3242 | val_loss: 1.5460 val_acc: 0.2997\n",
            "Epoch 5: train_loss: 1.5036 train_acc: 0.3397 | val_loss: 1.4820 val_acc: 0.3460\n",
            "Epoch 6: train_loss: 1.4846 train_acc: 0.3429 | val_loss: 1.4840 val_acc: 0.3288\n",
            "Epoch 7: train_loss: 1.4107 train_acc: 0.3799 | val_loss: 1.4224 val_acc: 0.3560\n",
            "Epoch 8: train_loss: 1.3591 train_acc: 0.3941 | val_loss: 1.3874 val_acc: 0.3751\n",
            "Epoch 9: train_loss: 1.2824 train_acc: 0.4233 | val_loss: 1.3603 val_acc: 0.3915\n",
            "Epoch 10: train_loss: 1.2417 train_acc: 0.4453 | val_loss: 1.3733 val_acc: 0.3915\n",
            "Epoch 11: train_loss: 1.2125 train_acc: 0.4588 | val_loss: 1.3195 val_acc: 0.4242\n",
            "Epoch 12: train_loss: 1.1910 train_acc: 0.4691 | val_loss: 1.3519 val_acc: 0.4033\n",
            "Epoch 13: train_loss: 1.1688 train_acc: 0.4806 | val_loss: 1.3314 val_acc: 0.4196\n",
            "Epoch 14: train_loss: 1.1362 train_acc: 0.5018 | val_loss: 1.3078 val_acc: 0.4260\n",
            "Epoch 15: train_loss: 1.1102 train_acc: 0.5111 | val_loss: 1.3618 val_acc: 0.3978\n",
            "Epoch 16: train_loss: 1.0774 train_acc: 0.5311 | val_loss: 1.3457 val_acc: 0.4087\n",
            "Epoch 17: train_loss: 1.0499 train_acc: 0.5453 | val_loss: 1.3559 val_acc: 0.4060\n",
            "Epoch 18: train_loss: 1.0124 train_acc: 0.5595 | val_loss: 1.4040 val_acc: 0.4024\n",
            "Epoch 19: train_loss: 0.9788 train_acc: 0.5775 | val_loss: 1.3915 val_acc: 0.4251\n",
            "Epoch 20: train_loss: 0.9402 train_acc: 0.6007 | val_loss: 1.4360 val_acc: 0.4169\n",
            "Epoch 21: train_loss: 0.8971 train_acc: 0.6203 | val_loss: 1.4223 val_acc: 0.4124\n",
            "Epoch 22: train_loss: 0.8574 train_acc: 0.6365 | val_loss: 1.5170 val_acc: 0.3987\n",
            "Epoch 23: train_loss: 0.8029 train_acc: 0.6692 | val_loss: 1.6062 val_acc: 0.3833\n",
            "Epoch 24: train_loss: 0.7579 train_acc: 0.6962 | val_loss: 1.6053 val_acc: 0.3960\n",
            "Lowest val_loss: 1.3078, at epoch 14\n",
            "GRU 70 2 [50]\n",
            "Epoch 0: train_loss: 1.5723 train_acc: 0.2690 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2724 | val_loss: 1.5708 val_acc: 0.2634\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2680 | val_loss: 1.5695 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5250 train_acc: 0.3090 | val_loss: 1.4097 val_acc: 0.3842\n",
            "Epoch 4: train_loss: 1.3213 train_acc: 0.4130 | val_loss: 1.3339 val_acc: 0.3969\n",
            "Epoch 5: train_loss: 1.2460 train_acc: 0.4442 | val_loss: 1.3184 val_acc: 0.4169\n",
            "Epoch 6: train_loss: 1.1967 train_acc: 0.4649 | val_loss: 1.3262 val_acc: 0.4242\n",
            "Epoch 7: train_loss: 1.1665 train_acc: 0.4857 | val_loss: 1.3332 val_acc: 0.4441\n",
            "Epoch 8: train_loss: 1.1422 train_acc: 0.4946 | val_loss: 1.3319 val_acc: 0.4196\n",
            "Epoch 9: train_loss: 1.1025 train_acc: 0.5169 | val_loss: 1.3876 val_acc: 0.4051\n",
            "Epoch 10: train_loss: 1.0756 train_acc: 0.5321 | val_loss: 1.3582 val_acc: 0.4214\n",
            "Epoch 11: train_loss: 1.0337 train_acc: 0.5545 | val_loss: 1.4150 val_acc: 0.4205\n",
            "Epoch 12: train_loss: 1.0063 train_acc: 0.5633 | val_loss: 1.4237 val_acc: 0.4260\n",
            "Epoch 13: train_loss: 0.9576 train_acc: 0.5867 | val_loss: 1.4424 val_acc: 0.4087\n",
            "Epoch 14: train_loss: 0.9102 train_acc: 0.6168 | val_loss: 1.4355 val_acc: 0.4269\n",
            "Epoch 15: train_loss: 0.8606 train_acc: 0.6353 | val_loss: 1.5260 val_acc: 0.4096\n",
            "Epoch 16: train_loss: 0.8038 train_acc: 0.6673 | val_loss: 1.5870 val_acc: 0.3960\n",
            "Epoch 17: train_loss: 0.7507 train_acc: 0.6893 | val_loss: 1.6331 val_acc: 0.4015\n",
            "Epoch 18: train_loss: 0.6972 train_acc: 0.7202 | val_loss: 1.6588 val_acc: 0.4060\n",
            "Epoch 19: train_loss: 0.6358 train_acc: 0.7475 | val_loss: 1.7681 val_acc: 0.4133\n",
            "Epoch 20: train_loss: 0.5744 train_acc: 0.7798 | val_loss: 1.8704 val_acc: 0.4051\n",
            "Epoch 21: train_loss: 0.5364 train_acc: 0.7951 | val_loss: 1.8944 val_acc: 0.3969\n",
            "Epoch 22: train_loss: 0.4932 train_acc: 0.8176 | val_loss: 1.9927 val_acc: 0.4196\n",
            "Epoch 23: train_loss: 0.4323 train_acc: 0.8413 | val_loss: 2.1215 val_acc: 0.4078\n",
            "Epoch 24: train_loss: 0.4103 train_acc: 0.8525 | val_loss: 2.1244 val_acc: 0.4024\n",
            "Lowest val_loss: 1.3184, at epoch 5\n",
            "GRU 70 2 [60]\n",
            "Epoch 0: train_loss: 1.5728 train_acc: 0.2625 | val_loss: 1.5767 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2657 | val_loss: 1.5732 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5474 train_acc: 0.3058 | val_loss: 1.5550 val_acc: 0.3052\n",
            "Epoch 3: train_loss: 1.4321 train_acc: 0.3752 | val_loss: 1.3701 val_acc: 0.3842\n",
            "Epoch 4: train_loss: 1.2994 train_acc: 0.4177 | val_loss: 1.3462 val_acc: 0.3833\n",
            "Epoch 5: train_loss: 1.2467 train_acc: 0.4408 | val_loss: 1.3255 val_acc: 0.4087\n",
            "Epoch 6: train_loss: 1.2124 train_acc: 0.4589 | val_loss: 1.3626 val_acc: 0.3942\n",
            "Epoch 7: train_loss: 1.1869 train_acc: 0.4684 | val_loss: 1.3332 val_acc: 0.4005\n",
            "Epoch 8: train_loss: 1.1572 train_acc: 0.4881 | val_loss: 1.3353 val_acc: 0.4296\n",
            "Epoch 9: train_loss: 1.1344 train_acc: 0.4982 | val_loss: 1.3254 val_acc: 0.4251\n",
            "Epoch 10: train_loss: 1.1082 train_acc: 0.5140 | val_loss: 1.3636 val_acc: 0.4251\n",
            "Epoch 11: train_loss: 1.0804 train_acc: 0.5254 | val_loss: 1.3554 val_acc: 0.4214\n",
            "Epoch 12: train_loss: 1.0382 train_acc: 0.5531 | val_loss: 1.4145 val_acc: 0.4169\n",
            "Epoch 13: train_loss: 1.0168 train_acc: 0.5574 | val_loss: 1.3745 val_acc: 0.4296\n",
            "Epoch 14: train_loss: 0.9724 train_acc: 0.5845 | val_loss: 1.3843 val_acc: 0.4287\n",
            "Epoch 15: train_loss: 0.9342 train_acc: 0.6040 | val_loss: 1.4062 val_acc: 0.4323\n",
            "Epoch 16: train_loss: 0.8957 train_acc: 0.6228 | val_loss: 1.4595 val_acc: 0.4296\n",
            "Epoch 17: train_loss: 0.8591 train_acc: 0.6419 | val_loss: 1.4741 val_acc: 0.4187\n",
            "Epoch 18: train_loss: 0.7990 train_acc: 0.6743 | val_loss: 1.5515 val_acc: 0.4287\n",
            "Epoch 19: train_loss: 0.7498 train_acc: 0.6955 | val_loss: 1.6205 val_acc: 0.4214\n",
            "Epoch 20: train_loss: 0.7083 train_acc: 0.7128 | val_loss: 1.7439 val_acc: 0.3951\n",
            "Epoch 21: train_loss: 0.6707 train_acc: 0.7343 | val_loss: 1.6950 val_acc: 0.4105\n",
            "Epoch 22: train_loss: 0.6149 train_acc: 0.7588 | val_loss: 1.7762 val_acc: 0.3960\n",
            "Epoch 23: train_loss: 0.5804 train_acc: 0.7782 | val_loss: 1.6923 val_acc: 0.4133\n",
            "Epoch 24: train_loss: 0.5205 train_acc: 0.8066 | val_loss: 1.8888 val_acc: 0.3906\n",
            "Lowest val_loss: 1.3254, at epoch 9\n",
            "GRU 70 2 [70]\n",
            "Epoch 0: train_loss: 1.5715 train_acc: 0.2649 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2671 | val_loss: 1.5695 val_acc: 0.2543\n",
            "Epoch 2: train_loss: 1.4988 train_acc: 0.3283 | val_loss: 1.3784 val_acc: 0.4033\n",
            "Epoch 3: train_loss: 1.3015 train_acc: 0.4218 | val_loss: 1.3342 val_acc: 0.4114\n",
            "Epoch 4: train_loss: 1.2394 train_acc: 0.4408 | val_loss: 1.3568 val_acc: 0.4096\n",
            "Epoch 5: train_loss: 1.2086 train_acc: 0.4565 | val_loss: 1.3495 val_acc: 0.4105\n",
            "Epoch 6: train_loss: 1.1797 train_acc: 0.4752 | val_loss: 1.3248 val_acc: 0.4214\n",
            "Epoch 7: train_loss: 1.1651 train_acc: 0.4835 | val_loss: 1.3119 val_acc: 0.4278\n",
            "Epoch 8: train_loss: 1.1340 train_acc: 0.4999 | val_loss: 1.3332 val_acc: 0.4196\n",
            "Epoch 9: train_loss: 1.1057 train_acc: 0.5131 | val_loss: 1.3296 val_acc: 0.4260\n",
            "Epoch 10: train_loss: 1.0729 train_acc: 0.5314 | val_loss: 1.3489 val_acc: 0.4160\n",
            "Epoch 11: train_loss: 1.0428 train_acc: 0.5405 | val_loss: 1.3545 val_acc: 0.4169\n",
            "Epoch 12: train_loss: 1.0008 train_acc: 0.5694 | val_loss: 1.4147 val_acc: 0.4178\n",
            "Epoch 13: train_loss: 0.9699 train_acc: 0.5845 | val_loss: 1.3804 val_acc: 0.4233\n",
            "Epoch 14: train_loss: 0.9223 train_acc: 0.6133 | val_loss: 1.3921 val_acc: 0.4223\n",
            "Epoch 15: train_loss: 0.8719 train_acc: 0.6376 | val_loss: 1.4765 val_acc: 0.4269\n",
            "Epoch 16: train_loss: 0.8311 train_acc: 0.6570 | val_loss: 1.4851 val_acc: 0.4242\n",
            "Epoch 17: train_loss: 0.7725 train_acc: 0.6910 | val_loss: 1.5139 val_acc: 0.4205\n",
            "Epoch 18: train_loss: 0.7256 train_acc: 0.7115 | val_loss: 1.5579 val_acc: 0.4196\n",
            "Epoch 19: train_loss: 0.6759 train_acc: 0.7365 | val_loss: 1.6750 val_acc: 0.4105\n",
            "Epoch 20: train_loss: 0.6245 train_acc: 0.7578 | val_loss: 1.7023 val_acc: 0.4242\n",
            "Epoch 21: train_loss: 0.5729 train_acc: 0.7832 | val_loss: 1.8159 val_acc: 0.4196\n",
            "Epoch 22: train_loss: 0.5216 train_acc: 0.8099 | val_loss: 1.8686 val_acc: 0.4178\n",
            "Epoch 23: train_loss: 0.4880 train_acc: 0.8189 | val_loss: 1.9063 val_acc: 0.4178\n",
            "Epoch 24: train_loss: 0.4322 train_acc: 0.8496 | val_loss: 2.0035 val_acc: 0.4087\n",
            "Lowest val_loss: 1.3119, at epoch 7\n",
            "GRU 80 1 [30]\n",
            "Epoch 0: train_loss: 1.5770 train_acc: 0.2619 | val_loss: 1.5750 val_acc: 0.2679\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2694 | val_loss: 1.5669 val_acc: 0.2625\n",
            "Epoch 2: train_loss: 1.5678 train_acc: 0.2664 | val_loss: 1.5598 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5598 train_acc: 0.2762 | val_loss: 1.4879 val_acc: 0.3470\n",
            "Epoch 4: train_loss: 1.3695 train_acc: 0.3920 | val_loss: 1.3307 val_acc: 0.4196\n",
            "Epoch 5: train_loss: 1.2468 train_acc: 0.4424 | val_loss: 1.2962 val_acc: 0.4278\n",
            "Epoch 6: train_loss: 1.1945 train_acc: 0.4732 | val_loss: 1.3053 val_acc: 0.4260\n",
            "Epoch 7: train_loss: 1.1656 train_acc: 0.4881 | val_loss: 1.2993 val_acc: 0.4323\n",
            "Epoch 8: train_loss: 1.1321 train_acc: 0.5074 | val_loss: 1.3392 val_acc: 0.4151\n",
            "Epoch 9: train_loss: 1.1070 train_acc: 0.5195 | val_loss: 1.3186 val_acc: 0.4187\n",
            "Epoch 10: train_loss: 1.0710 train_acc: 0.5372 | val_loss: 1.3343 val_acc: 0.4133\n",
            "Epoch 11: train_loss: 1.0299 train_acc: 0.5610 | val_loss: 1.3617 val_acc: 0.4060\n",
            "Epoch 12: train_loss: 0.9998 train_acc: 0.5717 | val_loss: 1.3581 val_acc: 0.4060\n",
            "Epoch 13: train_loss: 0.9477 train_acc: 0.6035 | val_loss: 1.3918 val_acc: 0.4069\n",
            "Epoch 14: train_loss: 0.9075 train_acc: 0.6246 | val_loss: 1.3968 val_acc: 0.3987\n",
            "Epoch 15: train_loss: 0.8659 train_acc: 0.6433 | val_loss: 1.4355 val_acc: 0.3933\n",
            "Epoch 16: train_loss: 0.8158 train_acc: 0.6647 | val_loss: 1.4831 val_acc: 0.4033\n",
            "Epoch 17: train_loss: 0.7563 train_acc: 0.7005 | val_loss: 1.5093 val_acc: 0.3978\n",
            "Epoch 18: train_loss: 0.6962 train_acc: 0.7274 | val_loss: 1.5617 val_acc: 0.4087\n",
            "Epoch 19: train_loss: 0.6486 train_acc: 0.7541 | val_loss: 1.6233 val_acc: 0.3978\n",
            "Epoch 20: train_loss: 0.5889 train_acc: 0.7811 | val_loss: 1.6990 val_acc: 0.3951\n",
            "Epoch 21: train_loss: 0.5384 train_acc: 0.8002 | val_loss: 1.7654 val_acc: 0.3878\n",
            "Epoch 22: train_loss: 0.4849 train_acc: 0.8249 | val_loss: 1.8175 val_acc: 0.3906\n",
            "Epoch 23: train_loss: 0.4453 train_acc: 0.8402 | val_loss: 1.8634 val_acc: 0.3806\n",
            "Epoch 24: train_loss: 0.4010 train_acc: 0.8599 | val_loss: 1.9281 val_acc: 0.3887\n",
            "Lowest val_loss: 1.2962, at epoch 5\n",
            "GRU 80 1 [40]\n",
            "Epoch 0: train_loss: 1.5753 train_acc: 0.2631 | val_loss: 1.5818 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2683 | val_loss: 1.5720 val_acc: 0.2480\n",
            "Epoch 2: train_loss: 1.5667 train_acc: 0.2711 | val_loss: 1.5646 val_acc: 0.2652\n",
            "Epoch 3: train_loss: 1.5658 train_acc: 0.2673 | val_loss: 1.6146 val_acc: 0.2598\n",
            "Epoch 4: train_loss: 1.4036 train_acc: 0.3782 | val_loss: 1.3642 val_acc: 0.3851\n",
            "Epoch 5: train_loss: 1.2422 train_acc: 0.4434 | val_loss: 1.3028 val_acc: 0.4142\n",
            "Epoch 6: train_loss: 1.1903 train_acc: 0.4757 | val_loss: 1.3257 val_acc: 0.3960\n",
            "Epoch 7: train_loss: 1.1574 train_acc: 0.4853 | val_loss: 1.3103 val_acc: 0.4169\n",
            "Epoch 8: train_loss: 1.1231 train_acc: 0.5030 | val_loss: 1.3727 val_acc: 0.4015\n",
            "Epoch 9: train_loss: 1.0842 train_acc: 0.5241 | val_loss: 1.3565 val_acc: 0.4051\n",
            "Epoch 10: train_loss: 1.0588 train_acc: 0.5382 | val_loss: 1.4098 val_acc: 0.3860\n",
            "Epoch 11: train_loss: 1.0103 train_acc: 0.5644 | val_loss: 1.4111 val_acc: 0.4069\n",
            "Epoch 12: train_loss: 0.9710 train_acc: 0.5854 | val_loss: 1.4565 val_acc: 0.3987\n",
            "Epoch 13: train_loss: 0.9239 train_acc: 0.6081 | val_loss: 1.4897 val_acc: 0.3969\n",
            "Epoch 14: train_loss: 0.8793 train_acc: 0.6311 | val_loss: 1.4844 val_acc: 0.3924\n",
            "Epoch 15: train_loss: 0.8310 train_acc: 0.6565 | val_loss: 1.5962 val_acc: 0.3797\n",
            "Epoch 16: train_loss: 0.7751 train_acc: 0.6808 | val_loss: 1.6279 val_acc: 0.4015\n",
            "Epoch 17: train_loss: 0.7229 train_acc: 0.7083 | val_loss: 1.6970 val_acc: 0.3869\n",
            "Epoch 18: train_loss: 0.6698 train_acc: 0.7358 | val_loss: 1.7259 val_acc: 0.3878\n",
            "Epoch 19: train_loss: 0.6063 train_acc: 0.7699 | val_loss: 1.8415 val_acc: 0.3787\n",
            "Epoch 20: train_loss: 0.5513 train_acc: 0.7972 | val_loss: 1.9288 val_acc: 0.3815\n",
            "Epoch 21: train_loss: 0.4891 train_acc: 0.8233 | val_loss: 2.0469 val_acc: 0.3751\n",
            "Epoch 22: train_loss: 0.4409 train_acc: 0.8415 | val_loss: 2.1588 val_acc: 0.3824\n",
            "Epoch 23: train_loss: 0.3981 train_acc: 0.8629 | val_loss: 2.2077 val_acc: 0.3678\n",
            "Epoch 24: train_loss: 0.3660 train_acc: 0.8763 | val_loss: 2.2043 val_acc: 0.3606\n",
            "Lowest val_loss: 1.3028, at epoch 5\n",
            "GRU 80 1 [50]\n",
            "Epoch 0: train_loss: 1.5758 train_acc: 0.2680 | val_loss: 1.5716 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2726 | val_loss: 1.5689 val_acc: 0.2643\n",
            "Epoch 2: train_loss: 1.5672 train_acc: 0.2683 | val_loss: 1.5676 val_acc: 0.2598\n",
            "Epoch 3: train_loss: 1.5482 train_acc: 0.2972 | val_loss: 1.5063 val_acc: 0.3351\n",
            "Epoch 4: train_loss: 1.3597 train_acc: 0.3985 | val_loss: 1.3349 val_acc: 0.4105\n",
            "Epoch 5: train_loss: 1.2652 train_acc: 0.4397 | val_loss: 1.3473 val_acc: 0.4087\n",
            "Epoch 6: train_loss: 1.2183 train_acc: 0.4556 | val_loss: 1.3364 val_acc: 0.4196\n",
            "Epoch 7: train_loss: 1.1811 train_acc: 0.4789 | val_loss: 1.3380 val_acc: 0.4178\n",
            "Epoch 8: train_loss: 1.1489 train_acc: 0.4950 | val_loss: 1.3320 val_acc: 0.4223\n",
            "Epoch 9: train_loss: 1.1171 train_acc: 0.5140 | val_loss: 1.3379 val_acc: 0.4124\n",
            "Epoch 10: train_loss: 1.0871 train_acc: 0.5274 | val_loss: 1.3552 val_acc: 0.4214\n",
            "Epoch 11: train_loss: 1.0458 train_acc: 0.5468 | val_loss: 1.3779 val_acc: 0.4096\n",
            "Epoch 12: train_loss: 1.0141 train_acc: 0.5713 | val_loss: 1.4589 val_acc: 0.3978\n",
            "Epoch 13: train_loss: 0.9742 train_acc: 0.5836 | val_loss: 1.4517 val_acc: 0.4169\n",
            "Epoch 14: train_loss: 0.9231 train_acc: 0.6126 | val_loss: 1.4355 val_acc: 0.4214\n",
            "Epoch 15: train_loss: 0.8710 train_acc: 0.6374 | val_loss: 1.5441 val_acc: 0.4196\n",
            "Epoch 16: train_loss: 0.8220 train_acc: 0.6607 | val_loss: 1.5522 val_acc: 0.4369\n",
            "Epoch 17: train_loss: 0.7638 train_acc: 0.6958 | val_loss: 1.6469 val_acc: 0.4223\n",
            "Epoch 18: train_loss: 0.7089 train_acc: 0.7257 | val_loss: 1.6500 val_acc: 0.4114\n",
            "Epoch 19: train_loss: 0.6596 train_acc: 0.7500 | val_loss: 1.6986 val_acc: 0.4178\n",
            "Epoch 20: train_loss: 0.5962 train_acc: 0.7801 | val_loss: 1.7151 val_acc: 0.4124\n",
            "Epoch 21: train_loss: 0.5462 train_acc: 0.8013 | val_loss: 1.7613 val_acc: 0.4096\n",
            "Epoch 22: train_loss: 0.5157 train_acc: 0.8169 | val_loss: 1.7966 val_acc: 0.4105\n",
            "Epoch 23: train_loss: 0.4704 train_acc: 0.8344 | val_loss: 1.9518 val_acc: 0.4033\n",
            "Epoch 24: train_loss: 0.3988 train_acc: 0.8675 | val_loss: 1.9637 val_acc: 0.4096\n",
            "Lowest val_loss: 1.3320, at epoch 8\n",
            "GRU 80 1 [60]\n",
            "Epoch 0: train_loss: 1.5730 train_acc: 0.2611 | val_loss: 1.5801 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2692 | val_loss: 1.5704 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5657 train_acc: 0.2702 | val_loss: 1.5414 val_acc: 0.2843\n",
            "Epoch 3: train_loss: 1.3936 train_acc: 0.3864 | val_loss: 1.3324 val_acc: 0.3996\n",
            "Epoch 4: train_loss: 1.2596 train_acc: 0.4339 | val_loss: 1.3091 val_acc: 0.4078\n",
            "Epoch 5: train_loss: 1.2145 train_acc: 0.4580 | val_loss: 1.3303 val_acc: 0.3987\n",
            "Epoch 6: train_loss: 1.1872 train_acc: 0.4662 | val_loss: 1.3072 val_acc: 0.4342\n",
            "Epoch 7: train_loss: 1.1591 train_acc: 0.4848 | val_loss: 1.3120 val_acc: 0.4360\n",
            "Epoch 8: train_loss: 1.1243 train_acc: 0.5046 | val_loss: 1.3277 val_acc: 0.4278\n",
            "Epoch 9: train_loss: 1.0907 train_acc: 0.5247 | val_loss: 1.3446 val_acc: 0.4278\n",
            "Epoch 10: train_loss: 1.0550 train_acc: 0.5434 | val_loss: 1.3514 val_acc: 0.4242\n",
            "Epoch 11: train_loss: 1.0198 train_acc: 0.5613 | val_loss: 1.3707 val_acc: 0.4332\n",
            "Epoch 12: train_loss: 0.9787 train_acc: 0.5782 | val_loss: 1.4167 val_acc: 0.4314\n",
            "Epoch 13: train_loss: 0.9349 train_acc: 0.6001 | val_loss: 1.4331 val_acc: 0.4351\n",
            "Epoch 14: train_loss: 0.8911 train_acc: 0.6237 | val_loss: 1.5068 val_acc: 0.4251\n",
            "Epoch 15: train_loss: 0.8423 train_acc: 0.6505 | val_loss: 1.5177 val_acc: 0.4151\n",
            "Epoch 16: train_loss: 0.7866 train_acc: 0.6816 | val_loss: 1.5901 val_acc: 0.4124\n",
            "Epoch 17: train_loss: 0.7356 train_acc: 0.7044 | val_loss: 1.6772 val_acc: 0.4142\n",
            "Epoch 18: train_loss: 0.6761 train_acc: 0.7361 | val_loss: 1.7194 val_acc: 0.4233\n",
            "Epoch 19: train_loss: 0.6282 train_acc: 0.7608 | val_loss: 1.7783 val_acc: 0.4205\n",
            "Epoch 20: train_loss: 0.5630 train_acc: 0.7904 | val_loss: 1.8510 val_acc: 0.4114\n",
            "Epoch 21: train_loss: 0.5121 train_acc: 0.8096 | val_loss: 2.0338 val_acc: 0.3969\n",
            "Epoch 22: train_loss: 0.4707 train_acc: 0.8326 | val_loss: 2.0927 val_acc: 0.4087\n",
            "Epoch 23: train_loss: 0.4203 train_acc: 0.8497 | val_loss: 2.1642 val_acc: 0.4042\n",
            "Epoch 24: train_loss: 0.3915 train_acc: 0.8622 | val_loss: 2.1252 val_acc: 0.4005\n",
            "Lowest val_loss: 1.3072, at epoch 6\n",
            "GRU 80 1 [70]\n",
            "Epoch 0: train_loss: 1.5728 train_acc: 0.2721 | val_loss: 1.5727 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5679 train_acc: 0.2665 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5673 train_acc: 0.2699 | val_loss: 1.5672 val_acc: 0.2779\n",
            "Epoch 3: train_loss: 1.5180 train_acc: 0.3126 | val_loss: 1.3858 val_acc: 0.3778\n",
            "Epoch 4: train_loss: 1.3000 train_acc: 0.4178 | val_loss: 1.3310 val_acc: 0.4069\n",
            "Epoch 5: train_loss: 1.2310 train_acc: 0.4529 | val_loss: 1.3264 val_acc: 0.4124\n",
            "Epoch 6: train_loss: 1.1947 train_acc: 0.4737 | val_loss: 1.3034 val_acc: 0.4178\n",
            "Epoch 7: train_loss: 1.1632 train_acc: 0.4883 | val_loss: 1.3244 val_acc: 0.4178\n",
            "Epoch 8: train_loss: 1.1349 train_acc: 0.5032 | val_loss: 1.3193 val_acc: 0.4169\n",
            "Epoch 9: train_loss: 1.1148 train_acc: 0.5122 | val_loss: 1.3313 val_acc: 0.4105\n",
            "Epoch 10: train_loss: 1.0792 train_acc: 0.5310 | val_loss: 1.3816 val_acc: 0.4015\n",
            "Epoch 11: train_loss: 1.0488 train_acc: 0.5466 | val_loss: 1.4148 val_acc: 0.4169\n",
            "Epoch 12: train_loss: 1.0004 train_acc: 0.5736 | val_loss: 1.3942 val_acc: 0.4069\n",
            "Epoch 13: train_loss: 0.9629 train_acc: 0.5935 | val_loss: 1.4575 val_acc: 0.4087\n",
            "Epoch 14: train_loss: 0.9173 train_acc: 0.6230 | val_loss: 1.4252 val_acc: 0.4160\n",
            "Epoch 15: train_loss: 0.8784 train_acc: 0.6378 | val_loss: 1.4882 val_acc: 0.4069\n",
            "Epoch 16: train_loss: 0.8214 train_acc: 0.6715 | val_loss: 1.5353 val_acc: 0.4042\n",
            "Epoch 17: train_loss: 0.7761 train_acc: 0.6960 | val_loss: 1.5700 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 0.7197 train_acc: 0.7237 | val_loss: 1.6328 val_acc: 0.4005\n",
            "Epoch 19: train_loss: 0.6764 train_acc: 0.7473 | val_loss: 1.6796 val_acc: 0.4051\n",
            "Epoch 20: train_loss: 0.6146 train_acc: 0.7770 | val_loss: 1.8122 val_acc: 0.3860\n",
            "Epoch 21: train_loss: 0.5702 train_acc: 0.7980 | val_loss: 1.7914 val_acc: 0.4005\n",
            "Epoch 22: train_loss: 0.5288 train_acc: 0.8165 | val_loss: 1.8601 val_acc: 0.3942\n",
            "Epoch 23: train_loss: 0.4840 train_acc: 0.8353 | val_loss: 1.8268 val_acc: 0.4124\n",
            "Epoch 24: train_loss: 0.4415 train_acc: 0.8511 | val_loss: 1.9617 val_acc: 0.4024\n",
            "Lowest val_loss: 1.3034, at epoch 6\n",
            "GRU 80 2 [30]\n",
            "Epoch 0: train_loss: 1.5717 train_acc: 0.2690 | val_loss: 1.5767 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2718 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2706 | val_loss: 1.5766 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5672 train_acc: 0.2693 | val_loss: 1.5407 val_acc: 0.2589\n",
            "Epoch 4: train_loss: 1.4768 train_acc: 0.3572 | val_loss: 1.4213 val_acc: 0.3651\n",
            "Epoch 5: train_loss: 1.3284 train_acc: 0.4079 | val_loss: 1.3293 val_acc: 0.4160\n",
            "Epoch 6: train_loss: 1.2427 train_acc: 0.4466 | val_loss: 1.3861 val_acc: 0.3987\n",
            "Epoch 7: train_loss: 1.2010 train_acc: 0.4638 | val_loss: 1.3338 val_acc: 0.4024\n",
            "Epoch 8: train_loss: 1.1624 train_acc: 0.4903 | val_loss: 1.3375 val_acc: 0.4305\n",
            "Epoch 9: train_loss: 1.1410 train_acc: 0.4987 | val_loss: 1.3110 val_acc: 0.4260\n",
            "Epoch 10: train_loss: 1.1014 train_acc: 0.5184 | val_loss: 1.3609 val_acc: 0.4323\n",
            "Epoch 11: train_loss: 1.0616 train_acc: 0.5410 | val_loss: 1.3939 val_acc: 0.4423\n",
            "Epoch 12: train_loss: 1.0302 train_acc: 0.5612 | val_loss: 1.4370 val_acc: 0.4205\n",
            "Epoch 13: train_loss: 0.9890 train_acc: 0.5796 | val_loss: 1.3935 val_acc: 0.4323\n",
            "Epoch 14: train_loss: 0.9467 train_acc: 0.6070 | val_loss: 1.4418 val_acc: 0.4323\n",
            "Epoch 15: train_loss: 0.8986 train_acc: 0.6276 | val_loss: 1.4491 val_acc: 0.4242\n",
            "Epoch 16: train_loss: 0.8461 train_acc: 0.6516 | val_loss: 1.5292 val_acc: 0.4169\n",
            "Epoch 17: train_loss: 0.7930 train_acc: 0.6862 | val_loss: 1.5435 val_acc: 0.4223\n",
            "Epoch 18: train_loss: 0.7366 train_acc: 0.7094 | val_loss: 1.6857 val_acc: 0.4260\n",
            "Epoch 19: train_loss: 0.6878 train_acc: 0.7406 | val_loss: 1.7471 val_acc: 0.4178\n",
            "Epoch 20: train_loss: 0.6304 train_acc: 0.7664 | val_loss: 1.7774 val_acc: 0.4178\n",
            "Epoch 21: train_loss: 0.5810 train_acc: 0.7843 | val_loss: 1.8407 val_acc: 0.4178\n",
            "Epoch 22: train_loss: 0.5267 train_acc: 0.8109 | val_loss: 1.9222 val_acc: 0.4114\n",
            "Epoch 23: train_loss: 0.4785 train_acc: 0.8366 | val_loss: 1.9557 val_acc: 0.4196\n",
            "Epoch 24: train_loss: 0.4559 train_acc: 0.8399 | val_loss: 1.9660 val_acc: 0.4060\n",
            "Lowest val_loss: 1.3110, at epoch 9\n",
            "GRU 80 2 [40]\n",
            "Epoch 0: train_loss: 1.5714 train_acc: 0.2695 | val_loss: 1.5743 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2715 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5682 train_acc: 0.2688 | val_loss: 1.5726 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5613 train_acc: 0.2853 | val_loss: 1.5329 val_acc: 0.3052\n",
            "Epoch 4: train_loss: 1.3429 train_acc: 0.4003 | val_loss: 1.3286 val_acc: 0.4087\n",
            "Epoch 5: train_loss: 1.2394 train_acc: 0.4453 | val_loss: 1.3144 val_acc: 0.4233\n",
            "Epoch 6: train_loss: 1.2011 train_acc: 0.4638 | val_loss: 1.3377 val_acc: 0.4096\n",
            "Epoch 7: train_loss: 1.1591 train_acc: 0.4909 | val_loss: 1.3133 val_acc: 0.4114\n",
            "Epoch 8: train_loss: 1.1316 train_acc: 0.5015 | val_loss: 1.3320 val_acc: 0.4287\n",
            "Epoch 9: train_loss: 1.0936 train_acc: 0.5252 | val_loss: 1.3624 val_acc: 0.4124\n",
            "Epoch 10: train_loss: 1.0593 train_acc: 0.5425 | val_loss: 1.3483 val_acc: 0.4214\n",
            "Epoch 11: train_loss: 1.0207 train_acc: 0.5612 | val_loss: 1.3996 val_acc: 0.4169\n",
            "Epoch 12: train_loss: 0.9794 train_acc: 0.5839 | val_loss: 1.4455 val_acc: 0.4142\n",
            "Epoch 13: train_loss: 0.9384 train_acc: 0.6024 | val_loss: 1.4365 val_acc: 0.4078\n",
            "Epoch 14: train_loss: 0.8786 train_acc: 0.6326 | val_loss: 1.5394 val_acc: 0.3933\n",
            "Epoch 15: train_loss: 0.8328 train_acc: 0.6619 | val_loss: 1.5979 val_acc: 0.4005\n",
            "Epoch 16: train_loss: 0.7809 train_acc: 0.6864 | val_loss: 1.6281 val_acc: 0.3969\n",
            "Epoch 17: train_loss: 0.7364 train_acc: 0.7081 | val_loss: 1.7498 val_acc: 0.4060\n",
            "Epoch 18: train_loss: 0.6638 train_acc: 0.7384 | val_loss: 1.7780 val_acc: 0.3924\n",
            "Epoch 19: train_loss: 0.6054 train_acc: 0.7658 | val_loss: 1.9605 val_acc: 0.3860\n",
            "Epoch 20: train_loss: 0.5476 train_acc: 0.7968 | val_loss: 2.0415 val_acc: 0.3915\n",
            "Epoch 21: train_loss: 0.4892 train_acc: 0.8229 | val_loss: 2.1511 val_acc: 0.3887\n",
            "Epoch 22: train_loss: 0.4388 train_acc: 0.8456 | val_loss: 2.2023 val_acc: 0.4005\n",
            "Epoch 23: train_loss: 0.4128 train_acc: 0.8560 | val_loss: 2.2677 val_acc: 0.4033\n",
            "Epoch 24: train_loss: 0.3623 train_acc: 0.8741 | val_loss: 2.4683 val_acc: 0.3933\n",
            "Lowest val_loss: 1.3133, at epoch 7\n",
            "GRU 80 2 [50]\n",
            "Epoch 0: train_loss: 1.5718 train_acc: 0.2702 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2690 | val_loss: 1.5830 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2681 | val_loss: 1.5805 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5116 train_acc: 0.3353 | val_loss: 1.4731 val_acc: 0.3333\n",
            "Epoch 4: train_loss: 1.3910 train_acc: 0.3860 | val_loss: 1.3433 val_acc: 0.3960\n",
            "Epoch 5: train_loss: 1.2806 train_acc: 0.4267 | val_loss: 1.3241 val_acc: 0.4051\n",
            "Epoch 6: train_loss: 1.2368 train_acc: 0.4507 | val_loss: 1.3185 val_acc: 0.4033\n",
            "Epoch 7: train_loss: 1.1977 train_acc: 0.4658 | val_loss: 1.3210 val_acc: 0.4305\n",
            "Epoch 8: train_loss: 1.1739 train_acc: 0.4817 | val_loss: 1.3185 val_acc: 0.4205\n",
            "Epoch 9: train_loss: 1.1422 train_acc: 0.4909 | val_loss: 1.3248 val_acc: 0.4242\n",
            "Epoch 10: train_loss: 1.1226 train_acc: 0.5071 | val_loss: 1.3206 val_acc: 0.4387\n",
            "Epoch 11: train_loss: 1.0896 train_acc: 0.5241 | val_loss: 1.3435 val_acc: 0.4178\n",
            "Epoch 12: train_loss: 1.0522 train_acc: 0.5430 | val_loss: 1.3773 val_acc: 0.3960\n",
            "Epoch 13: train_loss: 1.0177 train_acc: 0.5657 | val_loss: 1.4120 val_acc: 0.4069\n",
            "Epoch 14: train_loss: 0.9825 train_acc: 0.5767 | val_loss: 1.4518 val_acc: 0.4060\n",
            "Epoch 15: train_loss: 0.9412 train_acc: 0.5961 | val_loss: 1.4651 val_acc: 0.4196\n",
            "Epoch 16: train_loss: 0.9016 train_acc: 0.6172 | val_loss: 1.5756 val_acc: 0.3842\n",
            "Epoch 17: train_loss: 0.8429 train_acc: 0.6544 | val_loss: 1.5875 val_acc: 0.4005\n",
            "Epoch 18: train_loss: 0.7996 train_acc: 0.6772 | val_loss: 1.5787 val_acc: 0.3996\n",
            "Epoch 19: train_loss: 0.7439 train_acc: 0.7014 | val_loss: 1.7984 val_acc: 0.3806\n",
            "Epoch 20: train_loss: 0.6909 train_acc: 0.7289 | val_loss: 1.8765 val_acc: 0.3942\n",
            "Epoch 21: train_loss: 0.6433 train_acc: 0.7508 | val_loss: 1.8522 val_acc: 0.3987\n",
            "Epoch 22: train_loss: 0.5926 train_acc: 0.7745 | val_loss: 1.8980 val_acc: 0.3896\n",
            "Epoch 23: train_loss: 0.5440 train_acc: 0.7983 | val_loss: 2.2193 val_acc: 0.3878\n",
            "Epoch 24: train_loss: 0.5064 train_acc: 0.8173 | val_loss: 2.1739 val_acc: 0.3878\n",
            "Lowest val_loss: 1.3185, at epoch 6\n",
            "GRU 80 2 [60]\n",
            "Epoch 0: train_loss: 1.5732 train_acc: 0.2694 | val_loss: 1.5738 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5697 train_acc: 0.2704 | val_loss: 1.5705 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2713 | val_loss: 1.5657 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5355 train_acc: 0.2967 | val_loss: 1.4212 val_acc: 0.3860\n",
            "Epoch 4: train_loss: 1.3011 train_acc: 0.4272 | val_loss: 1.3405 val_acc: 0.4205\n",
            "Epoch 5: train_loss: 1.2156 train_acc: 0.4672 | val_loss: 1.3123 val_acc: 0.4087\n",
            "Epoch 6: train_loss: 1.1777 train_acc: 0.4850 | val_loss: 1.3511 val_acc: 0.4087\n",
            "Epoch 7: train_loss: 1.1397 train_acc: 0.5020 | val_loss: 1.4273 val_acc: 0.3915\n",
            "Epoch 8: train_loss: 1.1073 train_acc: 0.5228 | val_loss: 1.3145 val_acc: 0.4305\n",
            "Epoch 9: train_loss: 1.0730 train_acc: 0.5355 | val_loss: 1.3461 val_acc: 0.4151\n",
            "Epoch 10: train_loss: 1.0311 train_acc: 0.5569 | val_loss: 1.4082 val_acc: 0.4251\n",
            "Epoch 11: train_loss: 0.9927 train_acc: 0.5741 | val_loss: 1.4573 val_acc: 0.4242\n",
            "Epoch 12: train_loss: 0.9464 train_acc: 0.6058 | val_loss: 1.4456 val_acc: 0.4187\n",
            "Epoch 13: train_loss: 0.8899 train_acc: 0.6381 | val_loss: 1.4474 val_acc: 0.4187\n",
            "Epoch 14: train_loss: 0.8334 train_acc: 0.6552 | val_loss: 1.5732 val_acc: 0.4015\n",
            "Epoch 15: train_loss: 0.7792 train_acc: 0.6890 | val_loss: 1.5860 val_acc: 0.4124\n",
            "Epoch 16: train_loss: 0.7267 train_acc: 0.7180 | val_loss: 1.6877 val_acc: 0.4187\n",
            "Epoch 17: train_loss: 0.6635 train_acc: 0.7432 | val_loss: 1.7560 val_acc: 0.4287\n",
            "Epoch 18: train_loss: 0.5876 train_acc: 0.7773 | val_loss: 1.8413 val_acc: 0.4096\n",
            "Epoch 19: train_loss: 0.5341 train_acc: 0.8028 | val_loss: 1.9862 val_acc: 0.4069\n",
            "Epoch 20: train_loss: 0.4795 train_acc: 0.8287 | val_loss: 2.0157 val_acc: 0.3996\n",
            "Epoch 21: train_loss: 0.4172 train_acc: 0.8545 | val_loss: 2.2511 val_acc: 0.4005\n",
            "Epoch 22: train_loss: 0.3673 train_acc: 0.8716 | val_loss: 2.3046 val_acc: 0.3987\n",
            "Epoch 23: train_loss: 0.3387 train_acc: 0.8806 | val_loss: 2.3481 val_acc: 0.3996\n",
            "Epoch 24: train_loss: 0.2995 train_acc: 0.8977 | val_loss: 2.3986 val_acc: 0.3987\n",
            "Lowest val_loss: 1.3123, at epoch 5\n",
            "GRU 80 2 [70]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2726 | val_loss: 1.5738 val_acc: 0.2561\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2669 | val_loss: 1.5753 val_acc: 0.2552\n",
            "Epoch 2: train_loss: 1.5511 train_acc: 0.3023 | val_loss: 1.4600 val_acc: 0.3606\n",
            "Epoch 3: train_loss: 1.3364 train_acc: 0.4080 | val_loss: 1.3432 val_acc: 0.4033\n",
            "Epoch 4: train_loss: 1.2424 train_acc: 0.4436 | val_loss: 1.3422 val_acc: 0.4133\n",
            "Epoch 5: train_loss: 1.2033 train_acc: 0.4616 | val_loss: 1.3225 val_acc: 0.4187\n",
            "Epoch 6: train_loss: 1.1710 train_acc: 0.4821 | val_loss: 1.3342 val_acc: 0.4060\n",
            "Epoch 7: train_loss: 1.1355 train_acc: 0.5018 | val_loss: 1.3277 val_acc: 0.4187\n",
            "Epoch 8: train_loss: 1.1034 train_acc: 0.5187 | val_loss: 1.3361 val_acc: 0.4187\n",
            "Epoch 9: train_loss: 1.0694 train_acc: 0.5323 | val_loss: 1.3583 val_acc: 0.4178\n",
            "Epoch 10: train_loss: 1.0362 train_acc: 0.5500 | val_loss: 1.3470 val_acc: 0.4178\n",
            "Epoch 11: train_loss: 0.9911 train_acc: 0.5742 | val_loss: 1.4472 val_acc: 0.4160\n",
            "Epoch 12: train_loss: 0.9416 train_acc: 0.6004 | val_loss: 1.4423 val_acc: 0.4242\n",
            "Epoch 13: train_loss: 0.8978 train_acc: 0.6194 | val_loss: 1.5366 val_acc: 0.4042\n",
            "Epoch 14: train_loss: 0.8356 train_acc: 0.6589 | val_loss: 1.5616 val_acc: 0.4124\n",
            "Epoch 15: train_loss: 0.7843 train_acc: 0.6763 | val_loss: 1.6181 val_acc: 0.4160\n",
            "Epoch 16: train_loss: 0.7393 train_acc: 0.7001 | val_loss: 1.7068 val_acc: 0.4105\n",
            "Epoch 17: train_loss: 0.6699 train_acc: 0.7324 | val_loss: 1.7635 val_acc: 0.4051\n",
            "Epoch 18: train_loss: 0.6076 train_acc: 0.7638 | val_loss: 1.8327 val_acc: 0.4060\n",
            "Epoch 19: train_loss: 0.5680 train_acc: 0.7797 | val_loss: 1.9186 val_acc: 0.4160\n",
            "Epoch 20: train_loss: 0.5215 train_acc: 0.8000 | val_loss: 2.0618 val_acc: 0.4078\n",
            "Epoch 21: train_loss: 0.4636 train_acc: 0.8240 | val_loss: 2.0895 val_acc: 0.4087\n",
            "Epoch 22: train_loss: 0.4348 train_acc: 0.8384 | val_loss: 2.2833 val_acc: 0.3887\n",
            "Epoch 23: train_loss: 0.3768 train_acc: 0.8586 | val_loss: 2.3268 val_acc: 0.3896\n",
            "Epoch 24: train_loss: 0.3503 train_acc: 0.8713 | val_loss: 2.3481 val_acc: 0.3960\n",
            "Lowest val_loss: 1.3225, at epoch 5\n",
            "GRU 100 1 [30]\n",
            "Epoch 0: train_loss: 1.5780 train_acc: 0.2587 | val_loss: 1.5718 val_acc: 0.2480\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2720 | val_loss: 1.5704 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5675 train_acc: 0.2719 | val_loss: 1.5697 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5667 train_acc: 0.2685 | val_loss: 1.5679 val_acc: 0.2516\n",
            "Epoch 4: train_loss: 1.5347 train_acc: 0.3027 | val_loss: 1.4747 val_acc: 0.3406\n",
            "Epoch 5: train_loss: 1.2930 train_acc: 0.4235 | val_loss: 1.3174 val_acc: 0.4060\n",
            "Epoch 6: train_loss: 1.2171 train_acc: 0.4629 | val_loss: 1.3453 val_acc: 0.4151\n",
            "Epoch 7: train_loss: 1.1741 train_acc: 0.4841 | val_loss: 1.3856 val_acc: 0.3924\n",
            "Epoch 8: train_loss: 1.1340 train_acc: 0.5061 | val_loss: 1.3700 val_acc: 0.4033\n",
            "Epoch 9: train_loss: 1.0976 train_acc: 0.5214 | val_loss: 1.3687 val_acc: 0.4187\n",
            "Epoch 10: train_loss: 1.0584 train_acc: 0.5449 | val_loss: 1.4268 val_acc: 0.4096\n",
            "Epoch 11: train_loss: 1.0108 train_acc: 0.5664 | val_loss: 1.3866 val_acc: 0.4214\n",
            "Epoch 12: train_loss: 0.9650 train_acc: 0.5833 | val_loss: 1.5660 val_acc: 0.3869\n",
            "Epoch 13: train_loss: 0.9133 train_acc: 0.6152 | val_loss: 1.4769 val_acc: 0.3951\n",
            "Epoch 14: train_loss: 0.8583 train_acc: 0.6486 | val_loss: 1.5201 val_acc: 0.4096\n",
            "Epoch 15: train_loss: 0.7880 train_acc: 0.6868 | val_loss: 1.5928 val_acc: 0.4160\n",
            "Epoch 16: train_loss: 0.7323 train_acc: 0.7077 | val_loss: 1.7180 val_acc: 0.3733\n",
            "Epoch 17: train_loss: 0.6684 train_acc: 0.7427 | val_loss: 1.7699 val_acc: 0.3915\n",
            "Epoch 18: train_loss: 0.6110 train_acc: 0.7761 | val_loss: 1.7729 val_acc: 0.3915\n",
            "Epoch 19: train_loss: 0.5584 train_acc: 0.7968 | val_loss: 1.9125 val_acc: 0.3824\n",
            "Epoch 20: train_loss: 0.4821 train_acc: 0.8329 | val_loss: 1.9229 val_acc: 0.3924\n",
            "Epoch 21: train_loss: 0.4295 train_acc: 0.8562 | val_loss: 2.0507 val_acc: 0.3960\n",
            "Epoch 22: train_loss: 0.3813 train_acc: 0.8723 | val_loss: 2.1270 val_acc: 0.3869\n",
            "Epoch 23: train_loss: 0.3601 train_acc: 0.8793 | val_loss: 2.1573 val_acc: 0.3842\n",
            "Epoch 24: train_loss: 0.3246 train_acc: 0.8920 | val_loss: 2.2278 val_acc: 0.3751\n",
            "Lowest val_loss: 1.3174, at epoch 5\n",
            "GRU 100 1 [40]\n",
            "Epoch 0: train_loss: 1.5748 train_acc: 0.2657 | val_loss: 1.5712 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5825 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5652 train_acc: 0.2796 | val_loss: 1.5030 val_acc: 0.3488\n",
            "Epoch 3: train_loss: 1.5616 train_acc: 0.2727 | val_loss: 1.5738 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5667 train_acc: 0.2692 | val_loss: 1.5824 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5669 train_acc: 0.2736 | val_loss: 1.5722 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5659 train_acc: 0.2736 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5655 train_acc: 0.2694 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5651 train_acc: 0.2705 | val_loss: 1.5765 val_acc: 0.2525\n",
            "Epoch 9: train_loss: 1.5625 train_acc: 0.2789 | val_loss: 1.5610 val_acc: 0.2834\n",
            "Epoch 10: train_loss: 1.4217 train_acc: 0.3725 | val_loss: 1.3419 val_acc: 0.3887\n",
            "Epoch 11: train_loss: 1.2620 train_acc: 0.4279 | val_loss: 1.3174 val_acc: 0.4160\n",
            "Epoch 12: train_loss: 1.2097 train_acc: 0.4616 | val_loss: 1.3778 val_acc: 0.3933\n",
            "Epoch 13: train_loss: 1.1668 train_acc: 0.4778 | val_loss: 1.3350 val_acc: 0.4024\n",
            "Epoch 14: train_loss: 1.1298 train_acc: 0.4986 | val_loss: 1.3321 val_acc: 0.3951\n",
            "Epoch 15: train_loss: 1.0934 train_acc: 0.5147 | val_loss: 1.3390 val_acc: 0.4042\n",
            "Epoch 16: train_loss: 1.0452 train_acc: 0.5413 | val_loss: 1.5193 val_acc: 0.4015\n",
            "Epoch 17: train_loss: 1.0059 train_acc: 0.5609 | val_loss: 1.4424 val_acc: 0.4078\n",
            "Epoch 18: train_loss: 0.9556 train_acc: 0.5866 | val_loss: 1.5269 val_acc: 0.4105\n",
            "Epoch 19: train_loss: 0.8957 train_acc: 0.6193 | val_loss: 1.5062 val_acc: 0.4114\n",
            "Epoch 20: train_loss: 0.8414 train_acc: 0.6434 | val_loss: 1.6024 val_acc: 0.4096\n",
            "Epoch 21: train_loss: 0.7806 train_acc: 0.6768 | val_loss: 1.6115 val_acc: 0.4069\n",
            "Epoch 22: train_loss: 0.7169 train_acc: 0.7154 | val_loss: 1.6902 val_acc: 0.4323\n",
            "Epoch 23: train_loss: 0.6510 train_acc: 0.7447 | val_loss: 1.8813 val_acc: 0.4069\n",
            "Epoch 24: train_loss: 0.5813 train_acc: 0.7790 | val_loss: 1.8833 val_acc: 0.4160\n",
            "Lowest val_loss: 1.3174, at epoch 11\n",
            "GRU 100 1 [50]\n",
            "Epoch 0: train_loss: 1.5713 train_acc: 0.2688 | val_loss: 1.5727 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2711 | val_loss: 1.5697 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5184 train_acc: 0.3113 | val_loss: 1.3789 val_acc: 0.3915\n",
            "Epoch 3: train_loss: 1.3060 train_acc: 0.4223 | val_loss: 1.3186 val_acc: 0.4042\n",
            "Epoch 4: train_loss: 1.2330 train_acc: 0.4506 | val_loss: 1.2957 val_acc: 0.4251\n",
            "Epoch 5: train_loss: 1.1917 train_acc: 0.4733 | val_loss: 1.3151 val_acc: 0.4314\n",
            "Epoch 6: train_loss: 1.1646 train_acc: 0.4881 | val_loss: 1.2971 val_acc: 0.4378\n",
            "Epoch 7: train_loss: 1.1366 train_acc: 0.5033 | val_loss: 1.3252 val_acc: 0.4169\n",
            "Epoch 8: train_loss: 1.0967 train_acc: 0.5265 | val_loss: 1.3584 val_acc: 0.4015\n",
            "Epoch 9: train_loss: 1.0666 train_acc: 0.5360 | val_loss: 1.3803 val_acc: 0.4142\n",
            "Epoch 10: train_loss: 1.0288 train_acc: 0.5549 | val_loss: 1.3428 val_acc: 0.4151\n",
            "Epoch 11: train_loss: 0.9928 train_acc: 0.5742 | val_loss: 1.3795 val_acc: 0.4160\n",
            "Epoch 12: train_loss: 0.9489 train_acc: 0.6008 | val_loss: 1.4085 val_acc: 0.4060\n",
            "Epoch 13: train_loss: 0.9059 train_acc: 0.6168 | val_loss: 1.4736 val_acc: 0.4087\n",
            "Epoch 14: train_loss: 0.8456 train_acc: 0.6570 | val_loss: 1.4997 val_acc: 0.3987\n",
            "Epoch 15: train_loss: 0.7939 train_acc: 0.6808 | val_loss: 1.5189 val_acc: 0.3987\n",
            "Epoch 16: train_loss: 0.7286 train_acc: 0.7135 | val_loss: 1.6164 val_acc: 0.4087\n",
            "Epoch 17: train_loss: 0.6664 train_acc: 0.7384 | val_loss: 1.6694 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 0.6129 train_acc: 0.7642 | val_loss: 1.7289 val_acc: 0.3896\n",
            "Epoch 19: train_loss: 0.5414 train_acc: 0.7979 | val_loss: 1.8140 val_acc: 0.3960\n",
            "Epoch 20: train_loss: 0.4933 train_acc: 0.8179 | val_loss: 1.8551 val_acc: 0.4024\n",
            "Epoch 21: train_loss: 0.4341 train_acc: 0.8471 | val_loss: 1.8958 val_acc: 0.4005\n",
            "Epoch 22: train_loss: 0.3984 train_acc: 0.8586 | val_loss: 1.9651 val_acc: 0.4051\n",
            "Epoch 23: train_loss: 0.3509 train_acc: 0.8800 | val_loss: 2.0592 val_acc: 0.3951\n",
            "Epoch 24: train_loss: 0.3141 train_acc: 0.8896 | val_loss: 2.1025 val_acc: 0.4069\n",
            "Lowest val_loss: 1.2957, at epoch 4\n",
            "GRU 100 1 [60]\n",
            "Epoch 0: train_loss: 1.5735 train_acc: 0.2672 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2774 | val_loss: 1.5710 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5674 train_acc: 0.2680 | val_loss: 1.5608 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5102 train_acc: 0.3133 | val_loss: 1.4079 val_acc: 0.3715\n",
            "Epoch 4: train_loss: 1.3059 train_acc: 0.4176 | val_loss: 1.3341 val_acc: 0.4015\n",
            "Epoch 5: train_loss: 1.2342 train_acc: 0.4487 | val_loss: 1.3124 val_acc: 0.4078\n",
            "Epoch 6: train_loss: 1.1924 train_acc: 0.4680 | val_loss: 1.3208 val_acc: 0.4133\n",
            "Epoch 7: train_loss: 1.1627 train_acc: 0.4837 | val_loss: 1.3220 val_acc: 0.4160\n",
            "Epoch 8: train_loss: 1.1274 train_acc: 0.4989 | val_loss: 1.3440 val_acc: 0.4024\n",
            "Epoch 9: train_loss: 1.0896 train_acc: 0.5140 | val_loss: 1.4110 val_acc: 0.3942\n",
            "Epoch 10: train_loss: 1.0530 train_acc: 0.5350 | val_loss: 1.4222 val_acc: 0.3969\n",
            "Epoch 11: train_loss: 1.0130 train_acc: 0.5569 | val_loss: 1.4027 val_acc: 0.3978\n",
            "Epoch 12: train_loss: 0.9685 train_acc: 0.5838 | val_loss: 1.4305 val_acc: 0.4069\n",
            "Epoch 13: train_loss: 0.9176 train_acc: 0.6120 | val_loss: 1.4815 val_acc: 0.3906\n",
            "Epoch 14: train_loss: 0.8677 train_acc: 0.6387 | val_loss: 1.5035 val_acc: 0.3778\n",
            "Epoch 15: train_loss: 0.8320 train_acc: 0.6572 | val_loss: 1.5375 val_acc: 0.3887\n",
            "Epoch 16: train_loss: 0.7670 train_acc: 0.6891 | val_loss: 1.5665 val_acc: 0.3942\n",
            "Epoch 17: train_loss: 0.7089 train_acc: 0.7225 | val_loss: 1.6811 val_acc: 0.3869\n",
            "Epoch 18: train_loss: 0.6405 train_acc: 0.7566 | val_loss: 1.7113 val_acc: 0.3688\n",
            "Epoch 19: train_loss: 0.5991 train_acc: 0.7683 | val_loss: 1.7390 val_acc: 0.3833\n",
            "Epoch 20: train_loss: 0.5581 train_acc: 0.7920 | val_loss: 1.7682 val_acc: 0.3924\n",
            "Epoch 21: train_loss: 0.4942 train_acc: 0.8217 | val_loss: 1.9009 val_acc: 0.3715\n",
            "Epoch 22: train_loss: 0.4387 train_acc: 0.8438 | val_loss: 1.9797 val_acc: 0.3733\n",
            "Epoch 23: train_loss: 0.4050 train_acc: 0.8593 | val_loss: 1.9801 val_acc: 0.3978\n",
            "Epoch 24: train_loss: 0.3671 train_acc: 0.8745 | val_loss: 2.0752 val_acc: 0.3878\n",
            "Lowest val_loss: 1.3124, at epoch 5\n",
            "GRU 100 1 [70]\n",
            "Epoch 0: train_loss: 1.5712 train_acc: 0.2640 | val_loss: 1.5708 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2706 | val_loss: 1.5713 val_acc: 0.2652\n",
            "Epoch 2: train_loss: 1.5672 train_acc: 0.2750 | val_loss: 1.5620 val_acc: 0.3124\n",
            "Epoch 3: train_loss: 1.4944 train_acc: 0.3262 | val_loss: 1.3726 val_acc: 0.3906\n",
            "Epoch 4: train_loss: 1.2849 train_acc: 0.4216 | val_loss: 1.3196 val_acc: 0.4015\n",
            "Epoch 5: train_loss: 1.2186 train_acc: 0.4537 | val_loss: 1.2977 val_acc: 0.4151\n",
            "Epoch 6: train_loss: 1.1892 train_acc: 0.4666 | val_loss: 1.2916 val_acc: 0.4233\n",
            "Epoch 7: train_loss: 1.1469 train_acc: 0.4903 | val_loss: 1.3151 val_acc: 0.4196\n",
            "Epoch 8: train_loss: 1.1226 train_acc: 0.5043 | val_loss: 1.3274 val_acc: 0.4178\n",
            "Epoch 9: train_loss: 1.0772 train_acc: 0.5270 | val_loss: 1.3484 val_acc: 0.4169\n",
            "Epoch 10: train_loss: 1.0446 train_acc: 0.5463 | val_loss: 1.3413 val_acc: 0.4178\n",
            "Epoch 11: train_loss: 0.9974 train_acc: 0.5694 | val_loss: 1.3711 val_acc: 0.4124\n",
            "Epoch 12: train_loss: 0.9506 train_acc: 0.5923 | val_loss: 1.4097 val_acc: 0.4033\n",
            "Epoch 13: train_loss: 0.9092 train_acc: 0.6161 | val_loss: 1.4299 val_acc: 0.3906\n",
            "Epoch 14: train_loss: 0.8506 train_acc: 0.6451 | val_loss: 1.5031 val_acc: 0.4105\n",
            "Epoch 15: train_loss: 0.7806 train_acc: 0.6797 | val_loss: 1.5481 val_acc: 0.3942\n",
            "Epoch 16: train_loss: 0.7180 train_acc: 0.7135 | val_loss: 1.6400 val_acc: 0.4024\n",
            "Epoch 17: train_loss: 0.6553 train_acc: 0.7440 | val_loss: 1.6532 val_acc: 0.4042\n",
            "Epoch 18: train_loss: 0.5892 train_acc: 0.7717 | val_loss: 1.7801 val_acc: 0.3924\n",
            "Epoch 19: train_loss: 0.5185 train_acc: 0.8082 | val_loss: 1.8559 val_acc: 0.4060\n",
            "Epoch 20: train_loss: 0.4621 train_acc: 0.8306 | val_loss: 1.9212 val_acc: 0.4033\n",
            "Epoch 21: train_loss: 0.4327 train_acc: 0.8459 | val_loss: 2.0339 val_acc: 0.4024\n",
            "Epoch 22: train_loss: 0.3650 train_acc: 0.8737 | val_loss: 2.0753 val_acc: 0.4033\n",
            "Epoch 23: train_loss: 0.3273 train_acc: 0.8875 | val_loss: 2.1884 val_acc: 0.3806\n",
            "Epoch 24: train_loss: 0.3010 train_acc: 0.8978 | val_loss: 2.1880 val_acc: 0.3896\n",
            "Lowest val_loss: 1.2916, at epoch 6\n",
            "GRU 100 2 [30]\n",
            "Epoch 0: train_loss: 1.5737 train_acc: 0.2609 | val_loss: 1.5715 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2706 | val_loss: 1.5649 val_acc: 0.2634\n",
            "Epoch 2: train_loss: 1.5133 train_acc: 0.3158 | val_loss: 1.3879 val_acc: 0.3787\n",
            "Epoch 3: train_loss: 1.3057 train_acc: 0.4212 | val_loss: 1.3231 val_acc: 0.4160\n",
            "Epoch 4: train_loss: 1.2374 train_acc: 0.4497 | val_loss: 1.3219 val_acc: 0.4178\n",
            "Epoch 5: train_loss: 1.2046 train_acc: 0.4670 | val_loss: 1.3260 val_acc: 0.4269\n",
            "Epoch 6: train_loss: 1.1673 train_acc: 0.4836 | val_loss: 1.3378 val_acc: 0.4187\n",
            "Epoch 7: train_loss: 1.1391 train_acc: 0.5022 | val_loss: 1.3441 val_acc: 0.4151\n",
            "Epoch 8: train_loss: 1.1022 train_acc: 0.5240 | val_loss: 1.3162 val_acc: 0.4169\n",
            "Epoch 9: train_loss: 1.0686 train_acc: 0.5343 | val_loss: 1.3344 val_acc: 0.4233\n",
            "Epoch 10: train_loss: 1.0271 train_acc: 0.5590 | val_loss: 1.4395 val_acc: 0.3851\n",
            "Epoch 11: train_loss: 0.9918 train_acc: 0.5748 | val_loss: 1.3858 val_acc: 0.4005\n",
            "Epoch 12: train_loss: 0.9416 train_acc: 0.6049 | val_loss: 1.4167 val_acc: 0.4051\n",
            "Epoch 13: train_loss: 0.8869 train_acc: 0.6290 | val_loss: 1.4617 val_acc: 0.4214\n",
            "Epoch 14: train_loss: 0.8391 train_acc: 0.6561 | val_loss: 1.5707 val_acc: 0.3924\n",
            "Epoch 15: train_loss: 0.7826 train_acc: 0.6843 | val_loss: 1.5998 val_acc: 0.4133\n",
            "Epoch 16: train_loss: 0.7230 train_acc: 0.7178 | val_loss: 1.6225 val_acc: 0.4042\n",
            "Epoch 17: train_loss: 0.6623 train_acc: 0.7464 | val_loss: 1.6647 val_acc: 0.3851\n",
            "Epoch 18: train_loss: 0.6087 train_acc: 0.7697 | val_loss: 1.8204 val_acc: 0.3960\n",
            "Epoch 19: train_loss: 0.5403 train_acc: 0.8003 | val_loss: 1.8739 val_acc: 0.3797\n",
            "Epoch 20: train_loss: 0.5053 train_acc: 0.8165 | val_loss: 1.8975 val_acc: 0.4087\n",
            "Epoch 21: train_loss: 0.4516 train_acc: 0.8416 | val_loss: 2.0455 val_acc: 0.3933\n",
            "Epoch 22: train_loss: 0.4291 train_acc: 0.8476 | val_loss: 2.1255 val_acc: 0.4042\n",
            "Epoch 23: train_loss: 0.3715 train_acc: 0.8730 | val_loss: 2.2852 val_acc: 0.3887\n",
            "Epoch 24: train_loss: 0.3348 train_acc: 0.8853 | val_loss: 2.3362 val_acc: 0.3896\n",
            "Lowest val_loss: 1.3162, at epoch 8\n",
            "GRU 100 2 [40]\n",
            "Epoch 0: train_loss: 1.5716 train_acc: 0.2649 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2633 | val_loss: 1.5947 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5672 train_acc: 0.2671 | val_loss: 1.5447 val_acc: 0.2925\n",
            "Epoch 3: train_loss: 1.5238 train_acc: 0.3078 | val_loss: 1.4280 val_acc: 0.3606\n",
            "Epoch 4: train_loss: 1.3156 train_acc: 0.4112 | val_loss: 1.3107 val_acc: 0.4214\n",
            "Epoch 5: train_loss: 1.2420 train_acc: 0.4374 | val_loss: 1.3015 val_acc: 0.4196\n",
            "Epoch 6: train_loss: 1.1955 train_acc: 0.4677 | val_loss: 1.3321 val_acc: 0.4287\n",
            "Epoch 7: train_loss: 1.1629 train_acc: 0.4828 | val_loss: 1.3051 val_acc: 0.4233\n",
            "Epoch 8: train_loss: 1.1274 train_acc: 0.5000 | val_loss: 1.3484 val_acc: 0.4223\n",
            "Epoch 9: train_loss: 1.0944 train_acc: 0.5198 | val_loss: 1.3467 val_acc: 0.4314\n",
            "Epoch 10: train_loss: 1.0531 train_acc: 0.5379 | val_loss: 1.3592 val_acc: 0.4314\n",
            "Epoch 11: train_loss: 1.0125 train_acc: 0.5571 | val_loss: 1.3922 val_acc: 0.4351\n",
            "Epoch 12: train_loss: 0.9669 train_acc: 0.5867 | val_loss: 1.4092 val_acc: 0.4296\n",
            "Epoch 13: train_loss: 0.9244 train_acc: 0.6096 | val_loss: 1.4408 val_acc: 0.4260\n",
            "Epoch 14: train_loss: 0.8677 train_acc: 0.6386 | val_loss: 1.4799 val_acc: 0.4423\n",
            "Epoch 15: train_loss: 0.8080 train_acc: 0.6709 | val_loss: 1.5158 val_acc: 0.4169\n",
            "Epoch 16: train_loss: 0.7483 train_acc: 0.7000 | val_loss: 1.6068 val_acc: 0.4196\n",
            "Epoch 17: train_loss: 0.7104 train_acc: 0.7161 | val_loss: 1.6959 val_acc: 0.4142\n",
            "Epoch 18: train_loss: 0.6301 train_acc: 0.7578 | val_loss: 1.8039 val_acc: 0.4033\n",
            "Epoch 19: train_loss: 0.5725 train_acc: 0.7846 | val_loss: 1.8589 val_acc: 0.3942\n",
            "Epoch 20: train_loss: 0.5336 train_acc: 0.7993 | val_loss: 1.9307 val_acc: 0.4024\n",
            "Epoch 21: train_loss: 0.4779 train_acc: 0.8255 | val_loss: 1.9961 val_acc: 0.3978\n",
            "Epoch 22: train_loss: 0.4397 train_acc: 0.8450 | val_loss: 2.0919 val_acc: 0.3860\n",
            "Epoch 23: train_loss: 0.4132 train_acc: 0.8572 | val_loss: 2.1888 val_acc: 0.3969\n",
            "Epoch 24: train_loss: 0.3609 train_acc: 0.8789 | val_loss: 2.3535 val_acc: 0.4015\n",
            "Lowest val_loss: 1.3015, at epoch 5\n",
            "GRU 100 2 [50]\n",
            "Epoch 0: train_loss: 1.5734 train_acc: 0.2669 | val_loss: 1.5773 val_acc: 0.2634\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2692 | val_loss: 1.5698 val_acc: 0.2570\n",
            "Epoch 2: train_loss: 1.4552 train_acc: 0.3531 | val_loss: 1.3584 val_acc: 0.3924\n",
            "Epoch 3: train_loss: 1.2828 train_acc: 0.4188 | val_loss: 1.3248 val_acc: 0.4005\n",
            "Epoch 4: train_loss: 1.2332 train_acc: 0.4441 | val_loss: 1.3481 val_acc: 0.4169\n",
            "Epoch 5: train_loss: 1.1941 train_acc: 0.4638 | val_loss: 1.3230 val_acc: 0.4187\n",
            "Epoch 6: train_loss: 1.1582 train_acc: 0.4833 | val_loss: 1.3307 val_acc: 0.4251\n",
            "Epoch 7: train_loss: 1.1260 train_acc: 0.5062 | val_loss: 1.3572 val_acc: 0.4214\n",
            "Epoch 8: train_loss: 1.0940 train_acc: 0.5176 | val_loss: 1.3512 val_acc: 0.4305\n",
            "Epoch 9: train_loss: 1.0546 train_acc: 0.5408 | val_loss: 1.4043 val_acc: 0.4196\n",
            "Epoch 10: train_loss: 1.0114 train_acc: 0.5626 | val_loss: 1.4072 val_acc: 0.4278\n",
            "Epoch 11: train_loss: 0.9685 train_acc: 0.5860 | val_loss: 1.4438 val_acc: 0.4205\n",
            "Epoch 12: train_loss: 0.9276 train_acc: 0.6036 | val_loss: 1.4522 val_acc: 0.4332\n",
            "Epoch 13: train_loss: 0.8694 train_acc: 0.6413 | val_loss: 1.5861 val_acc: 0.4196\n",
            "Epoch 14: train_loss: 0.8254 train_acc: 0.6552 | val_loss: 1.5493 val_acc: 0.4342\n",
            "Epoch 15: train_loss: 0.7679 train_acc: 0.6910 | val_loss: 1.6065 val_acc: 0.4233\n",
            "Epoch 16: train_loss: 0.7149 train_acc: 0.7087 | val_loss: 1.7424 val_acc: 0.4233\n",
            "Epoch 17: train_loss: 0.6589 train_acc: 0.7436 | val_loss: 1.7666 val_acc: 0.4042\n",
            "Epoch 18: train_loss: 0.5952 train_acc: 0.7715 | val_loss: 1.8327 val_acc: 0.4042\n",
            "Epoch 19: train_loss: 0.5559 train_acc: 0.7919 | val_loss: 1.8555 val_acc: 0.4114\n",
            "Epoch 20: train_loss: 0.5011 train_acc: 0.8155 | val_loss: 2.0467 val_acc: 0.4033\n",
            "Epoch 21: train_loss: 0.4574 train_acc: 0.8304 | val_loss: 2.1153 val_acc: 0.3797\n",
            "Epoch 22: train_loss: 0.4041 train_acc: 0.8558 | val_loss: 2.1825 val_acc: 0.4005\n",
            "Epoch 23: train_loss: 0.3701 train_acc: 0.8687 | val_loss: 2.2165 val_acc: 0.3978\n",
            "Epoch 24: train_loss: 0.3542 train_acc: 0.8737 | val_loss: 2.2621 val_acc: 0.4042\n",
            "Lowest val_loss: 1.3230, at epoch 5\n",
            "GRU 100 2 [60]\n",
            "Epoch 0: train_loss: 1.5744 train_acc: 0.2687 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2618 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5685 train_acc: 0.2678 | val_loss: 1.5690 val_acc: 0.2579\n",
            "Epoch 3: train_loss: 1.4710 train_acc: 0.3385 | val_loss: 1.3540 val_acc: 0.3906\n",
            "Epoch 4: train_loss: 1.2817 train_acc: 0.4273 | val_loss: 1.3341 val_acc: 0.3815\n",
            "Epoch 5: train_loss: 1.2184 train_acc: 0.4574 | val_loss: 1.3447 val_acc: 0.3969\n",
            "Epoch 6: train_loss: 1.1785 train_acc: 0.4744 | val_loss: 1.3202 val_acc: 0.4296\n",
            "Epoch 7: train_loss: 1.1479 train_acc: 0.4913 | val_loss: 1.4027 val_acc: 0.4142\n",
            "Epoch 8: train_loss: 1.1098 train_acc: 0.5085 | val_loss: 1.3560 val_acc: 0.4251\n",
            "Epoch 9: train_loss: 1.0661 train_acc: 0.5325 | val_loss: 1.4334 val_acc: 0.4269\n",
            "Epoch 10: train_loss: 1.0246 train_acc: 0.5545 | val_loss: 1.4354 val_acc: 0.4314\n",
            "Epoch 11: train_loss: 0.9774 train_acc: 0.5775 | val_loss: 1.4096 val_acc: 0.4269\n",
            "Epoch 12: train_loss: 0.9217 train_acc: 0.6085 | val_loss: 1.5317 val_acc: 0.4015\n",
            "Epoch 13: train_loss: 0.8603 train_acc: 0.6361 | val_loss: 1.5328 val_acc: 0.4033\n",
            "Epoch 14: train_loss: 0.7957 train_acc: 0.6673 | val_loss: 1.6834 val_acc: 0.4251\n",
            "Epoch 15: train_loss: 0.7245 train_acc: 0.7076 | val_loss: 1.7872 val_acc: 0.4051\n",
            "Epoch 16: train_loss: 0.6664 train_acc: 0.7356 | val_loss: 1.8390 val_acc: 0.3960\n",
            "Epoch 17: train_loss: 0.5963 train_acc: 0.7701 | val_loss: 1.9444 val_acc: 0.4242\n",
            "Epoch 18: train_loss: 0.5317 train_acc: 0.7993 | val_loss: 2.0580 val_acc: 0.4069\n",
            "Epoch 19: train_loss: 0.4806 train_acc: 0.8264 | val_loss: 2.2515 val_acc: 0.3978\n",
            "Epoch 20: train_loss: 0.4190 train_acc: 0.8524 | val_loss: 2.2116 val_acc: 0.3987\n",
            "Epoch 21: train_loss: 0.3734 train_acc: 0.8679 | val_loss: 2.3344 val_acc: 0.3951\n",
            "Epoch 22: train_loss: 0.3350 train_acc: 0.8816 | val_loss: 2.3937 val_acc: 0.4151\n",
            "Epoch 23: train_loss: 0.2926 train_acc: 0.8991 | val_loss: 2.6077 val_acc: 0.3924\n",
            "Epoch 24: train_loss: 0.2664 train_acc: 0.9093 | val_loss: 2.7896 val_acc: 0.3815\n",
            "Lowest val_loss: 1.3202, at epoch 6\n",
            "GRU 100 2 [70]\n",
            "Epoch 0: train_loss: 1.5726 train_acc: 0.2672 | val_loss: 1.5740 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2690 | val_loss: 1.5706 val_acc: 0.2897\n",
            "Epoch 2: train_loss: 1.5585 train_acc: 0.2994 | val_loss: 1.5527 val_acc: 0.2997\n",
            "Epoch 3: train_loss: 1.5360 train_acc: 0.3180 | val_loss: 1.5370 val_acc: 0.3124\n",
            "Epoch 4: train_loss: 1.5258 train_acc: 0.3234 | val_loss: 1.5413 val_acc: 0.3061\n",
            "Epoch 5: train_loss: 1.5153 train_acc: 0.3251 | val_loss: 1.5325 val_acc: 0.2970\n",
            "Epoch 6: train_loss: 1.4525 train_acc: 0.3610 | val_loss: 1.3813 val_acc: 0.3860\n",
            "Epoch 7: train_loss: 1.3187 train_acc: 0.4102 | val_loss: 1.3304 val_acc: 0.4105\n",
            "Epoch 8: train_loss: 1.2599 train_acc: 0.4322 | val_loss: 1.3197 val_acc: 0.4069\n",
            "Epoch 9: train_loss: 1.2279 train_acc: 0.4453 | val_loss: 1.3353 val_acc: 0.3678\n",
            "Epoch 10: train_loss: 1.2037 train_acc: 0.4587 | val_loss: 1.3568 val_acc: 0.3669\n",
            "Epoch 11: train_loss: 1.1821 train_acc: 0.4698 | val_loss: 1.3474 val_acc: 0.3824\n",
            "Epoch 12: train_loss: 1.1523 train_acc: 0.4833 | val_loss: 1.3212 val_acc: 0.3878\n",
            "Epoch 13: train_loss: 1.1243 train_acc: 0.5067 | val_loss: 1.3330 val_acc: 0.3906\n",
            "Epoch 14: train_loss: 1.1031 train_acc: 0.5138 | val_loss: 1.3533 val_acc: 0.3987\n",
            "Epoch 15: train_loss: 1.0685 train_acc: 0.5320 | val_loss: 1.3481 val_acc: 0.3987\n",
            "Epoch 16: train_loss: 1.0382 train_acc: 0.5492 | val_loss: 1.3410 val_acc: 0.4133\n",
            "Epoch 17: train_loss: 1.0057 train_acc: 0.5625 | val_loss: 1.4025 val_acc: 0.4015\n",
            "Epoch 18: train_loss: 0.9640 train_acc: 0.5839 | val_loss: 1.4129 val_acc: 0.4151\n",
            "Epoch 19: train_loss: 0.9276 train_acc: 0.6002 | val_loss: 1.4289 val_acc: 0.4051\n",
            "Epoch 20: train_loss: 0.8684 train_acc: 0.6359 | val_loss: 1.5171 val_acc: 0.3987\n",
            "Epoch 21: train_loss: 0.8256 train_acc: 0.6570 | val_loss: 1.5346 val_acc: 0.3715\n",
            "Epoch 22: train_loss: 0.7669 train_acc: 0.6900 | val_loss: 1.6441 val_acc: 0.3869\n",
            "Epoch 23: train_loss: 0.7206 train_acc: 0.7099 | val_loss: 1.8215 val_acc: 0.3733\n",
            "Epoch 24: train_loss: 0.6552 train_acc: 0.7452 | val_loss: 1.7927 val_acc: 0.3860\n",
            "Lowest val_loss: 1.3197, at epoch 8\n",
            "GRU 150 1 [30]\n",
            "Epoch 0: train_loss: 1.5743 train_acc: 0.2643 | val_loss: 1.5705 val_acc: 0.2552\n",
            "Epoch 1: train_loss: 1.5665 train_acc: 0.2715 | val_loss: 1.5696 val_acc: 0.2661\n",
            "Epoch 2: train_loss: 1.4079 train_acc: 0.3830 | val_loss: 1.3367 val_acc: 0.4060\n",
            "Epoch 3: train_loss: 1.2663 train_acc: 0.4268 | val_loss: 1.3241 val_acc: 0.4105\n",
            "Epoch 4: train_loss: 1.2123 train_acc: 0.4592 | val_loss: 1.3079 val_acc: 0.4187\n",
            "Epoch 5: train_loss: 1.1793 train_acc: 0.4699 | val_loss: 1.3074 val_acc: 0.4114\n",
            "Epoch 6: train_loss: 1.1404 train_acc: 0.4956 | val_loss: 1.2963 val_acc: 0.4296\n",
            "Epoch 7: train_loss: 1.1072 train_acc: 0.5176 | val_loss: 1.3277 val_acc: 0.4005\n",
            "Epoch 8: train_loss: 1.0699 train_acc: 0.5373 | val_loss: 1.3525 val_acc: 0.4105\n",
            "Epoch 9: train_loss: 1.0258 train_acc: 0.5588 | val_loss: 1.3657 val_acc: 0.4142\n",
            "Epoch 10: train_loss: 0.9740 train_acc: 0.5895 | val_loss: 1.3301 val_acc: 0.4105\n",
            "Epoch 11: train_loss: 0.9213 train_acc: 0.6134 | val_loss: 1.3900 val_acc: 0.4251\n",
            "Epoch 12: train_loss: 0.8573 train_acc: 0.6416 | val_loss: 1.4645 val_acc: 0.3978\n",
            "Epoch 13: train_loss: 0.8009 train_acc: 0.6711 | val_loss: 1.4878 val_acc: 0.4124\n",
            "Epoch 14: train_loss: 0.7246 train_acc: 0.7106 | val_loss: 1.4913 val_acc: 0.4314\n",
            "Epoch 15: train_loss: 0.6633 train_acc: 0.7386 | val_loss: 1.5994 val_acc: 0.3987\n",
            "Epoch 16: train_loss: 0.5940 train_acc: 0.7690 | val_loss: 1.6110 val_acc: 0.4051\n",
            "Epoch 17: train_loss: 0.5122 train_acc: 0.8085 | val_loss: 1.7022 val_acc: 0.4015\n",
            "Epoch 18: train_loss: 0.4543 train_acc: 0.8311 | val_loss: 1.7870 val_acc: 0.4114\n",
            "Epoch 19: train_loss: 0.3834 train_acc: 0.8648 | val_loss: 1.8434 val_acc: 0.3960\n",
            "Epoch 20: train_loss: 0.3583 train_acc: 0.8754 | val_loss: 1.8776 val_acc: 0.4096\n",
            "Epoch 21: train_loss: 0.3178 train_acc: 0.8875 | val_loss: 2.0472 val_acc: 0.4024\n",
            "Epoch 22: train_loss: 0.2753 train_acc: 0.9060 | val_loss: 2.0660 val_acc: 0.3951\n",
            "Epoch 23: train_loss: 0.2115 train_acc: 0.9302 | val_loss: 2.1313 val_acc: 0.3987\n",
            "Epoch 24: train_loss: 0.2099 train_acc: 0.9314 | val_loss: 2.1598 val_acc: 0.3969\n",
            "Lowest val_loss: 1.2963, at epoch 6\n",
            "GRU 150 1 [40]\n",
            "Epoch 0: train_loss: 1.5745 train_acc: 0.2629 | val_loss: 1.5703 val_acc: 0.2579\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2683 | val_loss: 1.5682 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5427 train_acc: 0.2942 | val_loss: 1.4483 val_acc: 0.3633\n",
            "Epoch 3: train_loss: 1.3087 train_acc: 0.4130 | val_loss: 1.3163 val_acc: 0.4214\n",
            "Epoch 4: train_loss: 1.2229 train_acc: 0.4572 | val_loss: 1.3189 val_acc: 0.4087\n",
            "Epoch 5: train_loss: 1.1775 train_acc: 0.4820 | val_loss: 1.3322 val_acc: 0.4142\n",
            "Epoch 6: train_loss: 1.1391 train_acc: 0.4985 | val_loss: 1.3465 val_acc: 0.4114\n",
            "Epoch 7: train_loss: 1.0982 train_acc: 0.5183 | val_loss: 1.3292 val_acc: 0.4160\n",
            "Epoch 8: train_loss: 1.0572 train_acc: 0.5474 | val_loss: 1.3604 val_acc: 0.4142\n",
            "Epoch 9: train_loss: 1.0077 train_acc: 0.5648 | val_loss: 1.3612 val_acc: 0.4205\n",
            "Epoch 10: train_loss: 0.9511 train_acc: 0.5994 | val_loss: 1.4103 val_acc: 0.4078\n",
            "Epoch 11: train_loss: 0.8862 train_acc: 0.6300 | val_loss: 1.4420 val_acc: 0.4087\n",
            "Epoch 12: train_loss: 0.8273 train_acc: 0.6600 | val_loss: 1.5170 val_acc: 0.3960\n",
            "Epoch 13: train_loss: 0.7518 train_acc: 0.6926 | val_loss: 1.5498 val_acc: 0.4187\n",
            "Epoch 14: train_loss: 0.6749 train_acc: 0.7338 | val_loss: 1.5941 val_acc: 0.4142\n",
            "Epoch 15: train_loss: 0.6027 train_acc: 0.7707 | val_loss: 1.7355 val_acc: 0.3942\n",
            "Epoch 16: train_loss: 0.5255 train_acc: 0.8034 | val_loss: 1.7476 val_acc: 0.4033\n",
            "Epoch 17: train_loss: 0.4532 train_acc: 0.8388 | val_loss: 1.9477 val_acc: 0.3960\n",
            "Epoch 18: train_loss: 0.4055 train_acc: 0.8601 | val_loss: 1.9138 val_acc: 0.3869\n",
            "Epoch 19: train_loss: 0.3516 train_acc: 0.8803 | val_loss: 2.0043 val_acc: 0.3978\n",
            "Epoch 20: train_loss: 0.3080 train_acc: 0.8989 | val_loss: 2.1034 val_acc: 0.4069\n",
            "Epoch 21: train_loss: 0.2729 train_acc: 0.9087 | val_loss: 2.2217 val_acc: 0.4069\n",
            "Epoch 22: train_loss: 0.2393 train_acc: 0.9252 | val_loss: 2.2225 val_acc: 0.4051\n",
            "Epoch 23: train_loss: 0.2002 train_acc: 0.9371 | val_loss: 2.2841 val_acc: 0.4042\n",
            "Epoch 24: train_loss: 0.1927 train_acc: 0.9397 | val_loss: 2.3788 val_acc: 0.3978\n",
            "Lowest val_loss: 1.3163, at epoch 3\n",
            "GRU 150 1 [50]\n",
            "Epoch 0: train_loss: 1.5737 train_acc: 0.2684 | val_loss: 1.5735 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2635 | val_loss: 1.5676 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5663 train_acc: 0.2694 | val_loss: 1.5710 val_acc: 0.2688\n",
            "Epoch 3: train_loss: 1.3870 train_acc: 0.3834 | val_loss: 1.3255 val_acc: 0.4142\n",
            "Epoch 4: train_loss: 1.2402 train_acc: 0.4462 | val_loss: 1.3292 val_acc: 0.4169\n",
            "Epoch 5: train_loss: 1.1944 train_acc: 0.4679 | val_loss: 1.3097 val_acc: 0.4169\n",
            "Epoch 6: train_loss: 1.1525 train_acc: 0.4889 | val_loss: 1.3211 val_acc: 0.4205\n",
            "Epoch 7: train_loss: 1.1073 train_acc: 0.5173 | val_loss: 1.3315 val_acc: 0.4087\n",
            "Epoch 8: train_loss: 1.0680 train_acc: 0.5331 | val_loss: 1.3443 val_acc: 0.4233\n",
            "Epoch 9: train_loss: 1.0236 train_acc: 0.5593 | val_loss: 1.4336 val_acc: 0.4124\n",
            "Epoch 10: train_loss: 0.9818 train_acc: 0.5765 | val_loss: 1.3808 val_acc: 0.4033\n",
            "Epoch 11: train_loss: 0.9114 train_acc: 0.6101 | val_loss: 1.5125 val_acc: 0.3896\n",
            "Epoch 12: train_loss: 0.8428 train_acc: 0.6498 | val_loss: 1.5259 val_acc: 0.4033\n",
            "Epoch 13: train_loss: 0.7683 train_acc: 0.6857 | val_loss: 1.5697 val_acc: 0.4105\n",
            "Epoch 14: train_loss: 0.6981 train_acc: 0.7158 | val_loss: 1.7087 val_acc: 0.4114\n",
            "Epoch 15: train_loss: 0.6093 train_acc: 0.7631 | val_loss: 1.8432 val_acc: 0.4078\n",
            "Epoch 16: train_loss: 0.5386 train_acc: 0.8013 | val_loss: 1.9072 val_acc: 0.4024\n",
            "Epoch 17: train_loss: 0.4682 train_acc: 0.8248 | val_loss: 2.0508 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 0.4059 train_acc: 0.8532 | val_loss: 2.0636 val_acc: 0.4015\n",
            "Epoch 19: train_loss: 0.3438 train_acc: 0.8779 | val_loss: 2.3000 val_acc: 0.3787\n",
            "Epoch 20: train_loss: 0.3072 train_acc: 0.8947 | val_loss: 2.2939 val_acc: 0.3860\n",
            "Epoch 21: train_loss: 0.2782 train_acc: 0.9037 | val_loss: 2.4520 val_acc: 0.3978\n",
            "Epoch 22: train_loss: 0.2350 train_acc: 0.9211 | val_loss: 2.4911 val_acc: 0.3942\n",
            "Epoch 23: train_loss: 0.1883 train_acc: 0.9386 | val_loss: 2.6412 val_acc: 0.4078\n",
            "Epoch 24: train_loss: 0.1804 train_acc: 0.9412 | val_loss: 2.7696 val_acc: 0.3896\n",
            "Lowest val_loss: 1.3097, at epoch 5\n",
            "GRU 150 1 [60]\n",
            "Epoch 0: train_loss: 1.5714 train_acc: 0.2694 | val_loss: 1.5750 val_acc: 0.2470\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5667 train_acc: 0.2704 | val_loss: 1.5636 val_acc: 0.2561\n",
            "Epoch 3: train_loss: 1.4599 train_acc: 0.3422 | val_loss: 1.3487 val_acc: 0.4024\n",
            "Epoch 4: train_loss: 1.2726 train_acc: 0.4267 | val_loss: 1.2990 val_acc: 0.4296\n",
            "Epoch 5: train_loss: 1.2049 train_acc: 0.4601 | val_loss: 1.2895 val_acc: 0.4278\n",
            "Epoch 6: train_loss: 1.1705 train_acc: 0.4792 | val_loss: 1.3850 val_acc: 0.3951\n",
            "Epoch 7: train_loss: 1.1245 train_acc: 0.5075 | val_loss: 1.3189 val_acc: 0.4296\n",
            "Epoch 8: train_loss: 1.0815 train_acc: 0.5266 | val_loss: 1.3467 val_acc: 0.4278\n",
            "Epoch 9: train_loss: 1.0327 train_acc: 0.5485 | val_loss: 1.3797 val_acc: 0.4196\n",
            "Epoch 10: train_loss: 0.9778 train_acc: 0.5787 | val_loss: 1.4148 val_acc: 0.4087\n",
            "Epoch 11: train_loss: 0.9268 train_acc: 0.6018 | val_loss: 1.4644 val_acc: 0.4242\n",
            "Epoch 12: train_loss: 0.8600 train_acc: 0.6393 | val_loss: 1.5493 val_acc: 0.4160\n",
            "Epoch 13: train_loss: 0.7914 train_acc: 0.6692 | val_loss: 1.5948 val_acc: 0.4069\n",
            "Epoch 14: train_loss: 0.7093 train_acc: 0.7102 | val_loss: 1.6880 val_acc: 0.4187\n",
            "Epoch 15: train_loss: 0.6365 train_acc: 0.7485 | val_loss: 1.7552 val_acc: 0.4205\n",
            "Epoch 16: train_loss: 0.5571 train_acc: 0.7841 | val_loss: 2.0376 val_acc: 0.3887\n",
            "Epoch 17: train_loss: 0.4911 train_acc: 0.8117 | val_loss: 2.0524 val_acc: 0.3942\n",
            "Epoch 18: train_loss: 0.4197 train_acc: 0.8434 | val_loss: 2.2073 val_acc: 0.4051\n",
            "Epoch 19: train_loss: 0.3566 train_acc: 0.8710 | val_loss: 2.4314 val_acc: 0.3906\n",
            "Epoch 20: train_loss: 0.3070 train_acc: 0.8883 | val_loss: 2.4670 val_acc: 0.3824\n",
            "Epoch 21: train_loss: 0.2548 train_acc: 0.9119 | val_loss: 2.5651 val_acc: 0.3896\n",
            "Epoch 22: train_loss: 0.2407 train_acc: 0.9197 | val_loss: 2.5790 val_acc: 0.3896\n",
            "Epoch 23: train_loss: 0.1881 train_acc: 0.9376 | val_loss: 2.7689 val_acc: 0.3933\n",
            "Epoch 24: train_loss: 0.1775 train_acc: 0.9423 | val_loss: 2.8311 val_acc: 0.3715\n",
            "Lowest val_loss: 1.2895, at epoch 5\n",
            "GRU 150 1 [70]\n",
            "Epoch 0: train_loss: 1.5732 train_acc: 0.2663 | val_loss: 1.5735 val_acc: 0.2525\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2704 | val_loss: 1.5670 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5602 train_acc: 0.2779 | val_loss: 1.5101 val_acc: 0.3615\n",
            "Epoch 3: train_loss: 1.4046 train_acc: 0.3806 | val_loss: 1.3568 val_acc: 0.3951\n",
            "Epoch 4: train_loss: 1.2757 train_acc: 0.4312 | val_loss: 1.3138 val_acc: 0.4024\n",
            "Epoch 5: train_loss: 1.2173 train_acc: 0.4528 | val_loss: 1.3201 val_acc: 0.4260\n",
            "Epoch 6: train_loss: 1.1729 train_acc: 0.4822 | val_loss: 1.3194 val_acc: 0.4169\n",
            "Epoch 7: train_loss: 1.1433 train_acc: 0.4945 | val_loss: 1.3455 val_acc: 0.4060\n",
            "Epoch 8: train_loss: 1.1034 train_acc: 0.5187 | val_loss: 1.3045 val_acc: 0.4396\n",
            "Epoch 9: train_loss: 1.0527 train_acc: 0.5343 | val_loss: 1.3651 val_acc: 0.4342\n",
            "Epoch 10: train_loss: 1.0001 train_acc: 0.5685 | val_loss: 1.3996 val_acc: 0.4342\n",
            "Epoch 11: train_loss: 0.9529 train_acc: 0.5918 | val_loss: 1.4311 val_acc: 0.4205\n",
            "Epoch 12: train_loss: 0.8841 train_acc: 0.6299 | val_loss: 1.4332 val_acc: 0.4387\n",
            "Epoch 13: train_loss: 0.8158 train_acc: 0.6593 | val_loss: 1.5456 val_acc: 0.4269\n",
            "Epoch 14: train_loss: 0.7581 train_acc: 0.6928 | val_loss: 1.5620 val_acc: 0.4314\n",
            "Epoch 15: train_loss: 0.6728 train_acc: 0.7365 | val_loss: 1.6049 val_acc: 0.4342\n",
            "Epoch 16: train_loss: 0.6108 train_acc: 0.7624 | val_loss: 1.7095 val_acc: 0.4378\n",
            "Epoch 17: train_loss: 0.5312 train_acc: 0.8028 | val_loss: 1.7293 val_acc: 0.4387\n",
            "Epoch 18: train_loss: 0.4848 train_acc: 0.8223 | val_loss: 1.8246 val_acc: 0.4233\n",
            "Epoch 19: train_loss: 0.4179 train_acc: 0.8521 | val_loss: 1.8697 val_acc: 0.4296\n",
            "Epoch 20: train_loss: 0.3560 train_acc: 0.8775 | val_loss: 2.0497 val_acc: 0.4205\n",
            "Epoch 21: train_loss: 0.2985 train_acc: 0.9024 | val_loss: 2.0378 val_acc: 0.4251\n",
            "Epoch 22: train_loss: 0.2670 train_acc: 0.9091 | val_loss: 2.1471 val_acc: 0.4205\n",
            "Epoch 23: train_loss: 0.2410 train_acc: 0.9182 | val_loss: 2.2758 val_acc: 0.4114\n",
            "Epoch 24: train_loss: 0.2067 train_acc: 0.9321 | val_loss: 2.1859 val_acc: 0.4278\n",
            "Lowest val_loss: 1.3045, at epoch 8\n",
            "GRU 150 2 [30]\n",
            "Epoch 0: train_loss: 1.5756 train_acc: 0.2632 | val_loss: 1.5786 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5694 train_acc: 0.2679 | val_loss: 1.5488 val_acc: 0.3070\n",
            "Epoch 2: train_loss: 1.4416 train_acc: 0.3723 | val_loss: 1.3941 val_acc: 0.3787\n",
            "Epoch 3: train_loss: 1.2863 train_acc: 0.4270 | val_loss: 1.3441 val_acc: 0.4051\n",
            "Epoch 4: train_loss: 1.2338 train_acc: 0.4457 | val_loss: 1.3305 val_acc: 0.4015\n",
            "Epoch 5: train_loss: 1.1898 train_acc: 0.4656 | val_loss: 1.2977 val_acc: 0.4305\n",
            "Epoch 6: train_loss: 1.1576 train_acc: 0.4854 | val_loss: 1.3158 val_acc: 0.4369\n",
            "Epoch 7: train_loss: 1.1257 train_acc: 0.5056 | val_loss: 1.3354 val_acc: 0.4214\n",
            "Epoch 8: train_loss: 1.0856 train_acc: 0.5249 | val_loss: 1.3791 val_acc: 0.4087\n",
            "Epoch 9: train_loss: 1.0374 train_acc: 0.5540 | val_loss: 1.3757 val_acc: 0.4114\n",
            "Epoch 10: train_loss: 0.9914 train_acc: 0.5680 | val_loss: 1.4233 val_acc: 0.4169\n",
            "Epoch 11: train_loss: 0.9395 train_acc: 0.6002 | val_loss: 1.4579 val_acc: 0.4178\n",
            "Epoch 12: train_loss: 0.8789 train_acc: 0.6317 | val_loss: 1.4676 val_acc: 0.4378\n",
            "Epoch 13: train_loss: 0.8065 train_acc: 0.6650 | val_loss: 1.5703 val_acc: 0.4196\n",
            "Epoch 14: train_loss: 0.7428 train_acc: 0.6989 | val_loss: 1.7554 val_acc: 0.3996\n",
            "Epoch 15: train_loss: 0.6622 train_acc: 0.7363 | val_loss: 1.6849 val_acc: 0.4360\n",
            "Epoch 16: train_loss: 0.5891 train_acc: 0.7732 | val_loss: 1.8342 val_acc: 0.4205\n",
            "Epoch 17: train_loss: 0.5333 train_acc: 0.7935 | val_loss: 1.9004 val_acc: 0.4133\n",
            "Epoch 18: train_loss: 0.4638 train_acc: 0.8295 | val_loss: 2.0166 val_acc: 0.4151\n",
            "Epoch 19: train_loss: 0.4026 train_acc: 0.8565 | val_loss: 2.1130 val_acc: 0.4251\n",
            "Epoch 20: train_loss: 0.3377 train_acc: 0.8831 | val_loss: 2.2461 val_acc: 0.4069\n",
            "Epoch 21: train_loss: 0.3100 train_acc: 0.8926 | val_loss: 2.3490 val_acc: 0.4124\n",
            "Epoch 22: train_loss: 0.2829 train_acc: 0.9047 | val_loss: 2.3365 val_acc: 0.4169\n",
            "Epoch 23: train_loss: 0.2334 train_acc: 0.9226 | val_loss: 2.4588 val_acc: 0.4305\n",
            "Epoch 24: train_loss: 0.2134 train_acc: 0.9259 | val_loss: 2.5917 val_acc: 0.4151\n",
            "Lowest val_loss: 1.2977, at epoch 5\n",
            "GRU 150 2 [40]\n",
            "Epoch 0: train_loss: 1.5726 train_acc: 0.2678 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2698 | val_loss: 1.5784 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5051 train_acc: 0.3210 | val_loss: 1.3993 val_acc: 0.3615\n",
            "Epoch 3: train_loss: 1.3001 train_acc: 0.4158 | val_loss: 1.3144 val_acc: 0.4015\n",
            "Epoch 4: train_loss: 1.2444 train_acc: 0.4426 | val_loss: 1.3326 val_acc: 0.4087\n",
            "Epoch 5: train_loss: 1.1933 train_acc: 0.4643 | val_loss: 1.2901 val_acc: 0.4178\n",
            "Epoch 6: train_loss: 1.1554 train_acc: 0.4864 | val_loss: 1.3044 val_acc: 0.4342\n",
            "Epoch 7: train_loss: 1.1141 train_acc: 0.5110 | val_loss: 1.3420 val_acc: 0.4260\n",
            "Epoch 8: train_loss: 1.0743 train_acc: 0.5304 | val_loss: 1.3550 val_acc: 0.4096\n",
            "Epoch 9: train_loss: 1.0249 train_acc: 0.5558 | val_loss: 1.3982 val_acc: 0.4169\n",
            "Epoch 10: train_loss: 0.9718 train_acc: 0.5831 | val_loss: 1.4100 val_acc: 0.4369\n",
            "Epoch 11: train_loss: 0.9078 train_acc: 0.6132 | val_loss: 1.4539 val_acc: 0.4305\n",
            "Epoch 12: train_loss: 0.8349 train_acc: 0.6554 | val_loss: 1.6348 val_acc: 0.4142\n",
            "Epoch 13: train_loss: 0.7571 train_acc: 0.6926 | val_loss: 1.6422 val_acc: 0.4260\n",
            "Epoch 14: train_loss: 0.6871 train_acc: 0.7285 | val_loss: 1.7432 val_acc: 0.4142\n",
            "Epoch 15: train_loss: 0.6034 train_acc: 0.7695 | val_loss: 1.8427 val_acc: 0.4087\n",
            "Epoch 16: train_loss: 0.5428 train_acc: 0.7940 | val_loss: 1.9151 val_acc: 0.3924\n",
            "Epoch 17: train_loss: 0.4690 train_acc: 0.8292 | val_loss: 2.0602 val_acc: 0.3996\n",
            "Epoch 18: train_loss: 0.4024 train_acc: 0.8531 | val_loss: 2.2023 val_acc: 0.3987\n",
            "Epoch 19: train_loss: 0.3530 train_acc: 0.8725 | val_loss: 2.3797 val_acc: 0.3987\n",
            "Epoch 20: train_loss: 0.3245 train_acc: 0.8855 | val_loss: 2.4039 val_acc: 0.3933\n",
            "Epoch 21: train_loss: 0.2581 train_acc: 0.9085 | val_loss: 2.5233 val_acc: 0.3942\n",
            "Epoch 22: train_loss: 0.2321 train_acc: 0.9180 | val_loss: 2.6402 val_acc: 0.3851\n",
            "Epoch 23: train_loss: 0.2087 train_acc: 0.9252 | val_loss: 2.6273 val_acc: 0.3987\n",
            "Epoch 24: train_loss: 0.1911 train_acc: 0.9352 | val_loss: 2.7945 val_acc: 0.3987\n",
            "Lowest val_loss: 1.2901, at epoch 5\n",
            "GRU 150 2 [50]\n",
            "Epoch 0: train_loss: 1.5751 train_acc: 0.2665 | val_loss: 1.5758 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2666 | val_loss: 1.5693 val_acc: 0.2507\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2767 | val_loss: 1.5428 val_acc: 0.2888\n",
            "Epoch 3: train_loss: 1.3657 train_acc: 0.4031 | val_loss: 1.3023 val_acc: 0.4260\n",
            "Epoch 4: train_loss: 1.2360 train_acc: 0.4490 | val_loss: 1.3326 val_acc: 0.4214\n",
            "Epoch 5: train_loss: 1.1832 train_acc: 0.4782 | val_loss: 1.3404 val_acc: 0.4251\n",
            "Epoch 6: train_loss: 1.1497 train_acc: 0.4968 | val_loss: 1.3814 val_acc: 0.4178\n",
            "Epoch 7: train_loss: 1.1083 train_acc: 0.5126 | val_loss: 1.3530 val_acc: 0.4260\n",
            "Epoch 8: train_loss: 1.0676 train_acc: 0.5356 | val_loss: 1.3809 val_acc: 0.4015\n",
            "Epoch 9: train_loss: 1.0022 train_acc: 0.5708 | val_loss: 1.3791 val_acc: 0.4142\n",
            "Epoch 10: train_loss: 0.9505 train_acc: 0.5930 | val_loss: 1.4247 val_acc: 0.4269\n",
            "Epoch 11: train_loss: 0.8756 train_acc: 0.6365 | val_loss: 1.5227 val_acc: 0.4242\n",
            "Epoch 12: train_loss: 0.8002 train_acc: 0.6751 | val_loss: 1.6220 val_acc: 0.4105\n",
            "Epoch 13: train_loss: 0.7150 train_acc: 0.7137 | val_loss: 1.6536 val_acc: 0.4051\n",
            "Epoch 14: train_loss: 0.6244 train_acc: 0.7575 | val_loss: 1.7597 val_acc: 0.4042\n",
            "Epoch 15: train_loss: 0.5605 train_acc: 0.7887 | val_loss: 1.9244 val_acc: 0.3833\n",
            "Epoch 16: train_loss: 0.4697 train_acc: 0.8323 | val_loss: 2.0694 val_acc: 0.3915\n",
            "Epoch 17: train_loss: 0.4040 train_acc: 0.8611 | val_loss: 2.2100 val_acc: 0.3869\n",
            "Epoch 18: train_loss: 0.3482 train_acc: 0.8770 | val_loss: 2.2562 val_acc: 0.3715\n",
            "Epoch 19: train_loss: 0.2956 train_acc: 0.8978 | val_loss: 2.4235 val_acc: 0.3842\n",
            "Epoch 20: train_loss: 0.2418 train_acc: 0.9216 | val_loss: 2.4957 val_acc: 0.3951\n",
            "Epoch 21: train_loss: 0.2228 train_acc: 0.9245 | val_loss: 2.6516 val_acc: 0.3569\n",
            "Epoch 22: train_loss: 0.1791 train_acc: 0.9421 | val_loss: 2.8094 val_acc: 0.3769\n",
            "Epoch 23: train_loss: 0.1593 train_acc: 0.9498 | val_loss: 2.9055 val_acc: 0.3833\n",
            "Epoch 24: train_loss: 0.1382 train_acc: 0.9568 | val_loss: 3.0166 val_acc: 0.3797\n",
            "Lowest val_loss: 1.3023, at epoch 3\n",
            "GRU 150 2 [60]\n",
            "Epoch 0: train_loss: 1.5745 train_acc: 0.2630 | val_loss: 1.5794 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2694 | val_loss: 1.5691 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5325 train_acc: 0.3048 | val_loss: 1.4341 val_acc: 0.3597\n",
            "Epoch 3: train_loss: 1.3028 train_acc: 0.4216 | val_loss: 1.3444 val_acc: 0.3778\n",
            "Epoch 4: train_loss: 1.2387 train_acc: 0.4444 | val_loss: 1.3196 val_acc: 0.4160\n",
            "Epoch 5: train_loss: 1.1967 train_acc: 0.4655 | val_loss: 1.3454 val_acc: 0.4124\n",
            "Epoch 6: train_loss: 1.1578 train_acc: 0.4879 | val_loss: 1.3144 val_acc: 0.4269\n",
            "Epoch 7: train_loss: 1.1196 train_acc: 0.5112 | val_loss: 1.3473 val_acc: 0.4005\n",
            "Epoch 8: train_loss: 1.0859 train_acc: 0.5277 | val_loss: 1.3602 val_acc: 0.4051\n",
            "Epoch 9: train_loss: 1.0367 train_acc: 0.5545 | val_loss: 1.3270 val_acc: 0.4160\n",
            "Epoch 10: train_loss: 0.9825 train_acc: 0.5804 | val_loss: 1.4169 val_acc: 0.4133\n",
            "Epoch 11: train_loss: 0.9337 train_acc: 0.6062 | val_loss: 1.4175 val_acc: 0.4124\n",
            "Epoch 12: train_loss: 0.8639 train_acc: 0.6396 | val_loss: 1.4592 val_acc: 0.3869\n",
            "Epoch 13: train_loss: 0.7892 train_acc: 0.6772 | val_loss: 1.5057 val_acc: 0.4169\n",
            "Epoch 14: train_loss: 0.7027 train_acc: 0.7231 | val_loss: 1.6755 val_acc: 0.3942\n",
            "Epoch 15: train_loss: 0.6304 train_acc: 0.7539 | val_loss: 1.6819 val_acc: 0.4051\n",
            "Epoch 16: train_loss: 0.5487 train_acc: 0.7919 | val_loss: 1.8261 val_acc: 0.3987\n",
            "Epoch 17: train_loss: 0.4859 train_acc: 0.8203 | val_loss: 1.9146 val_acc: 0.4051\n",
            "Epoch 18: train_loss: 0.4070 train_acc: 0.8519 | val_loss: 2.0249 val_acc: 0.3978\n",
            "Epoch 19: train_loss: 0.3735 train_acc: 0.8660 | val_loss: 2.1766 val_acc: 0.3933\n",
            "Epoch 20: train_loss: 0.2974 train_acc: 0.8954 | val_loss: 2.3347 val_acc: 0.4042\n",
            "Epoch 21: train_loss: 0.2670 train_acc: 0.9054 | val_loss: 2.4038 val_acc: 0.3951\n",
            "Epoch 22: train_loss: 0.2319 train_acc: 0.9206 | val_loss: 2.4691 val_acc: 0.4024\n",
            "Epoch 23: train_loss: 0.1934 train_acc: 0.9368 | val_loss: 2.5924 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 0.1740 train_acc: 0.9410 | val_loss: 2.7779 val_acc: 0.4005\n",
            "Lowest val_loss: 1.3144, at epoch 6\n",
            "GRU 150 2 [70]\n",
            "Epoch 0: train_loss: 1.5714 train_acc: 0.2614 | val_loss: 1.5817 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2714 | val_loss: 1.5681 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5383 train_acc: 0.3015 | val_loss: 1.4159 val_acc: 0.3833\n",
            "Epoch 3: train_loss: 1.3106 train_acc: 0.4153 | val_loss: 1.3464 val_acc: 0.4087\n",
            "Epoch 4: train_loss: 1.2308 train_acc: 0.4455 | val_loss: 1.3046 val_acc: 0.4133\n",
            "Epoch 5: train_loss: 1.1923 train_acc: 0.4588 | val_loss: 1.4046 val_acc: 0.4033\n",
            "Epoch 6: train_loss: 1.1565 train_acc: 0.4853 | val_loss: 1.3251 val_acc: 0.4278\n",
            "Epoch 7: train_loss: 1.1141 train_acc: 0.5123 | val_loss: 1.3275 val_acc: 0.4205\n",
            "Epoch 8: train_loss: 1.0717 train_acc: 0.5350 | val_loss: 1.3792 val_acc: 0.4133\n",
            "Epoch 9: train_loss: 1.0217 train_acc: 0.5550 | val_loss: 1.4195 val_acc: 0.4233\n",
            "Epoch 10: train_loss: 0.9601 train_acc: 0.5844 | val_loss: 1.4147 val_acc: 0.4251\n",
            "Epoch 11: train_loss: 0.8992 train_acc: 0.6158 | val_loss: 1.5301 val_acc: 0.4214\n",
            "Epoch 12: train_loss: 0.8310 train_acc: 0.6568 | val_loss: 1.5870 val_acc: 0.4151\n",
            "Epoch 13: train_loss: 0.7459 train_acc: 0.6959 | val_loss: 1.6931 val_acc: 0.4015\n",
            "Epoch 14: train_loss: 0.6689 train_acc: 0.7331 | val_loss: 1.9166 val_acc: 0.3942\n",
            "Epoch 15: train_loss: 0.5830 train_acc: 0.7704 | val_loss: 2.0135 val_acc: 0.4005\n",
            "Epoch 16: train_loss: 0.4983 train_acc: 0.8121 | val_loss: 2.0518 val_acc: 0.3996\n",
            "Epoch 17: train_loss: 0.4303 train_acc: 0.8393 | val_loss: 2.3768 val_acc: 0.3887\n",
            "Epoch 18: train_loss: 0.3758 train_acc: 0.8632 | val_loss: 2.4193 val_acc: 0.3987\n",
            "Epoch 19: train_loss: 0.3188 train_acc: 0.8851 | val_loss: 2.6206 val_acc: 0.3778\n",
            "Epoch 20: train_loss: 0.2714 train_acc: 0.9047 | val_loss: 2.8010 val_acc: 0.4024\n",
            "Epoch 21: train_loss: 0.2461 train_acc: 0.9129 | val_loss: 2.9564 val_acc: 0.3960\n",
            "Epoch 22: train_loss: 0.2009 train_acc: 0.9318 | val_loss: 3.0106 val_acc: 0.3906\n",
            "Epoch 23: train_loss: 0.1962 train_acc: 0.9284 | val_loss: 3.1061 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 0.1914 train_acc: 0.9322 | val_loss: 3.0664 val_acc: 0.3942\n",
            "Lowest val_loss: 1.3046, at epoch 4\n",
            "GRU 200 1 [30]\n",
            "Epoch 0: train_loss: 1.5705 train_acc: 0.2691 | val_loss: 1.5690 val_acc: 0.2561\n",
            "Epoch 1: train_loss: 1.5646 train_acc: 0.2794 | val_loss: 1.5636 val_acc: 0.2698\n",
            "Epoch 2: train_loss: 1.3951 train_acc: 0.3869 | val_loss: 1.4351 val_acc: 0.3624\n",
            "Epoch 3: train_loss: 1.2613 train_acc: 0.4336 | val_loss: 1.3534 val_acc: 0.3815\n",
            "Epoch 4: train_loss: 1.2152 train_acc: 0.4610 | val_loss: 1.3428 val_acc: 0.4087\n",
            "Epoch 5: train_loss: 1.1733 train_acc: 0.4776 | val_loss: 1.3143 val_acc: 0.4242\n",
            "Epoch 6: train_loss: 1.1408 train_acc: 0.4998 | val_loss: 1.3222 val_acc: 0.4178\n",
            "Epoch 7: train_loss: 1.0959 train_acc: 0.5138 | val_loss: 1.3415 val_acc: 0.4096\n",
            "Epoch 8: train_loss: 1.0420 train_acc: 0.5444 | val_loss: 1.3721 val_acc: 0.3996\n",
            "Epoch 9: train_loss: 0.9909 train_acc: 0.5728 | val_loss: 1.3924 val_acc: 0.4314\n",
            "Epoch 10: train_loss: 0.9280 train_acc: 0.6005 | val_loss: 1.4974 val_acc: 0.4051\n",
            "Epoch 11: train_loss: 0.8657 train_acc: 0.6348 | val_loss: 1.5058 val_acc: 0.4114\n",
            "Epoch 12: train_loss: 0.7865 train_acc: 0.6791 | val_loss: 1.5020 val_acc: 0.4096\n",
            "Epoch 13: train_loss: 0.6953 train_acc: 0.7225 | val_loss: 1.5845 val_acc: 0.4196\n",
            "Epoch 14: train_loss: 0.6262 train_acc: 0.7526 | val_loss: 1.6096 val_acc: 0.4214\n",
            "Epoch 15: train_loss: 0.5421 train_acc: 0.7961 | val_loss: 1.8405 val_acc: 0.3978\n",
            "Epoch 16: train_loss: 0.4617 train_acc: 0.8270 | val_loss: 1.8938 val_acc: 0.3996\n",
            "Epoch 17: train_loss: 0.3876 train_acc: 0.8599 | val_loss: 1.9608 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 0.3207 train_acc: 0.8902 | val_loss: 2.0139 val_acc: 0.4187\n",
            "Epoch 19: train_loss: 0.2779 train_acc: 0.9039 | val_loss: 2.1772 val_acc: 0.4069\n",
            "Epoch 20: train_loss: 0.2520 train_acc: 0.9143 | val_loss: 2.1842 val_acc: 0.3942\n",
            "Epoch 21: train_loss: 0.2218 train_acc: 0.9254 | val_loss: 2.2579 val_acc: 0.3978\n",
            "Epoch 22: train_loss: 0.1753 train_acc: 0.9432 | val_loss: 2.3233 val_acc: 0.3996\n",
            "Epoch 23: train_loss: 0.1643 train_acc: 0.9497 | val_loss: 2.2396 val_acc: 0.4051\n",
            "Epoch 24: train_loss: 0.1584 train_acc: 0.9499 | val_loss: 2.3637 val_acc: 0.4024\n",
            "Lowest val_loss: 1.3143, at epoch 5\n",
            "GRU 200 1 [40]\n",
            "Epoch 0: train_loss: 1.5727 train_acc: 0.2688 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2719 | val_loss: 1.5729 val_acc: 0.2589\n",
            "Epoch 2: train_loss: 1.5668 train_acc: 0.2712 | val_loss: 1.5753 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.4840 train_acc: 0.3340 | val_loss: 1.4039 val_acc: 0.3715\n",
            "Epoch 4: train_loss: 1.2794 train_acc: 0.4261 | val_loss: 1.3273 val_acc: 0.4124\n",
            "Epoch 5: train_loss: 1.2186 train_acc: 0.4636 | val_loss: 1.3182 val_acc: 0.3942\n",
            "Epoch 6: train_loss: 1.1661 train_acc: 0.4834 | val_loss: 1.3491 val_acc: 0.4124\n",
            "Epoch 7: train_loss: 1.1202 train_acc: 0.5150 | val_loss: 1.3048 val_acc: 0.4042\n",
            "Epoch 8: train_loss: 1.0636 train_acc: 0.5379 | val_loss: 1.3300 val_acc: 0.4223\n",
            "Epoch 9: train_loss: 1.0174 train_acc: 0.5617 | val_loss: 1.3597 val_acc: 0.4133\n",
            "Epoch 10: train_loss: 0.9379 train_acc: 0.6051 | val_loss: 1.3853 val_acc: 0.4178\n",
            "Epoch 11: train_loss: 0.8700 train_acc: 0.6372 | val_loss: 1.4206 val_acc: 0.4260\n",
            "Epoch 12: train_loss: 0.7853 train_acc: 0.6806 | val_loss: 1.5582 val_acc: 0.3996\n",
            "Epoch 13: train_loss: 0.6982 train_acc: 0.7280 | val_loss: 1.5819 val_acc: 0.4269\n",
            "Epoch 14: train_loss: 0.6076 train_acc: 0.7660 | val_loss: 1.6992 val_acc: 0.4114\n",
            "Epoch 15: train_loss: 0.5247 train_acc: 0.8052 | val_loss: 1.8114 val_acc: 0.4078\n",
            "Epoch 16: train_loss: 0.4470 train_acc: 0.8377 | val_loss: 1.9112 val_acc: 0.4015\n",
            "Epoch 17: train_loss: 0.4157 train_acc: 0.8489 | val_loss: 1.9141 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 0.3443 train_acc: 0.8763 | val_loss: 2.0019 val_acc: 0.4033\n",
            "Epoch 19: train_loss: 0.2943 train_acc: 0.8974 | val_loss: 2.1342 val_acc: 0.3878\n",
            "Epoch 20: train_loss: 0.2411 train_acc: 0.9210 | val_loss: 2.2581 val_acc: 0.4078\n",
            "Epoch 21: train_loss: 0.2230 train_acc: 0.9284 | val_loss: 2.2266 val_acc: 0.4105\n",
            "Epoch 22: train_loss: 0.1948 train_acc: 0.9342 | val_loss: 2.3271 val_acc: 0.4005\n",
            "Epoch 23: train_loss: 0.1505 train_acc: 0.9499 | val_loss: 2.4290 val_acc: 0.4105\n",
            "Epoch 24: train_loss: 0.1534 train_acc: 0.9494 | val_loss: 2.5207 val_acc: 0.3960\n",
            "Lowest val_loss: 1.3048, at epoch 7\n",
            "GRU 200 1 [50]\n",
            "Epoch 0: train_loss: 1.5713 train_acc: 0.2743 | val_loss: 1.5686 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2710 | val_loss: 1.5881 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5187 train_acc: 0.3069 | val_loss: 1.4032 val_acc: 0.3806\n",
            "Epoch 3: train_loss: 1.2898 train_acc: 0.4225 | val_loss: 1.3500 val_acc: 0.4069\n",
            "Epoch 4: train_loss: 1.2201 train_acc: 0.4551 | val_loss: 1.3203 val_acc: 0.4042\n",
            "Epoch 5: train_loss: 1.1876 train_acc: 0.4714 | val_loss: 1.3032 val_acc: 0.4269\n",
            "Epoch 6: train_loss: 1.1479 train_acc: 0.4923 | val_loss: 1.3291 val_acc: 0.4160\n",
            "Epoch 7: train_loss: 1.1087 train_acc: 0.5180 | val_loss: 1.3374 val_acc: 0.4114\n",
            "Epoch 8: train_loss: 1.0573 train_acc: 0.5451 | val_loss: 1.3250 val_acc: 0.4205\n",
            "Epoch 9: train_loss: 1.0078 train_acc: 0.5692 | val_loss: 1.3732 val_acc: 0.4160\n",
            "Epoch 10: train_loss: 0.9499 train_acc: 0.5953 | val_loss: 1.4224 val_acc: 0.4142\n",
            "Epoch 11: train_loss: 0.8724 train_acc: 0.6338 | val_loss: 1.4181 val_acc: 0.4278\n",
            "Epoch 12: train_loss: 0.7885 train_acc: 0.6822 | val_loss: 1.5444 val_acc: 0.4160\n",
            "Epoch 13: train_loss: 0.7191 train_acc: 0.7143 | val_loss: 1.6362 val_acc: 0.4087\n",
            "Epoch 14: train_loss: 0.6188 train_acc: 0.7557 | val_loss: 1.6727 val_acc: 0.4124\n",
            "Epoch 15: train_loss: 0.5312 train_acc: 0.7996 | val_loss: 1.8904 val_acc: 0.4024\n",
            "Epoch 16: train_loss: 0.4620 train_acc: 0.8284 | val_loss: 1.9179 val_acc: 0.4051\n",
            "Epoch 17: train_loss: 0.3915 train_acc: 0.8571 | val_loss: 1.9116 val_acc: 0.3815\n",
            "Epoch 18: train_loss: 0.3346 train_acc: 0.8853 | val_loss: 2.2507 val_acc: 0.3915\n",
            "Epoch 19: train_loss: 0.2939 train_acc: 0.8985 | val_loss: 2.2677 val_acc: 0.3996\n",
            "Epoch 20: train_loss: 0.2373 train_acc: 0.9205 | val_loss: 2.3110 val_acc: 0.3896\n",
            "Epoch 21: train_loss: 0.2116 train_acc: 0.9287 | val_loss: 2.4081 val_acc: 0.3815\n",
            "Epoch 22: train_loss: 0.1897 train_acc: 0.9363 | val_loss: 2.4441 val_acc: 0.3960\n",
            "Epoch 23: train_loss: 0.1686 train_acc: 0.9439 | val_loss: 2.5216 val_acc: 0.4060\n",
            "Epoch 24: train_loss: 0.1454 train_acc: 0.9518 | val_loss: 2.6623 val_acc: 0.4015\n",
            "Lowest val_loss: 1.3032, at epoch 5\n",
            "GRU 200 1 [60]\n",
            "Epoch 0: train_loss: 1.5727 train_acc: 0.2663 | val_loss: 1.5694 val_acc: 0.2961\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2679 | val_loss: 1.5637 val_acc: 0.2543\n",
            "Epoch 2: train_loss: 1.5669 train_acc: 0.2686 | val_loss: 1.5592 val_acc: 0.3252\n",
            "Epoch 3: train_loss: 1.4107 train_acc: 0.3673 | val_loss: 1.3555 val_acc: 0.3842\n",
            "Epoch 4: train_loss: 1.2493 train_acc: 0.4388 | val_loss: 1.3057 val_acc: 0.4196\n",
            "Epoch 5: train_loss: 1.1918 train_acc: 0.4680 | val_loss: 1.3080 val_acc: 0.4133\n",
            "Epoch 6: train_loss: 1.1440 train_acc: 0.4936 | val_loss: 1.3507 val_acc: 0.4087\n",
            "Epoch 7: train_loss: 1.1022 train_acc: 0.5130 | val_loss: 1.3657 val_acc: 0.4205\n",
            "Epoch 8: train_loss: 1.0526 train_acc: 0.5419 | val_loss: 1.4393 val_acc: 0.4105\n",
            "Epoch 9: train_loss: 0.9917 train_acc: 0.5746 | val_loss: 1.4060 val_acc: 0.4087\n",
            "Epoch 10: train_loss: 0.9185 train_acc: 0.6131 | val_loss: 1.4382 val_acc: 0.4332\n",
            "Epoch 11: train_loss: 0.8417 train_acc: 0.6510 | val_loss: 1.5443 val_acc: 0.4051\n",
            "Epoch 12: train_loss: 0.7577 train_acc: 0.6868 | val_loss: 1.5241 val_acc: 0.4151\n",
            "Epoch 13: train_loss: 0.6763 train_acc: 0.7281 | val_loss: 1.7056 val_acc: 0.3942\n",
            "Epoch 14: train_loss: 0.5698 train_acc: 0.7757 | val_loss: 1.8724 val_acc: 0.4042\n",
            "Epoch 15: train_loss: 0.4968 train_acc: 0.8076 | val_loss: 2.0432 val_acc: 0.3960\n",
            "Epoch 16: train_loss: 0.4273 train_acc: 0.8381 | val_loss: 2.0687 val_acc: 0.3869\n",
            "Epoch 17: train_loss: 0.3699 train_acc: 0.8632 | val_loss: 2.1873 val_acc: 0.3887\n",
            "Epoch 18: train_loss: 0.3024 train_acc: 0.8909 | val_loss: 2.3875 val_acc: 0.3842\n",
            "Epoch 19: train_loss: 0.2689 train_acc: 0.9058 | val_loss: 2.4069 val_acc: 0.3878\n",
            "Epoch 20: train_loss: 0.2364 train_acc: 0.9165 | val_loss: 2.5182 val_acc: 0.3933\n",
            "Epoch 21: train_loss: 0.2139 train_acc: 0.9280 | val_loss: 2.5991 val_acc: 0.3860\n",
            "Epoch 22: train_loss: 0.1873 train_acc: 0.9381 | val_loss: 2.6221 val_acc: 0.4005\n",
            "Epoch 23: train_loss: 0.1655 train_acc: 0.9453 | val_loss: 2.6834 val_acc: 0.3760\n",
            "Epoch 24: train_loss: 0.1376 train_acc: 0.9520 | val_loss: 2.8160 val_acc: 0.3787\n",
            "Lowest val_loss: 1.3057, at epoch 4\n",
            "GRU 200 1 [70]\n",
            "Epoch 0: train_loss: 1.5726 train_acc: 0.2684 | val_loss: 1.5718 val_acc: 0.2598\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2683 | val_loss: 1.5615 val_acc: 0.2961\n",
            "Epoch 2: train_loss: 1.5663 train_acc: 0.2674 | val_loss: 1.5629 val_acc: 0.2634\n",
            "Epoch 3: train_loss: 1.4330 train_acc: 0.3653 | val_loss: 1.3837 val_acc: 0.3851\n",
            "Epoch 4: train_loss: 1.2588 train_acc: 0.4357 | val_loss: 1.3346 val_acc: 0.4124\n",
            "Epoch 5: train_loss: 1.2069 train_acc: 0.4686 | val_loss: 1.3138 val_acc: 0.4133\n",
            "Epoch 6: train_loss: 1.1605 train_acc: 0.4891 | val_loss: 1.3444 val_acc: 0.4187\n",
            "Epoch 7: train_loss: 1.1092 train_acc: 0.5140 | val_loss: 1.3612 val_acc: 0.4151\n",
            "Epoch 8: train_loss: 1.0663 train_acc: 0.5403 | val_loss: 1.3622 val_acc: 0.4142\n",
            "Epoch 9: train_loss: 1.0098 train_acc: 0.5658 | val_loss: 1.3837 val_acc: 0.4160\n",
            "Epoch 10: train_loss: 0.9483 train_acc: 0.6011 | val_loss: 1.4705 val_acc: 0.4051\n",
            "Epoch 11: train_loss: 0.8825 train_acc: 0.6383 | val_loss: 1.4739 val_acc: 0.4223\n",
            "Epoch 12: train_loss: 0.8022 train_acc: 0.6721 | val_loss: 1.5354 val_acc: 0.4187\n",
            "Epoch 13: train_loss: 0.7295 train_acc: 0.7074 | val_loss: 1.6909 val_acc: 0.4287\n",
            "Epoch 14: train_loss: 0.6340 train_acc: 0.7507 | val_loss: 1.7292 val_acc: 0.4142\n",
            "Epoch 15: train_loss: 0.5581 train_acc: 0.7872 | val_loss: 1.8263 val_acc: 0.4078\n",
            "Epoch 16: train_loss: 0.4660 train_acc: 0.8310 | val_loss: 1.9882 val_acc: 0.3951\n",
            "Epoch 17: train_loss: 0.4134 train_acc: 0.8528 | val_loss: 2.0108 val_acc: 0.4024\n",
            "Epoch 18: train_loss: 0.3445 train_acc: 0.8799 | val_loss: 2.1753 val_acc: 0.3951\n",
            "Epoch 19: train_loss: 0.3166 train_acc: 0.8876 | val_loss: 2.1867 val_acc: 0.4105\n",
            "Epoch 20: train_loss: 0.2664 train_acc: 0.9105 | val_loss: 2.2752 val_acc: 0.3942\n",
            "Epoch 21: train_loss: 0.2243 train_acc: 0.9243 | val_loss: 2.3800 val_acc: 0.3960\n",
            "Epoch 22: train_loss: 0.1906 train_acc: 0.9376 | val_loss: 2.5475 val_acc: 0.3824\n",
            "Epoch 23: train_loss: 0.1670 train_acc: 0.9452 | val_loss: 2.5549 val_acc: 0.3833\n",
            "Epoch 24: train_loss: 0.1687 train_acc: 0.9446 | val_loss: 2.5103 val_acc: 0.3915\n",
            "Lowest val_loss: 1.3138, at epoch 5\n",
            "GRU 200 2 [30]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2722 | val_loss: 1.5738 val_acc: 0.2797\n",
            "Epoch 1: train_loss: 1.5704 train_acc: 0.2678 | val_loss: 1.5645 val_acc: 0.2807\n",
            "Epoch 2: train_loss: 1.4167 train_acc: 0.3727 | val_loss: 1.3533 val_acc: 0.3896\n",
            "Epoch 3: train_loss: 1.2596 train_acc: 0.4371 | val_loss: 1.2959 val_acc: 0.4178\n",
            "Epoch 4: train_loss: 1.2147 train_acc: 0.4573 | val_loss: 1.3051 val_acc: 0.4196\n",
            "Epoch 5: train_loss: 1.1760 train_acc: 0.4805 | val_loss: 1.3306 val_acc: 0.3978\n",
            "Epoch 6: train_loss: 1.1327 train_acc: 0.4980 | val_loss: 1.3987 val_acc: 0.4078\n",
            "Epoch 7: train_loss: 1.0896 train_acc: 0.5243 | val_loss: 1.4467 val_acc: 0.3969\n",
            "Epoch 8: train_loss: 1.0351 train_acc: 0.5488 | val_loss: 1.3309 val_acc: 0.4351\n",
            "Epoch 9: train_loss: 0.9714 train_acc: 0.5871 | val_loss: 1.4858 val_acc: 0.4087\n",
            "Epoch 10: train_loss: 0.9035 train_acc: 0.6142 | val_loss: 1.5592 val_acc: 0.3996\n",
            "Epoch 11: train_loss: 0.8208 train_acc: 0.6607 | val_loss: 1.6326 val_acc: 0.4078\n",
            "Epoch 12: train_loss: 0.7496 train_acc: 0.6955 | val_loss: 1.7084 val_acc: 0.4051\n",
            "Epoch 13: train_loss: 0.6579 train_acc: 0.7406 | val_loss: 1.8212 val_acc: 0.4178\n",
            "Epoch 14: train_loss: 0.5599 train_acc: 0.7853 | val_loss: 1.9887 val_acc: 0.3842\n",
            "Epoch 15: train_loss: 0.4732 train_acc: 0.8226 | val_loss: 2.1232 val_acc: 0.3969\n",
            "Epoch 16: train_loss: 0.4353 train_acc: 0.8364 | val_loss: 2.3077 val_acc: 0.3769\n",
            "Epoch 17: train_loss: 0.3534 train_acc: 0.8721 | val_loss: 2.4121 val_acc: 0.3860\n",
            "Epoch 18: train_loss: 0.3026 train_acc: 0.8940 | val_loss: 2.4936 val_acc: 0.3851\n",
            "Epoch 19: train_loss: 0.2373 train_acc: 0.9181 | val_loss: 2.7034 val_acc: 0.3833\n",
            "Epoch 20: train_loss: 0.2157 train_acc: 0.9267 | val_loss: 2.7610 val_acc: 0.3751\n",
            "Epoch 21: train_loss: 0.1651 train_acc: 0.9474 | val_loss: 2.9469 val_acc: 0.3860\n",
            "Epoch 22: train_loss: 0.1708 train_acc: 0.9396 | val_loss: 3.0626 val_acc: 0.3651\n",
            "Epoch 23: train_loss: 0.1384 train_acc: 0.9524 | val_loss: 3.2306 val_acc: 0.3824\n",
            "Epoch 24: train_loss: 0.1416 train_acc: 0.9496 | val_loss: 3.2528 val_acc: 0.3778\n",
            "Lowest val_loss: 1.2959, at epoch 3\n",
            "GRU 200 2 [40]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2651 | val_loss: 1.5728 val_acc: 0.2707\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2702 | val_loss: 1.5979 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5096 train_acc: 0.3178 | val_loss: 1.3725 val_acc: 0.3906\n",
            "Epoch 3: train_loss: 1.2973 train_acc: 0.4140 | val_loss: 1.3559 val_acc: 0.3987\n",
            "Epoch 4: train_loss: 1.2239 train_acc: 0.4532 | val_loss: 1.3046 val_acc: 0.4069\n",
            "Epoch 5: train_loss: 1.1752 train_acc: 0.4802 | val_loss: 1.3210 val_acc: 0.4024\n",
            "Epoch 6: train_loss: 1.1359 train_acc: 0.4996 | val_loss: 1.3307 val_acc: 0.4187\n",
            "Epoch 7: train_loss: 1.0927 train_acc: 0.5169 | val_loss: 1.3593 val_acc: 0.4260\n",
            "Epoch 8: train_loss: 1.0431 train_acc: 0.5510 | val_loss: 1.3540 val_acc: 0.4178\n",
            "Epoch 9: train_loss: 0.9859 train_acc: 0.5698 | val_loss: 1.3860 val_acc: 0.4332\n",
            "Epoch 10: train_loss: 0.9050 train_acc: 0.6072 | val_loss: 1.4596 val_acc: 0.4251\n",
            "Epoch 11: train_loss: 0.8322 train_acc: 0.6516 | val_loss: 1.5337 val_acc: 0.4169\n",
            "Epoch 12: train_loss: 0.7439 train_acc: 0.6982 | val_loss: 1.6919 val_acc: 0.4269\n",
            "Epoch 13: train_loss: 0.6519 train_acc: 0.7434 | val_loss: 1.7008 val_acc: 0.4223\n",
            "Epoch 14: train_loss: 0.5683 train_acc: 0.7802 | val_loss: 1.9290 val_acc: 0.3924\n",
            "Epoch 15: train_loss: 0.4780 train_acc: 0.8215 | val_loss: 2.0285 val_acc: 0.3878\n",
            "Epoch 16: train_loss: 0.4085 train_acc: 0.8498 | val_loss: 2.2978 val_acc: 0.3869\n",
            "Epoch 17: train_loss: 0.3368 train_acc: 0.8782 | val_loss: 2.5957 val_acc: 0.3824\n",
            "Epoch 18: train_loss: 0.2861 train_acc: 0.8984 | val_loss: 2.5148 val_acc: 0.3896\n",
            "Epoch 19: train_loss: 0.2453 train_acc: 0.9139 | val_loss: 2.5965 val_acc: 0.3833\n",
            "Epoch 20: train_loss: 0.2157 train_acc: 0.9246 | val_loss: 2.8897 val_acc: 0.3869\n",
            "Epoch 21: train_loss: 0.1739 train_acc: 0.9416 | val_loss: 3.0369 val_acc: 0.3878\n",
            "Epoch 22: train_loss: 0.1638 train_acc: 0.9448 | val_loss: 2.9610 val_acc: 0.4051\n",
            "Epoch 23: train_loss: 0.1341 train_acc: 0.9565 | val_loss: 3.1919 val_acc: 0.3924\n",
            "Epoch 24: train_loss: 0.1208 train_acc: 0.9589 | val_loss: 3.1128 val_acc: 0.3906\n",
            "Lowest val_loss: 1.3046, at epoch 4\n",
            "GRU 200 2 [50]\n",
            "Epoch 0: train_loss: 1.5745 train_acc: 0.2614 | val_loss: 1.5743 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5697 train_acc: 0.2673 | val_loss: 1.5723 val_acc: 0.2498\n",
            "Epoch 2: train_loss: 1.5658 train_acc: 0.2677 | val_loss: 1.4803 val_acc: 0.3597\n",
            "Epoch 3: train_loss: 1.3463 train_acc: 0.4018 | val_loss: 1.3039 val_acc: 0.4233\n",
            "Epoch 4: train_loss: 1.2335 train_acc: 0.4472 | val_loss: 1.3225 val_acc: 0.4105\n",
            "Epoch 5: train_loss: 1.1871 train_acc: 0.4706 | val_loss: 1.2900 val_acc: 0.4323\n",
            "Epoch 6: train_loss: 1.1386 train_acc: 0.4943 | val_loss: 1.3784 val_acc: 0.3951\n",
            "Epoch 7: train_loss: 1.0872 train_acc: 0.5200 | val_loss: 1.3421 val_acc: 0.4223\n",
            "Epoch 8: train_loss: 1.0320 train_acc: 0.5497 | val_loss: 1.3964 val_acc: 0.4178\n",
            "Epoch 9: train_loss: 0.9619 train_acc: 0.5873 | val_loss: 1.4294 val_acc: 0.4142\n",
            "Epoch 10: train_loss: 0.8768 train_acc: 0.6292 | val_loss: 1.5270 val_acc: 0.3996\n",
            "Epoch 11: train_loss: 0.8036 train_acc: 0.6674 | val_loss: 1.5416 val_acc: 0.3978\n",
            "Epoch 12: train_loss: 0.6929 train_acc: 0.7204 | val_loss: 1.6617 val_acc: 0.4005\n",
            "Epoch 13: train_loss: 0.5913 train_acc: 0.7731 | val_loss: 1.8563 val_acc: 0.3833\n",
            "Epoch 14: train_loss: 0.4947 train_acc: 0.8126 | val_loss: 1.9569 val_acc: 0.4114\n",
            "Epoch 15: train_loss: 0.4083 train_acc: 0.8503 | val_loss: 2.0887 val_acc: 0.4069\n",
            "Epoch 16: train_loss: 0.3195 train_acc: 0.8837 | val_loss: 2.3327 val_acc: 0.3915\n",
            "Epoch 17: train_loss: 0.2594 train_acc: 0.9068 | val_loss: 2.5155 val_acc: 0.4042\n",
            "Epoch 18: train_loss: 0.2252 train_acc: 0.9218 | val_loss: 2.5176 val_acc: 0.3842\n",
            "Epoch 19: train_loss: 0.1977 train_acc: 0.9305 | val_loss: 2.6298 val_acc: 0.3996\n",
            "Epoch 20: train_loss: 0.1592 train_acc: 0.9458 | val_loss: 2.7873 val_acc: 0.3906\n",
            "Epoch 21: train_loss: 0.1459 train_acc: 0.9504 | val_loss: 2.8940 val_acc: 0.3806\n",
            "Epoch 22: train_loss: 0.1237 train_acc: 0.9573 | val_loss: 3.0040 val_acc: 0.3896\n",
            "Epoch 23: train_loss: 0.1159 train_acc: 0.9611 | val_loss: 3.1090 val_acc: 0.4015\n",
            "Epoch 24: train_loss: 0.1024 train_acc: 0.9644 | val_loss: 3.2661 val_acc: 0.3860\n",
            "Lowest val_loss: 1.2900, at epoch 5\n",
            "GRU 200 2 [60]\n",
            "Epoch 0: train_loss: 1.5719 train_acc: 0.2686 | val_loss: 1.5715 val_acc: 0.2661\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2720 | val_loss: 1.5674 val_acc: 0.2788\n",
            "Epoch 2: train_loss: 1.4866 train_acc: 0.3347 | val_loss: 1.3607 val_acc: 0.3933\n",
            "Epoch 3: train_loss: 1.2879 train_acc: 0.4272 | val_loss: 1.3047 val_acc: 0.4278\n",
            "Epoch 4: train_loss: 1.2197 train_acc: 0.4569 | val_loss: 1.3414 val_acc: 0.4124\n",
            "Epoch 5: train_loss: 1.1716 train_acc: 0.4830 | val_loss: 1.2958 val_acc: 0.4269\n",
            "Epoch 6: train_loss: 1.1315 train_acc: 0.4995 | val_loss: 1.3277 val_acc: 0.4269\n",
            "Epoch 7: train_loss: 1.0822 train_acc: 0.5221 | val_loss: 1.3275 val_acc: 0.4405\n",
            "Epoch 8: train_loss: 1.0299 train_acc: 0.5480 | val_loss: 1.4056 val_acc: 0.4378\n",
            "Epoch 9: train_loss: 0.9695 train_acc: 0.5779 | val_loss: 1.4144 val_acc: 0.4196\n",
            "Epoch 10: train_loss: 0.8948 train_acc: 0.6165 | val_loss: 1.5748 val_acc: 0.4015\n",
            "Epoch 11: train_loss: 0.8260 train_acc: 0.6544 | val_loss: 1.6357 val_acc: 0.3924\n",
            "Epoch 12: train_loss: 0.7393 train_acc: 0.6962 | val_loss: 1.7314 val_acc: 0.4024\n",
            "Epoch 13: train_loss: 0.6628 train_acc: 0.7372 | val_loss: 1.8134 val_acc: 0.3960\n",
            "Epoch 14: train_loss: 0.5887 train_acc: 0.7679 | val_loss: 1.8318 val_acc: 0.4033\n",
            "Epoch 15: train_loss: 0.4948 train_acc: 0.8096 | val_loss: 2.0444 val_acc: 0.3969\n",
            "Epoch 16: train_loss: 0.4217 train_acc: 0.8404 | val_loss: 2.2587 val_acc: 0.4015\n",
            "Epoch 17: train_loss: 0.3616 train_acc: 0.8679 | val_loss: 2.3458 val_acc: 0.3842\n",
            "Epoch 18: train_loss: 0.3175 train_acc: 0.8858 | val_loss: 2.4084 val_acc: 0.3769\n",
            "Epoch 19: train_loss: 0.2527 train_acc: 0.9101 | val_loss: 2.6095 val_acc: 0.3806\n",
            "Epoch 20: train_loss: 0.2228 train_acc: 0.9213 | val_loss: 2.7426 val_acc: 0.3887\n",
            "Epoch 21: train_loss: 0.1843 train_acc: 0.9346 | val_loss: 2.8497 val_acc: 0.3797\n",
            "Epoch 22: train_loss: 0.1548 train_acc: 0.9462 | val_loss: 2.9348 val_acc: 0.3942\n",
            "Epoch 23: train_loss: 0.1320 train_acc: 0.9538 | val_loss: 3.1069 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 0.1285 train_acc: 0.9581 | val_loss: 3.1483 val_acc: 0.4051\n",
            "Lowest val_loss: 1.2958, at epoch 5\n",
            "GRU 200 2 [70]\n",
            "Epoch 0: train_loss: 1.5720 train_acc: 0.2662 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5694 train_acc: 0.2684 | val_loss: 1.5845 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5689 train_acc: 0.2701 | val_loss: 1.5727 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5373 train_acc: 0.2971 | val_loss: 1.4045 val_acc: 0.3860\n",
            "Epoch 4: train_loss: 1.3118 train_acc: 0.4155 | val_loss: 1.3210 val_acc: 0.3969\n",
            "Epoch 5: train_loss: 1.2223 train_acc: 0.4526 | val_loss: 1.2965 val_acc: 0.4124\n",
            "Epoch 6: train_loss: 1.1743 train_acc: 0.4774 | val_loss: 1.3361 val_acc: 0.4096\n",
            "Epoch 7: train_loss: 1.1255 train_acc: 0.5063 | val_loss: 1.3467 val_acc: 0.4151\n",
            "Epoch 8: train_loss: 1.0731 train_acc: 0.5305 | val_loss: 1.3612 val_acc: 0.4151\n",
            "Epoch 9: train_loss: 1.0175 train_acc: 0.5593 | val_loss: 1.4189 val_acc: 0.4242\n",
            "Epoch 10: train_loss: 0.9436 train_acc: 0.5947 | val_loss: 1.4488 val_acc: 0.3942\n",
            "Epoch 11: train_loss: 0.8532 train_acc: 0.6458 | val_loss: 1.6027 val_acc: 0.4196\n",
            "Epoch 12: train_loss: 0.7537 train_acc: 0.6956 | val_loss: 1.7699 val_acc: 0.3960\n",
            "Epoch 13: train_loss: 0.6490 train_acc: 0.7417 | val_loss: 1.8702 val_acc: 0.3869\n",
            "Epoch 14: train_loss: 0.5416 train_acc: 0.7890 | val_loss: 2.0296 val_acc: 0.4042\n",
            "Epoch 15: train_loss: 0.4553 train_acc: 0.8311 | val_loss: 2.3557 val_acc: 0.3969\n",
            "Epoch 16: train_loss: 0.3558 train_acc: 0.8706 | val_loss: 2.6361 val_acc: 0.3733\n",
            "Epoch 17: train_loss: 0.2870 train_acc: 0.8983 | val_loss: 2.6350 val_acc: 0.3842\n",
            "Epoch 18: train_loss: 0.2434 train_acc: 0.9127 | val_loss: 2.8359 val_acc: 0.3806\n",
            "Epoch 19: train_loss: 0.1995 train_acc: 0.9280 | val_loss: 2.9677 val_acc: 0.3787\n",
            "Epoch 20: train_loss: 0.1730 train_acc: 0.9404 | val_loss: 3.0399 val_acc: 0.3824\n",
            "Epoch 21: train_loss: 0.1458 train_acc: 0.9478 | val_loss: 3.4092 val_acc: 0.3915\n",
            "Epoch 22: train_loss: 0.1276 train_acc: 0.9563 | val_loss: 3.5219 val_acc: 0.4078\n",
            "Epoch 23: train_loss: 0.1076 train_acc: 0.9638 | val_loss: 3.5160 val_acc: 0.3842\n",
            "Epoch 24: train_loss: 0.0826 train_acc: 0.9731 | val_loss: 3.5851 val_acc: 0.3906\n",
            "Lowest val_loss: 1.2965, at epoch 5\n",
            "GRU 250 1 [30]\n",
            "Epoch 0: train_loss: 1.5774 train_acc: 0.2537 | val_loss: 1.5645 val_acc: 0.2661\n",
            "Epoch 1: train_loss: 1.5675 train_acc: 0.2722 | val_loss: 1.5643 val_acc: 0.2679\n",
            "Epoch 2: train_loss: 1.4327 train_acc: 0.3535 | val_loss: 1.4167 val_acc: 0.3551\n",
            "Epoch 3: train_loss: 1.2543 train_acc: 0.4381 | val_loss: 1.3375 val_acc: 0.4069\n",
            "Epoch 4: train_loss: 1.1942 train_acc: 0.4684 | val_loss: 1.3433 val_acc: 0.4042\n",
            "Epoch 5: train_loss: 1.1518 train_acc: 0.4892 | val_loss: 1.3760 val_acc: 0.4124\n",
            "Epoch 6: train_loss: 1.1107 train_acc: 0.5133 | val_loss: 1.3789 val_acc: 0.4024\n",
            "Epoch 7: train_loss: 1.0531 train_acc: 0.5415 | val_loss: 1.3579 val_acc: 0.3996\n",
            "Epoch 8: train_loss: 0.9949 train_acc: 0.5732 | val_loss: 1.3666 val_acc: 0.4160\n",
            "Epoch 9: train_loss: 0.9258 train_acc: 0.6083 | val_loss: 1.4813 val_acc: 0.3960\n",
            "Epoch 10: train_loss: 0.8554 train_acc: 0.6390 | val_loss: 1.4409 val_acc: 0.4178\n",
            "Epoch 11: train_loss: 0.7634 train_acc: 0.6905 | val_loss: 1.5664 val_acc: 0.4051\n",
            "Epoch 12: train_loss: 0.6618 train_acc: 0.7431 | val_loss: 1.7071 val_acc: 0.3996\n",
            "Epoch 13: train_loss: 0.5778 train_acc: 0.7801 | val_loss: 1.7700 val_acc: 0.4105\n",
            "Epoch 14: train_loss: 0.4939 train_acc: 0.8166 | val_loss: 1.7604 val_acc: 0.4005\n",
            "Epoch 15: train_loss: 0.3947 train_acc: 0.8570 | val_loss: 1.9466 val_acc: 0.4242\n",
            "Epoch 16: train_loss: 0.3324 train_acc: 0.8837 | val_loss: 2.1877 val_acc: 0.3906\n",
            "Epoch 17: train_loss: 0.2704 train_acc: 0.9085 | val_loss: 2.3225 val_acc: 0.3987\n",
            "Epoch 18: train_loss: 0.2337 train_acc: 0.9204 | val_loss: 2.3238 val_acc: 0.4015\n",
            "Epoch 19: train_loss: 0.1931 train_acc: 0.9347 | val_loss: 2.4269 val_acc: 0.3896\n",
            "Epoch 20: train_loss: 0.1468 train_acc: 0.9528 | val_loss: 2.4691 val_acc: 0.4151\n",
            "Epoch 21: train_loss: 0.1490 train_acc: 0.9504 | val_loss: 2.5094 val_acc: 0.3896\n",
            "Epoch 22: train_loss: 0.1275 train_acc: 0.9585 | val_loss: 2.6317 val_acc: 0.3987\n",
            "Epoch 23: train_loss: 0.0978 train_acc: 0.9705 | val_loss: 2.7481 val_acc: 0.4033\n",
            "Epoch 24: train_loss: 0.0940 train_acc: 0.9709 | val_loss: 2.8279 val_acc: 0.4114\n",
            "Lowest val_loss: 1.3375, at epoch 3\n",
            "GRU 250 1 [40]\n",
            "Epoch 0: train_loss: 1.5752 train_acc: 0.2721 | val_loss: 1.5768 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5684 train_acc: 0.2719 | val_loss: 1.5746 val_acc: 0.2589\n",
            "Epoch 2: train_loss: 1.5677 train_acc: 0.2649 | val_loss: 1.5556 val_acc: 0.2625\n",
            "Epoch 3: train_loss: 1.5644 train_acc: 0.2705 | val_loss: 1.5989 val_acc: 0.2725\n",
            "Epoch 4: train_loss: 1.3704 train_acc: 0.3892 | val_loss: 1.3255 val_acc: 0.4151\n",
            "Epoch 5: train_loss: 1.2388 train_acc: 0.4431 | val_loss: 1.3277 val_acc: 0.3996\n",
            "Epoch 6: train_loss: 1.1876 train_acc: 0.4629 | val_loss: 1.3294 val_acc: 0.4169\n",
            "Epoch 7: train_loss: 1.1317 train_acc: 0.5061 | val_loss: 1.3271 val_acc: 0.4124\n",
            "Epoch 8: train_loss: 1.0754 train_acc: 0.5242 | val_loss: 1.3483 val_acc: 0.4069\n",
            "Epoch 9: train_loss: 1.0156 train_acc: 0.5620 | val_loss: 1.3772 val_acc: 0.4105\n",
            "Epoch 10: train_loss: 0.9379 train_acc: 0.6004 | val_loss: 1.4319 val_acc: 0.4069\n",
            "Epoch 11: train_loss: 0.8595 train_acc: 0.6401 | val_loss: 1.5006 val_acc: 0.4133\n",
            "Epoch 12: train_loss: 0.7582 train_acc: 0.6914 | val_loss: 1.5892 val_acc: 0.4042\n",
            "Epoch 13: train_loss: 0.6514 train_acc: 0.7404 | val_loss: 1.7667 val_acc: 0.3769\n",
            "Epoch 14: train_loss: 0.5398 train_acc: 0.7983 | val_loss: 1.9620 val_acc: 0.4051\n",
            "Epoch 15: train_loss: 0.4555 train_acc: 0.8316 | val_loss: 2.0977 val_acc: 0.3978\n",
            "Epoch 16: train_loss: 0.3734 train_acc: 0.8638 | val_loss: 2.0136 val_acc: 0.3815\n",
            "Epoch 17: train_loss: 0.3098 train_acc: 0.8890 | val_loss: 2.2568 val_acc: 0.3869\n",
            "Epoch 18: train_loss: 0.2565 train_acc: 0.9107 | val_loss: 2.4410 val_acc: 0.3942\n",
            "Epoch 19: train_loss: 0.2144 train_acc: 0.9268 | val_loss: 2.4472 val_acc: 0.3769\n",
            "Epoch 20: train_loss: 0.1833 train_acc: 0.9403 | val_loss: 2.4544 val_acc: 0.3951\n",
            "Epoch 21: train_loss: 0.1451 train_acc: 0.9507 | val_loss: 2.6934 val_acc: 0.3742\n",
            "Epoch 22: train_loss: 0.1349 train_acc: 0.9538 | val_loss: 2.7747 val_acc: 0.3851\n",
            "Epoch 23: train_loss: 0.1158 train_acc: 0.9620 | val_loss: 2.8445 val_acc: 0.3824\n",
            "Epoch 24: train_loss: 0.1186 train_acc: 0.9593 | val_loss: 2.7521 val_acc: 0.3669\n",
            "Lowest val_loss: 1.3255, at epoch 4\n",
            "GRU 250 1 [50]\n",
            "Epoch 0: train_loss: 1.5725 train_acc: 0.2715 | val_loss: 1.5911 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2683 | val_loss: 1.5692 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5668 train_acc: 0.2667 | val_loss: 1.5933 val_acc: 0.2452\n",
            "Epoch 3: train_loss: 1.5664 train_acc: 0.2742 | val_loss: 1.5653 val_acc: 0.2788\n",
            "Epoch 4: train_loss: 1.5618 train_acc: 0.2765 | val_loss: 1.5586 val_acc: 0.2516\n",
            "Epoch 5: train_loss: 1.5566 train_acc: 0.2823 | val_loss: 1.4624 val_acc: 0.3515\n",
            "Epoch 6: train_loss: 1.3687 train_acc: 0.3974 | val_loss: 1.4048 val_acc: 0.3678\n",
            "Epoch 7: train_loss: 1.2501 train_acc: 0.4384 | val_loss: 1.3459 val_acc: 0.4005\n",
            "Epoch 8: train_loss: 1.1844 train_acc: 0.4680 | val_loss: 1.3477 val_acc: 0.4151\n",
            "Epoch 9: train_loss: 1.1333 train_acc: 0.4985 | val_loss: 1.3577 val_acc: 0.3996\n",
            "Epoch 10: train_loss: 1.0712 train_acc: 0.5297 | val_loss: 1.3843 val_acc: 0.3851\n",
            "Epoch 11: train_loss: 1.0030 train_acc: 0.5657 | val_loss: 1.4183 val_acc: 0.3996\n",
            "Epoch 12: train_loss: 0.9087 train_acc: 0.6100 | val_loss: 1.4785 val_acc: 0.3960\n",
            "Epoch 13: train_loss: 0.8206 train_acc: 0.6573 | val_loss: 1.6091 val_acc: 0.4051\n",
            "Epoch 14: train_loss: 0.7071 train_acc: 0.7170 | val_loss: 1.6629 val_acc: 0.3960\n",
            "Epoch 15: train_loss: 0.6139 train_acc: 0.7587 | val_loss: 1.7305 val_acc: 0.4024\n",
            "Epoch 16: train_loss: 0.5005 train_acc: 0.8131 | val_loss: 2.0203 val_acc: 0.3760\n",
            "Epoch 17: train_loss: 0.3960 train_acc: 0.8593 | val_loss: 2.1511 val_acc: 0.3933\n",
            "Epoch 18: train_loss: 0.3213 train_acc: 0.8869 | val_loss: 2.2458 val_acc: 0.3824\n",
            "Epoch 19: train_loss: 0.2631 train_acc: 0.9110 | val_loss: 2.2853 val_acc: 0.3869\n",
            "Epoch 20: train_loss: 0.2191 train_acc: 0.9243 | val_loss: 2.5637 val_acc: 0.3878\n",
            "Epoch 21: train_loss: 0.1851 train_acc: 0.9400 | val_loss: 2.6058 val_acc: 0.3824\n",
            "Epoch 22: train_loss: 0.1568 train_acc: 0.9493 | val_loss: 2.5492 val_acc: 0.3896\n",
            "Epoch 23: train_loss: 0.1336 train_acc: 0.9565 | val_loss: 2.7249 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 0.1207 train_acc: 0.9613 | val_loss: 2.7525 val_acc: 0.3915\n",
            "Lowest val_loss: 1.3459, at epoch 7\n",
            "GRU 250 1 [60]\n",
            "Epoch 0: train_loss: 1.5729 train_acc: 0.2671 | val_loss: 1.5711 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2714 | val_loss: 1.5666 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5612 train_acc: 0.2801 | val_loss: 1.4770 val_acc: 0.3642\n",
            "Epoch 3: train_loss: 1.3234 train_acc: 0.4114 | val_loss: 1.3696 val_acc: 0.4205\n",
            "Epoch 4: train_loss: 1.2321 train_acc: 0.4492 | val_loss: 1.3528 val_acc: 0.4178\n",
            "Epoch 5: train_loss: 1.1720 train_acc: 0.4819 | val_loss: 1.3226 val_acc: 0.4260\n",
            "Epoch 6: train_loss: 1.1240 train_acc: 0.5037 | val_loss: 1.3639 val_acc: 0.4124\n",
            "Epoch 7: train_loss: 1.0807 train_acc: 0.5243 | val_loss: 1.3675 val_acc: 0.4105\n",
            "Epoch 8: train_loss: 1.0138 train_acc: 0.5626 | val_loss: 1.3600 val_acc: 0.4024\n",
            "Epoch 9: train_loss: 0.9478 train_acc: 0.5981 | val_loss: 1.4208 val_acc: 0.4142\n",
            "Epoch 10: train_loss: 0.8681 train_acc: 0.6372 | val_loss: 1.5306 val_acc: 0.4042\n",
            "Epoch 11: train_loss: 0.7662 train_acc: 0.6883 | val_loss: 1.6684 val_acc: 0.4033\n",
            "Epoch 12: train_loss: 0.6814 train_acc: 0.7320 | val_loss: 1.6869 val_acc: 0.3915\n",
            "Epoch 13: train_loss: 0.5840 train_acc: 0.7707 | val_loss: 1.8733 val_acc: 0.3969\n",
            "Epoch 14: train_loss: 0.4937 train_acc: 0.8114 | val_loss: 1.9885 val_acc: 0.3951\n",
            "Epoch 15: train_loss: 0.4142 train_acc: 0.8457 | val_loss: 2.1588 val_acc: 0.3878\n",
            "Epoch 16: train_loss: 0.3476 train_acc: 0.8758 | val_loss: 2.1918 val_acc: 0.4051\n",
            "Epoch 17: train_loss: 0.2815 train_acc: 0.9019 | val_loss: 2.2945 val_acc: 0.3951\n",
            "Epoch 18: train_loss: 0.2343 train_acc: 0.9182 | val_loss: 2.5006 val_acc: 0.4078\n",
            "Epoch 19: train_loss: 0.2037 train_acc: 0.9291 | val_loss: 2.4399 val_acc: 0.3942\n",
            "Epoch 20: train_loss: 0.1600 train_acc: 0.9459 | val_loss: 2.6748 val_acc: 0.3951\n",
            "Epoch 21: train_loss: 0.1538 train_acc: 0.9458 | val_loss: 2.5768 val_acc: 0.4133\n",
            "Epoch 22: train_loss: 0.1411 train_acc: 0.9514 | val_loss: 2.7431 val_acc: 0.3969\n",
            "Epoch 23: train_loss: 0.1040 train_acc: 0.9665 | val_loss: 2.9191 val_acc: 0.3896\n",
            "Epoch 24: train_loss: 0.0908 train_acc: 0.9690 | val_loss: 3.0132 val_acc: 0.3978\n",
            "Lowest val_loss: 1.3226, at epoch 5\n",
            "GRU 250 1 [70]\n",
            "Epoch 0: train_loss: 1.5741 train_acc: 0.2683 | val_loss: 1.5884 val_acc: 0.2761\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2719 | val_loss: 1.5708 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5680 train_acc: 0.2666 | val_loss: 1.5588 val_acc: 0.2561\n",
            "Epoch 3: train_loss: 1.4841 train_acc: 0.3346 | val_loss: 1.3811 val_acc: 0.3733\n",
            "Epoch 4: train_loss: 1.2661 train_acc: 0.4388 | val_loss: 1.3328 val_acc: 0.4142\n",
            "Epoch 5: train_loss: 1.1965 train_acc: 0.4730 | val_loss: 1.3197 val_acc: 0.4124\n",
            "Epoch 6: train_loss: 1.1477 train_acc: 0.4925 | val_loss: 1.3358 val_acc: 0.4133\n",
            "Epoch 7: train_loss: 1.0954 train_acc: 0.5228 | val_loss: 1.3393 val_acc: 0.4278\n",
            "Epoch 8: train_loss: 1.0335 train_acc: 0.5559 | val_loss: 1.3547 val_acc: 0.4196\n",
            "Epoch 9: train_loss: 0.9650 train_acc: 0.5868 | val_loss: 1.4112 val_acc: 0.4296\n",
            "Epoch 10: train_loss: 0.8813 train_acc: 0.6320 | val_loss: 1.5405 val_acc: 0.4042\n",
            "Epoch 11: train_loss: 0.7832 train_acc: 0.6784 | val_loss: 1.6397 val_acc: 0.4033\n",
            "Epoch 12: train_loss: 0.6801 train_acc: 0.7275 | val_loss: 1.7396 val_acc: 0.4060\n",
            "Epoch 13: train_loss: 0.5928 train_acc: 0.7680 | val_loss: 1.9166 val_acc: 0.3987\n",
            "Epoch 14: train_loss: 0.4976 train_acc: 0.8179 | val_loss: 2.0569 val_acc: 0.4096\n",
            "Epoch 15: train_loss: 0.3955 train_acc: 0.8577 | val_loss: 2.1755 val_acc: 0.3933\n",
            "Epoch 16: train_loss: 0.3350 train_acc: 0.8828 | val_loss: 2.4208 val_acc: 0.3942\n",
            "Epoch 17: train_loss: 0.2662 train_acc: 0.9078 | val_loss: 2.4183 val_acc: 0.3951\n",
            "Epoch 18: train_loss: 0.2444 train_acc: 0.9182 | val_loss: 2.5642 val_acc: 0.3806\n",
            "Epoch 19: train_loss: 0.1877 train_acc: 0.9376 | val_loss: 2.6957 val_acc: 0.3751\n",
            "Epoch 20: train_loss: 0.1579 train_acc: 0.9467 | val_loss: 2.8154 val_acc: 0.3906\n",
            "Epoch 21: train_loss: 0.1238 train_acc: 0.9585 | val_loss: 2.9434 val_acc: 0.3842\n",
            "Epoch 22: train_loss: 0.1200 train_acc: 0.9602 | val_loss: 3.0261 val_acc: 0.3806\n",
            "Epoch 23: train_loss: 0.0895 train_acc: 0.9728 | val_loss: 3.1486 val_acc: 0.3806\n",
            "Epoch 24: train_loss: 0.0897 train_acc: 0.9724 | val_loss: 3.2200 val_acc: 0.3933\n",
            "Lowest val_loss: 1.3197, at epoch 5\n",
            "GRU 250 2 [30]\n",
            "Epoch 0: train_loss: 1.5723 train_acc: 0.2665 | val_loss: 1.5889 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5701 train_acc: 0.2727 | val_loss: 1.5684 val_acc: 0.2861\n",
            "Epoch 2: train_loss: 1.5150 train_acc: 0.3159 | val_loss: 1.3706 val_acc: 0.3806\n",
            "Epoch 3: train_loss: 1.3025 train_acc: 0.4123 | val_loss: 1.3211 val_acc: 0.3824\n",
            "Epoch 4: train_loss: 1.2219 train_acc: 0.4546 | val_loss: 1.3235 val_acc: 0.4087\n",
            "Epoch 5: train_loss: 1.1753 train_acc: 0.4803 | val_loss: 1.3235 val_acc: 0.4178\n",
            "Epoch 6: train_loss: 1.1180 train_acc: 0.5112 | val_loss: 1.3202 val_acc: 0.4260\n",
            "Epoch 7: train_loss: 1.0513 train_acc: 0.5384 | val_loss: 1.4056 val_acc: 0.4114\n",
            "Epoch 8: train_loss: 0.9891 train_acc: 0.5775 | val_loss: 1.4298 val_acc: 0.4178\n",
            "Epoch 9: train_loss: 0.8981 train_acc: 0.6225 | val_loss: 1.5494 val_acc: 0.4242\n",
            "Epoch 10: train_loss: 0.8231 train_acc: 0.6547 | val_loss: 1.6551 val_acc: 0.4087\n",
            "Epoch 11: train_loss: 0.7206 train_acc: 0.7058 | val_loss: 1.6556 val_acc: 0.4151\n",
            "Epoch 12: train_loss: 0.6235 train_acc: 0.7576 | val_loss: 1.9230 val_acc: 0.3751\n",
            "Epoch 13: train_loss: 0.5149 train_acc: 0.8017 | val_loss: 2.1607 val_acc: 0.4160\n",
            "Epoch 14: train_loss: 0.4307 train_acc: 0.8367 | val_loss: 2.1520 val_acc: 0.4233\n",
            "Epoch 15: train_loss: 0.3521 train_acc: 0.8628 | val_loss: 2.3777 val_acc: 0.3960\n",
            "Epoch 16: train_loss: 0.2754 train_acc: 0.9023 | val_loss: 2.4452 val_acc: 0.4124\n",
            "Epoch 17: train_loss: 0.2170 train_acc: 0.9224 | val_loss: 2.7884 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 0.1681 train_acc: 0.9442 | val_loss: 2.9421 val_acc: 0.4114\n",
            "Epoch 19: train_loss: 0.1302 train_acc: 0.9548 | val_loss: 3.0613 val_acc: 0.4078\n",
            "Epoch 20: train_loss: 0.1401 train_acc: 0.9531 | val_loss: 3.0642 val_acc: 0.4096\n",
            "Epoch 21: train_loss: 0.1266 train_acc: 0.9554 | val_loss: 3.1816 val_acc: 0.3824\n",
            "Epoch 22: train_loss: 0.0764 train_acc: 0.9764 | val_loss: 3.4680 val_acc: 0.3942\n",
            "Epoch 23: train_loss: 0.0822 train_acc: 0.9721 | val_loss: 3.4735 val_acc: 0.3915\n",
            "Epoch 24: train_loss: 0.0709 train_acc: 0.9771 | val_loss: 3.3635 val_acc: 0.3815\n",
            "Lowest val_loss: 1.3202, at epoch 6\n",
            "GRU 250 2 [40]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2618 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5707 train_acc: 0.2692 | val_loss: 1.5773 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5288 train_acc: 0.2963 | val_loss: 1.3776 val_acc: 0.3869\n",
            "Epoch 3: train_loss: 1.2992 train_acc: 0.4191 | val_loss: 1.3243 val_acc: 0.4142\n",
            "Epoch 4: train_loss: 1.2272 train_acc: 0.4489 | val_loss: 1.2875 val_acc: 0.4178\n",
            "Epoch 5: train_loss: 1.1746 train_acc: 0.4788 | val_loss: 1.3253 val_acc: 0.4178\n",
            "Epoch 6: train_loss: 1.1300 train_acc: 0.5059 | val_loss: 1.3532 val_acc: 0.4033\n",
            "Epoch 7: train_loss: 1.0801 train_acc: 0.5215 | val_loss: 1.3990 val_acc: 0.4105\n",
            "Epoch 8: train_loss: 1.0201 train_acc: 0.5536 | val_loss: 1.3627 val_acc: 0.4251\n",
            "Epoch 9: train_loss: 0.9539 train_acc: 0.5920 | val_loss: 1.4238 val_acc: 0.4160\n",
            "Epoch 10: train_loss: 0.8723 train_acc: 0.6355 | val_loss: 1.5215 val_acc: 0.4069\n",
            "Epoch 11: train_loss: 0.7830 train_acc: 0.6785 | val_loss: 1.6644 val_acc: 0.4042\n",
            "Epoch 12: train_loss: 0.6974 train_acc: 0.7204 | val_loss: 1.7187 val_acc: 0.4151\n",
            "Epoch 13: train_loss: 0.5970 train_acc: 0.7660 | val_loss: 1.9990 val_acc: 0.4133\n",
            "Epoch 14: train_loss: 0.4986 train_acc: 0.8097 | val_loss: 2.0562 val_acc: 0.3851\n",
            "Epoch 15: train_loss: 0.4108 train_acc: 0.8518 | val_loss: 2.1854 val_acc: 0.3860\n",
            "Epoch 16: train_loss: 0.3341 train_acc: 0.8807 | val_loss: 2.4283 val_acc: 0.3896\n",
            "Epoch 17: train_loss: 0.2828 train_acc: 0.8984 | val_loss: 2.7333 val_acc: 0.3960\n",
            "Epoch 18: train_loss: 0.2373 train_acc: 0.9148 | val_loss: 2.8747 val_acc: 0.3760\n",
            "Epoch 19: train_loss: 0.1949 train_acc: 0.9318 | val_loss: 2.9317 val_acc: 0.3815\n",
            "Epoch 20: train_loss: 0.1568 train_acc: 0.9456 | val_loss: 2.9154 val_acc: 0.3833\n",
            "Epoch 21: train_loss: 0.1612 train_acc: 0.9456 | val_loss: 2.9317 val_acc: 0.3678\n",
            "Epoch 22: train_loss: 0.1291 train_acc: 0.9560 | val_loss: 3.2283 val_acc: 0.3769\n",
            "Epoch 23: train_loss: 0.0916 train_acc: 0.9700 | val_loss: 3.4327 val_acc: 0.3669\n",
            "Epoch 24: train_loss: 0.0963 train_acc: 0.9680 | val_loss: 3.5314 val_acc: 0.3669\n",
            "Lowest val_loss: 1.2875, at epoch 4\n",
            "GRU 250 2 [50]\n",
            "Epoch 0: train_loss: 1.5744 train_acc: 0.2628 | val_loss: 1.5824 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5702 train_acc: 0.2652 | val_loss: 1.5665 val_acc: 0.3106\n",
            "Epoch 2: train_loss: 1.5447 train_acc: 0.3010 | val_loss: 1.4237 val_acc: 0.3315\n",
            "Epoch 3: train_loss: 1.3165 train_acc: 0.4070 | val_loss: 1.3240 val_acc: 0.4024\n",
            "Epoch 4: train_loss: 1.2307 train_acc: 0.4462 | val_loss: 1.3079 val_acc: 0.4078\n",
            "Epoch 5: train_loss: 1.1849 train_acc: 0.4673 | val_loss: 1.3900 val_acc: 0.4033\n",
            "Epoch 6: train_loss: 1.1314 train_acc: 0.4995 | val_loss: 1.3557 val_acc: 0.4005\n",
            "Epoch 7: train_loss: 1.0755 train_acc: 0.5270 | val_loss: 1.3947 val_acc: 0.4060\n",
            "Epoch 8: train_loss: 1.0104 train_acc: 0.5507 | val_loss: 1.4174 val_acc: 0.4114\n",
            "Epoch 9: train_loss: 0.9289 train_acc: 0.6050 | val_loss: 1.5048 val_acc: 0.4296\n",
            "Epoch 10: train_loss: 0.8466 train_acc: 0.6427 | val_loss: 1.6441 val_acc: 0.4087\n",
            "Epoch 11: train_loss: 0.7494 train_acc: 0.6900 | val_loss: 1.6626 val_acc: 0.4178\n",
            "Epoch 12: train_loss: 0.6556 train_acc: 0.7363 | val_loss: 1.8476 val_acc: 0.3787\n",
            "Epoch 13: train_loss: 0.5587 train_acc: 0.7800 | val_loss: 1.9872 val_acc: 0.4087\n",
            "Epoch 14: train_loss: 0.4930 train_acc: 0.8083 | val_loss: 2.2885 val_acc: 0.4096\n",
            "Epoch 15: train_loss: 0.3937 train_acc: 0.8531 | val_loss: 2.2982 val_acc: 0.3924\n",
            "Epoch 16: train_loss: 0.3279 train_acc: 0.8765 | val_loss: 2.5206 val_acc: 0.3778\n",
            "Epoch 17: train_loss: 0.2738 train_acc: 0.9027 | val_loss: 2.6907 val_acc: 0.4033\n",
            "Epoch 18: train_loss: 0.2233 train_acc: 0.9229 | val_loss: 2.8342 val_acc: 0.4105\n",
            "Epoch 19: train_loss: 0.1922 train_acc: 0.9315 | val_loss: 2.9998 val_acc: 0.3951\n",
            "Epoch 20: train_loss: 0.1508 train_acc: 0.9482 | val_loss: 3.1086 val_acc: 0.4078\n",
            "Epoch 21: train_loss: 0.1442 train_acc: 0.9500 | val_loss: 3.2410 val_acc: 0.3987\n",
            "Epoch 22: train_loss: 0.1231 train_acc: 0.9592 | val_loss: 3.1950 val_acc: 0.3942\n",
            "Epoch 23: train_loss: 0.1015 train_acc: 0.9662 | val_loss: 3.3725 val_acc: 0.4005\n",
            "Epoch 24: train_loss: 0.0718 train_acc: 0.9753 | val_loss: 3.5819 val_acc: 0.4060\n",
            "Lowest val_loss: 1.3079, at epoch 4\n",
            "GRU 250 2 [60]\n",
            "Epoch 0: train_loss: 1.5742 train_acc: 0.2651 | val_loss: 1.5721 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5694 train_acc: 0.2672 | val_loss: 1.5705 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5486 train_acc: 0.2852 | val_loss: 1.3785 val_acc: 0.3960\n",
            "Epoch 3: train_loss: 1.3078 train_acc: 0.4174 | val_loss: 1.3274 val_acc: 0.4251\n",
            "Epoch 4: train_loss: 1.2179 train_acc: 0.4555 | val_loss: 1.3289 val_acc: 0.4205\n",
            "Epoch 5: train_loss: 1.1671 train_acc: 0.4809 | val_loss: 1.3223 val_acc: 0.4251\n",
            "Epoch 6: train_loss: 1.1167 train_acc: 0.5154 | val_loss: 1.3648 val_acc: 0.4305\n",
            "Epoch 7: train_loss: 1.0562 train_acc: 0.5401 | val_loss: 1.4065 val_acc: 0.4269\n",
            "Epoch 8: train_loss: 0.9932 train_acc: 0.5740 | val_loss: 1.3935 val_acc: 0.4114\n",
            "Epoch 9: train_loss: 0.9096 train_acc: 0.6132 | val_loss: 1.4746 val_acc: 0.4060\n",
            "Epoch 10: train_loss: 0.8172 train_acc: 0.6635 | val_loss: 1.6569 val_acc: 0.4078\n",
            "Epoch 11: train_loss: 0.7089 train_acc: 0.7156 | val_loss: 1.8167 val_acc: 0.3996\n",
            "Epoch 12: train_loss: 0.6010 train_acc: 0.7642 | val_loss: 1.9753 val_acc: 0.4169\n",
            "Epoch 13: train_loss: 0.5023 train_acc: 0.8118 | val_loss: 2.1094 val_acc: 0.4223\n",
            "Epoch 14: train_loss: 0.3944 train_acc: 0.8533 | val_loss: 2.3669 val_acc: 0.3942\n",
            "Epoch 15: train_loss: 0.3097 train_acc: 0.8907 | val_loss: 2.6327 val_acc: 0.3815\n",
            "Epoch 16: train_loss: 0.2722 train_acc: 0.8992 | val_loss: 2.6469 val_acc: 0.3896\n",
            "Epoch 17: train_loss: 0.2144 train_acc: 0.9256 | val_loss: 2.7777 val_acc: 0.4005\n",
            "Epoch 18: train_loss: 0.1708 train_acc: 0.9417 | val_loss: 3.0409 val_acc: 0.4142\n",
            "Epoch 19: train_loss: 0.1254 train_acc: 0.9579 | val_loss: 3.2156 val_acc: 0.3969\n",
            "Epoch 20: train_loss: 0.1269 train_acc: 0.9566 | val_loss: 3.3057 val_acc: 0.4142\n",
            "Epoch 21: train_loss: 0.1039 train_acc: 0.9658 | val_loss: 3.2797 val_acc: 0.3987\n",
            "Epoch 22: train_loss: 0.0860 train_acc: 0.9724 | val_loss: 3.4785 val_acc: 0.4005\n",
            "Epoch 23: train_loss: 0.0653 train_acc: 0.9790 | val_loss: 3.6462 val_acc: 0.3978\n",
            "Epoch 24: train_loss: 0.0639 train_acc: 0.9807 | val_loss: 3.6025 val_acc: 0.4005\n",
            "Lowest val_loss: 1.3223, at epoch 5\n",
            "GRU 250 2 [70]\n",
            "Epoch 0: train_loss: 1.5710 train_acc: 0.2707 | val_loss: 1.5743 val_acc: 0.2552\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2746 | val_loss: 1.5652 val_acc: 0.2861\n",
            "Epoch 2: train_loss: 1.4873 train_acc: 0.3285 | val_loss: 1.3385 val_acc: 0.3978\n",
            "Epoch 3: train_loss: 1.2704 train_acc: 0.4285 | val_loss: 1.3628 val_acc: 0.4105\n",
            "Epoch 4: train_loss: 1.2086 train_acc: 0.4594 | val_loss: 1.2981 val_acc: 0.4278\n",
            "Epoch 5: train_loss: 1.1677 train_acc: 0.4823 | val_loss: 1.3019 val_acc: 0.4242\n",
            "Epoch 6: train_loss: 1.1218 train_acc: 0.5036 | val_loss: 1.3540 val_acc: 0.4142\n",
            "Epoch 7: train_loss: 1.0636 train_acc: 0.5341 | val_loss: 1.4018 val_acc: 0.4169\n",
            "Epoch 8: train_loss: 1.0058 train_acc: 0.5607 | val_loss: 1.4015 val_acc: 0.4078\n",
            "Epoch 9: train_loss: 0.9353 train_acc: 0.6003 | val_loss: 1.4600 val_acc: 0.4287\n",
            "Epoch 10: train_loss: 0.8370 train_acc: 0.6537 | val_loss: 1.6146 val_acc: 0.4124\n",
            "Epoch 11: train_loss: 0.7587 train_acc: 0.6918 | val_loss: 1.8391 val_acc: 0.4423\n",
            "Epoch 12: train_loss: 0.6522 train_acc: 0.7415 | val_loss: 2.0305 val_acc: 0.4078\n",
            "Epoch 13: train_loss: 0.5529 train_acc: 0.7865 | val_loss: 2.0706 val_acc: 0.4015\n",
            "Epoch 14: train_loss: 0.4644 train_acc: 0.8208 | val_loss: 2.2391 val_acc: 0.3933\n",
            "Epoch 15: train_loss: 0.3790 train_acc: 0.8626 | val_loss: 2.4687 val_acc: 0.4078\n",
            "Epoch 16: train_loss: 0.3190 train_acc: 0.8864 | val_loss: 2.6936 val_acc: 0.3987\n",
            "Epoch 17: train_loss: 0.2605 train_acc: 0.9095 | val_loss: 2.9004 val_acc: 0.3924\n",
            "Epoch 18: train_loss: 0.2090 train_acc: 0.9272 | val_loss: 3.0111 val_acc: 0.3996\n",
            "Epoch 19: train_loss: 0.1774 train_acc: 0.9400 | val_loss: 3.1748 val_acc: 0.3906\n",
            "Epoch 20: train_loss: 0.1426 train_acc: 0.9515 | val_loss: 3.2679 val_acc: 0.3878\n",
            "Epoch 21: train_loss: 0.1588 train_acc: 0.9448 | val_loss: 3.4548 val_acc: 0.3815\n",
            "Epoch 22: train_loss: 0.1344 train_acc: 0.9532 | val_loss: 3.5673 val_acc: 0.3833\n",
            "Epoch 23: train_loss: 0.0942 train_acc: 0.9690 | val_loss: 3.7464 val_acc: 0.3860\n",
            "Epoch 24: train_loss: 0.0631 train_acc: 0.9807 | val_loss: 3.8883 val_acc: 0.3824\n",
            "Lowest val_loss: 1.2981, at epoch 4\n",
            "LSTM 30 1 [30]\n",
            "Epoch 0: train_loss: 1.5742 train_acc: 0.2718 | val_loss: 1.5743 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2702 | val_loss: 1.5732 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5678 train_acc: 0.2711 | val_loss: 1.5693 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2691 | val_loss: 1.5638 val_acc: 0.2552\n",
            "Epoch 4: train_loss: 1.5606 train_acc: 0.2783 | val_loss: 1.5601 val_acc: 0.2897\n",
            "Epoch 5: train_loss: 1.5158 train_acc: 0.3269 | val_loss: 1.5289 val_acc: 0.2897\n",
            "Epoch 6: train_loss: 1.4854 train_acc: 0.3537 | val_loss: 1.5121 val_acc: 0.3524\n",
            "Epoch 7: train_loss: 1.4981 train_acc: 0.3483 | val_loss: 1.4882 val_acc: 0.3460\n",
            "Epoch 8: train_loss: 1.4825 train_acc: 0.3546 | val_loss: 1.4779 val_acc: 0.3442\n",
            "Epoch 9: train_loss: 1.5020 train_acc: 0.3384 | val_loss: 1.4887 val_acc: 0.3651\n",
            "Epoch 10: train_loss: 1.5638 train_acc: 0.2704 | val_loss: 1.5674 val_acc: 0.2816\n",
            "Epoch 11: train_loss: 1.5682 train_acc: 0.2719 | val_loss: 1.5667 val_acc: 0.2670\n",
            "Epoch 12: train_loss: 1.5694 train_acc: 0.2630 | val_loss: 1.5665 val_acc: 0.2825\n",
            "Epoch 13: train_loss: 1.5684 train_acc: 0.2673 | val_loss: 1.5645 val_acc: 0.2834\n",
            "Epoch 14: train_loss: 1.5682 train_acc: 0.2666 | val_loss: 1.5643 val_acc: 0.2834\n",
            "Epoch 15: train_loss: 1.5680 train_acc: 0.2720 | val_loss: 1.5646 val_acc: 0.2816\n",
            "Epoch 16: train_loss: 1.5685 train_acc: 0.2660 | val_loss: 1.5643 val_acc: 0.2816\n",
            "Epoch 17: train_loss: 1.5684 train_acc: 0.2692 | val_loss: 1.5652 val_acc: 0.2816\n",
            "Epoch 18: train_loss: 1.5682 train_acc: 0.2721 | val_loss: 1.5634 val_acc: 0.2807\n",
            "Epoch 19: train_loss: 1.5683 train_acc: 0.2721 | val_loss: 1.5634 val_acc: 0.2825\n",
            "Epoch 20: train_loss: 1.5683 train_acc: 0.2685 | val_loss: 1.5618 val_acc: 0.2834\n",
            "Epoch 21: train_loss: 1.5680 train_acc: 0.2724 | val_loss: 1.5577 val_acc: 0.2934\n",
            "Epoch 22: train_loss: 1.5667 train_acc: 0.2713 | val_loss: 1.5534 val_acc: 0.2952\n",
            "Epoch 23: train_loss: 1.5319 train_acc: 0.3174 | val_loss: 1.4960 val_acc: 0.3470\n",
            "Epoch 24: train_loss: 1.4955 train_acc: 0.3405 | val_loss: 1.5087 val_acc: 0.3361\n",
            "Lowest val_loss: 1.4779, at epoch 8\n",
            "LSTM 30 1 [40]\n",
            "Epoch 0: train_loss: 1.5820 train_acc: 0.2651 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2705 | val_loss: 1.5733 val_acc: 0.2589\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2688 | val_loss: 1.5711 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5677 train_acc: 0.2701 | val_loss: 1.5708 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5683 train_acc: 0.2670 | val_loss: 1.5676 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5647 train_acc: 0.2665 | val_loss: 1.5654 val_acc: 0.2480\n",
            "Epoch 6: train_loss: 1.5550 train_acc: 0.2830 | val_loss: 1.5109 val_acc: 0.2716\n",
            "Epoch 7: train_loss: 1.5301 train_acc: 0.2985 | val_loss: 1.5027 val_acc: 0.3279\n",
            "Epoch 8: train_loss: 1.5434 train_acc: 0.2879 | val_loss: 1.5272 val_acc: 0.2743\n",
            "Epoch 9: train_loss: 1.5301 train_acc: 0.3172 | val_loss: 1.5559 val_acc: 0.2870\n",
            "Epoch 10: train_loss: 1.5427 train_acc: 0.3024 | val_loss: 1.5510 val_acc: 0.2843\n",
            "Epoch 11: train_loss: 1.5129 train_acc: 0.3309 | val_loss: 1.5350 val_acc: 0.2707\n",
            "Epoch 12: train_loss: 1.5119 train_acc: 0.3207 | val_loss: 1.5542 val_acc: 0.2480\n",
            "Epoch 13: train_loss: 1.5203 train_acc: 0.2997 | val_loss: 1.5412 val_acc: 0.2552\n",
            "Epoch 14: train_loss: 1.5031 train_acc: 0.3207 | val_loss: 1.5070 val_acc: 0.3097\n",
            "Epoch 15: train_loss: 1.5004 train_acc: 0.3232 | val_loss: 1.5055 val_acc: 0.2906\n",
            "Epoch 16: train_loss: 1.4813 train_acc: 0.3488 | val_loss: 1.5053 val_acc: 0.2997\n",
            "Epoch 17: train_loss: 1.5065 train_acc: 0.3217 | val_loss: 1.5236 val_acc: 0.2852\n",
            "Epoch 18: train_loss: 1.5188 train_acc: 0.2980 | val_loss: 1.5078 val_acc: 0.2852\n",
            "Epoch 19: train_loss: 1.4847 train_acc: 0.3440 | val_loss: 1.5000 val_acc: 0.3124\n",
            "Epoch 20: train_loss: 1.4701 train_acc: 0.3502 | val_loss: 1.4905 val_acc: 0.3270\n",
            "Epoch 21: train_loss: 1.4660 train_acc: 0.3580 | val_loss: 1.4827 val_acc: 0.3370\n",
            "Epoch 22: train_loss: 1.4768 train_acc: 0.3460 | val_loss: 1.5055 val_acc: 0.3115\n",
            "Epoch 23: train_loss: 1.4888 train_acc: 0.3201 | val_loss: 1.5087 val_acc: 0.3015\n",
            "Epoch 24: train_loss: 1.4849 train_acc: 0.3264 | val_loss: 1.5117 val_acc: 0.3070\n",
            "Lowest val_loss: 1.4827, at epoch 21\n",
            "LSTM 30 1 [50]\n",
            "Epoch 0: train_loss: 1.5789 train_acc: 0.2587 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2699 | val_loss: 1.5721 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2680 | val_loss: 1.5729 val_acc: 0.2516\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2720 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5665 train_acc: 0.2741 | val_loss: 1.5560 val_acc: 0.3315\n",
            "Epoch 5: train_loss: 1.5520 train_acc: 0.2987 | val_loss: 1.5690 val_acc: 0.2906\n",
            "Epoch 6: train_loss: 1.5173 train_acc: 0.3372 | val_loss: 1.5109 val_acc: 0.3215\n",
            "Epoch 7: train_loss: 1.5045 train_acc: 0.3447 | val_loss: 1.4768 val_acc: 0.3433\n",
            "Epoch 8: train_loss: 1.4607 train_acc: 0.3710 | val_loss: 1.4280 val_acc: 0.3660\n",
            "Epoch 9: train_loss: 1.4079 train_acc: 0.3915 | val_loss: 1.3946 val_acc: 0.3769\n",
            "Epoch 10: train_loss: 1.3597 train_acc: 0.4036 | val_loss: 1.3812 val_acc: 0.3797\n",
            "Epoch 11: train_loss: 1.3080 train_acc: 0.4137 | val_loss: 1.3639 val_acc: 0.3833\n",
            "Epoch 12: train_loss: 1.2716 train_acc: 0.4216 | val_loss: 1.3619 val_acc: 0.3915\n",
            "Epoch 13: train_loss: 1.2394 train_acc: 0.4407 | val_loss: 1.4118 val_acc: 0.3806\n",
            "Epoch 14: train_loss: 1.2140 train_acc: 0.4554 | val_loss: 1.3833 val_acc: 0.3869\n",
            "Epoch 15: train_loss: 1.1927 train_acc: 0.4602 | val_loss: 1.3619 val_acc: 0.3969\n",
            "Epoch 16: train_loss: 1.1803 train_acc: 0.4635 | val_loss: 1.3861 val_acc: 0.3951\n",
            "Epoch 17: train_loss: 1.1618 train_acc: 0.4754 | val_loss: 1.3611 val_acc: 0.3942\n",
            "Epoch 18: train_loss: 1.1388 train_acc: 0.4882 | val_loss: 1.3679 val_acc: 0.3906\n",
            "Epoch 19: train_loss: 1.1284 train_acc: 0.4931 | val_loss: 1.3804 val_acc: 0.3896\n",
            "Epoch 20: train_loss: 1.1060 train_acc: 0.5009 | val_loss: 1.3788 val_acc: 0.3987\n",
            "Epoch 21: train_loss: 1.1014 train_acc: 0.5076 | val_loss: 1.4079 val_acc: 0.3933\n",
            "Epoch 22: train_loss: 1.0729 train_acc: 0.5238 | val_loss: 1.3730 val_acc: 0.3906\n",
            "Epoch 23: train_loss: 1.0503 train_acc: 0.5317 | val_loss: 1.4037 val_acc: 0.4015\n",
            "Epoch 24: train_loss: 1.0372 train_acc: 0.5407 | val_loss: 1.4062 val_acc: 0.3951\n",
            "Lowest val_loss: 1.3611, at epoch 17\n",
            "LSTM 30 1 [60]\n",
            "Epoch 0: train_loss: 1.5737 train_acc: 0.2640 | val_loss: 1.5820 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2718 | val_loss: 1.5696 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5678 train_acc: 0.2650 | val_loss: 1.5684 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2701 | val_loss: 1.5661 val_acc: 0.2589\n",
            "Epoch 4: train_loss: 1.5492 train_acc: 0.2971 | val_loss: 1.5490 val_acc: 0.3052\n",
            "Epoch 5: train_loss: 1.5267 train_acc: 0.2954 | val_loss: 1.5218 val_acc: 0.3379\n",
            "Epoch 6: train_loss: 1.5590 train_acc: 0.2937 | val_loss: 1.5432 val_acc: 0.3043\n",
            "Epoch 7: train_loss: 1.5187 train_acc: 0.3295 | val_loss: 1.4977 val_acc: 0.3052\n",
            "Epoch 8: train_loss: 1.4931 train_acc: 0.3481 | val_loss: 1.4783 val_acc: 0.3488\n",
            "Epoch 9: train_loss: 1.5460 train_acc: 0.3006 | val_loss: 1.5538 val_acc: 0.2816\n",
            "Epoch 10: train_loss: 1.5547 train_acc: 0.2884 | val_loss: 1.5523 val_acc: 0.2807\n",
            "Epoch 11: train_loss: 1.5483 train_acc: 0.2956 | val_loss: 1.5504 val_acc: 0.2816\n",
            "Epoch 12: train_loss: 1.5515 train_acc: 0.2918 | val_loss: 1.5709 val_acc: 0.2579\n",
            "Epoch 13: train_loss: 1.5640 train_acc: 0.2690 | val_loss: 1.5675 val_acc: 0.2607\n",
            "Epoch 14: train_loss: 1.5621 train_acc: 0.2783 | val_loss: 1.5634 val_acc: 0.2643\n",
            "Epoch 15: train_loss: 1.5615 train_acc: 0.2768 | val_loss: 1.5838 val_acc: 0.2625\n",
            "Epoch 16: train_loss: 1.5586 train_acc: 0.2777 | val_loss: 1.5538 val_acc: 0.2979\n",
            "Epoch 17: train_loss: 1.4984 train_acc: 0.3372 | val_loss: 1.4159 val_acc: 0.3642\n",
            "Epoch 18: train_loss: 1.3618 train_acc: 0.4030 | val_loss: 1.3663 val_acc: 0.3842\n",
            "Epoch 19: train_loss: 1.3152 train_acc: 0.4188 | val_loss: 1.3546 val_acc: 0.3751\n",
            "Epoch 20: train_loss: 1.2858 train_acc: 0.4341 | val_loss: 1.3767 val_acc: 0.3769\n",
            "Epoch 21: train_loss: 1.2581 train_acc: 0.4435 | val_loss: 1.3593 val_acc: 0.3833\n",
            "Epoch 22: train_loss: 1.2487 train_acc: 0.4494 | val_loss: 1.3753 val_acc: 0.3833\n",
            "Epoch 23: train_loss: 1.2391 train_acc: 0.4466 | val_loss: 1.3371 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 1.2264 train_acc: 0.4545 | val_loss: 1.3316 val_acc: 0.3906\n",
            "Lowest val_loss: 1.3316, at epoch 24\n",
            "LSTM 30 1 [70]\n",
            "Epoch 0: train_loss: 1.5764 train_acc: 0.2592 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2733 | val_loss: 1.5773 val_acc: 0.2779\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2697 | val_loss: 1.5751 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5673 train_acc: 0.2701 | val_loss: 1.5630 val_acc: 0.2725\n",
            "Epoch 4: train_loss: 1.5661 train_acc: 0.2721 | val_loss: 1.5609 val_acc: 0.2589\n",
            "Epoch 5: train_loss: 1.5444 train_acc: 0.2908 | val_loss: 1.4938 val_acc: 0.3397\n",
            "Epoch 6: train_loss: 1.4943 train_acc: 0.3373 | val_loss: 1.4522 val_acc: 0.3379\n",
            "Epoch 7: train_loss: 1.4340 train_acc: 0.3853 | val_loss: 1.4515 val_acc: 0.3560\n",
            "Epoch 8: train_loss: 1.4106 train_acc: 0.3951 | val_loss: 1.3968 val_acc: 0.3724\n",
            "Epoch 9: train_loss: 1.3761 train_acc: 0.4000 | val_loss: 1.3677 val_acc: 0.3933\n",
            "Epoch 10: train_loss: 1.3213 train_acc: 0.4116 | val_loss: 1.3460 val_acc: 0.4069\n",
            "Epoch 11: train_loss: 1.2930 train_acc: 0.4230 | val_loss: 1.3401 val_acc: 0.4096\n",
            "Epoch 12: train_loss: 1.2544 train_acc: 0.4435 | val_loss: 1.3471 val_acc: 0.4124\n",
            "Epoch 13: train_loss: 1.2378 train_acc: 0.4498 | val_loss: 1.3339 val_acc: 0.4205\n",
            "Epoch 14: train_loss: 1.2208 train_acc: 0.4588 | val_loss: 1.3205 val_acc: 0.4278\n",
            "Epoch 15: train_loss: 1.1990 train_acc: 0.4640 | val_loss: 1.3274 val_acc: 0.4142\n",
            "Epoch 16: train_loss: 1.1815 train_acc: 0.4752 | val_loss: 1.3407 val_acc: 0.4178\n",
            "Epoch 17: train_loss: 1.1590 train_acc: 0.4901 | val_loss: 1.3405 val_acc: 0.4378\n",
            "Epoch 18: train_loss: 1.1409 train_acc: 0.4925 | val_loss: 1.3299 val_acc: 0.4260\n",
            "Epoch 19: train_loss: 1.1237 train_acc: 0.5035 | val_loss: 1.3442 val_acc: 0.4360\n",
            "Epoch 20: train_loss: 1.1090 train_acc: 0.5172 | val_loss: 1.3341 val_acc: 0.4314\n",
            "Epoch 21: train_loss: 1.0905 train_acc: 0.5288 | val_loss: 1.3347 val_acc: 0.4369\n",
            "Epoch 22: train_loss: 1.0795 train_acc: 0.5325 | val_loss: 1.3649 val_acc: 0.4332\n",
            "Epoch 23: train_loss: 1.0519 train_acc: 0.5471 | val_loss: 1.3847 val_acc: 0.4332\n",
            "Epoch 24: train_loss: 1.0389 train_acc: 0.5564 | val_loss: 1.3730 val_acc: 0.4378\n",
            "Lowest val_loss: 1.3205, at epoch 14\n",
            "LSTM 30 2 [30]\n",
            "Epoch 0: train_loss: 1.5828 train_acc: 0.2477 | val_loss: 1.5754 val_acc: 0.2443\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2681 | val_loss: 1.5772 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5691 train_acc: 0.2685 | val_loss: 1.5740 val_acc: 0.2661\n",
            "Epoch 3: train_loss: 1.5694 train_acc: 0.2667 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5633 train_acc: 0.2774 | val_loss: 1.5721 val_acc: 0.2816\n",
            "Epoch 5: train_loss: 1.5480 train_acc: 0.2967 | val_loss: 1.5585 val_acc: 0.2843\n",
            "Epoch 6: train_loss: 1.5458 train_acc: 0.2995 | val_loss: 1.5571 val_acc: 0.2852\n",
            "Epoch 7: train_loss: 1.5452 train_acc: 0.2995 | val_loss: 1.5607 val_acc: 0.2852\n",
            "Epoch 8: train_loss: 1.5450 train_acc: 0.2992 | val_loss: 1.5572 val_acc: 0.2852\n",
            "Epoch 9: train_loss: 1.5437 train_acc: 0.3000 | val_loss: 1.5588 val_acc: 0.2870\n",
            "Epoch 10: train_loss: 1.5448 train_acc: 0.3000 | val_loss: 1.5561 val_acc: 0.2870\n",
            "Epoch 11: train_loss: 1.5449 train_acc: 0.2993 | val_loss: 1.5608 val_acc: 0.2788\n",
            "Epoch 12: train_loss: 1.5507 train_acc: 0.2948 | val_loss: 1.5602 val_acc: 0.2816\n",
            "Epoch 13: train_loss: 1.5509 train_acc: 0.2915 | val_loss: 1.5613 val_acc: 0.2834\n",
            "Epoch 14: train_loss: 1.5513 train_acc: 0.2899 | val_loss: 1.5605 val_acc: 0.2825\n",
            "Epoch 15: train_loss: 1.5513 train_acc: 0.2923 | val_loss: 1.5601 val_acc: 0.2807\n",
            "Epoch 16: train_loss: 1.5508 train_acc: 0.2944 | val_loss: 1.5601 val_acc: 0.2825\n",
            "Epoch 17: train_loss: 1.5511 train_acc: 0.2939 | val_loss: 1.5594 val_acc: 0.2825\n",
            "Epoch 18: train_loss: 1.5504 train_acc: 0.2941 | val_loss: 1.5599 val_acc: 0.2825\n",
            "Epoch 19: train_loss: 1.5505 train_acc: 0.2939 | val_loss: 1.5607 val_acc: 0.2816\n",
            "Epoch 20: train_loss: 1.5505 train_acc: 0.2935 | val_loss: 1.5600 val_acc: 0.2816\n",
            "Epoch 21: train_loss: 1.5507 train_acc: 0.2928 | val_loss: 1.5606 val_acc: 0.2816\n",
            "Epoch 22: train_loss: 1.5635 train_acc: 0.2864 | val_loss: 1.5710 val_acc: 0.2707\n",
            "Epoch 23: train_loss: 1.5629 train_acc: 0.2839 | val_loss: 1.5663 val_acc: 0.2925\n",
            "Epoch 24: train_loss: 1.5565 train_acc: 0.2884 | val_loss: 1.5621 val_acc: 0.2897\n",
            "Lowest val_loss: 1.5561, at epoch 10\n",
            "LSTM 30 2 [40]\n",
            "Epoch 0: train_loss: 1.5778 train_acc: 0.2477 | val_loss: 1.5789 val_acc: 0.2661\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2710 | val_loss: 1.5750 val_acc: 0.2561\n",
            "Epoch 2: train_loss: 1.5695 train_acc: 0.2679 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5685 train_acc: 0.2711 | val_loss: 1.5705 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5683 train_acc: 0.2711 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5665 train_acc: 0.2670 | val_loss: 1.5745 val_acc: 0.3243\n",
            "Epoch 6: train_loss: 1.5380 train_acc: 0.3118 | val_loss: 1.5169 val_acc: 0.3188\n",
            "Epoch 7: train_loss: 1.4715 train_acc: 0.3641 | val_loss: 1.4874 val_acc: 0.3324\n",
            "Epoch 8: train_loss: 1.4238 train_acc: 0.3803 | val_loss: 1.4530 val_acc: 0.3433\n",
            "Epoch 9: train_loss: 1.3779 train_acc: 0.3948 | val_loss: 1.3956 val_acc: 0.3624\n",
            "Epoch 10: train_loss: 1.3503 train_acc: 0.4044 | val_loss: 1.3615 val_acc: 0.3769\n",
            "Epoch 11: train_loss: 1.3059 train_acc: 0.4261 | val_loss: 1.3600 val_acc: 0.3896\n",
            "Epoch 12: train_loss: 1.2748 train_acc: 0.4315 | val_loss: 1.3517 val_acc: 0.4114\n",
            "Epoch 13: train_loss: 1.2526 train_acc: 0.4443 | val_loss: 1.3393 val_acc: 0.4105\n",
            "Epoch 14: train_loss: 1.2298 train_acc: 0.4542 | val_loss: 1.3478 val_acc: 0.4069\n",
            "Epoch 15: train_loss: 1.2118 train_acc: 0.4649 | val_loss: 1.3403 val_acc: 0.4105\n",
            "Epoch 16: train_loss: 1.1966 train_acc: 0.4673 | val_loss: 1.3365 val_acc: 0.4160\n",
            "Epoch 17: train_loss: 1.1808 train_acc: 0.4794 | val_loss: 1.3514 val_acc: 0.4087\n",
            "Epoch 18: train_loss: 1.1659 train_acc: 0.4902 | val_loss: 1.3242 val_acc: 0.4287\n",
            "Epoch 19: train_loss: 1.1501 train_acc: 0.4944 | val_loss: 1.3254 val_acc: 0.4151\n",
            "Epoch 20: train_loss: 1.1339 train_acc: 0.5030 | val_loss: 1.3254 val_acc: 0.4187\n",
            "Epoch 21: train_loss: 1.1141 train_acc: 0.5126 | val_loss: 1.3354 val_acc: 0.4214\n",
            "Epoch 22: train_loss: 1.1023 train_acc: 0.5249 | val_loss: 1.3411 val_acc: 0.4160\n",
            "Epoch 23: train_loss: 1.0945 train_acc: 0.5253 | val_loss: 1.3188 val_acc: 0.4223\n",
            "Epoch 24: train_loss: 1.0680 train_acc: 0.5407 | val_loss: 1.3481 val_acc: 0.4178\n",
            "Lowest val_loss: 1.3188, at epoch 23\n",
            "LSTM 30 2 [50]\n",
            "Epoch 0: train_loss: 1.5723 train_acc: 0.2701 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5742 val_acc: 0.2579\n",
            "Epoch 2: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5722 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5633 train_acc: 0.2788 | val_loss: 1.5718 val_acc: 0.2507\n",
            "Epoch 4: train_loss: 1.5654 train_acc: 0.2676 | val_loss: 1.5701 val_acc: 0.2561\n",
            "Epoch 5: train_loss: 1.5645 train_acc: 0.2712 | val_loss: 1.5706 val_acc: 0.2716\n",
            "Epoch 6: train_loss: 1.5629 train_acc: 0.2705 | val_loss: 1.5707 val_acc: 0.2561\n",
            "Epoch 7: train_loss: 1.5630 train_acc: 0.2728 | val_loss: 1.5734 val_acc: 0.2561\n",
            "Epoch 8: train_loss: 1.5630 train_acc: 0.2707 | val_loss: 1.5709 val_acc: 0.2561\n",
            "Epoch 9: train_loss: 1.5621 train_acc: 0.2719 | val_loss: 1.5723 val_acc: 0.2561\n",
            "Epoch 10: train_loss: 1.5625 train_acc: 0.2731 | val_loss: 1.5698 val_acc: 0.2552\n",
            "Epoch 11: train_loss: 1.5639 train_acc: 0.2702 | val_loss: 1.5694 val_acc: 0.2552\n",
            "Epoch 12: train_loss: 1.5660 train_acc: 0.2706 | val_loss: 1.5725 val_acc: 0.2543\n",
            "Epoch 13: train_loss: 1.5659 train_acc: 0.2705 | val_loss: 1.5705 val_acc: 0.2543\n",
            "Epoch 14: train_loss: 1.5657 train_acc: 0.2707 | val_loss: 1.5707 val_acc: 0.2543\n",
            "Epoch 15: train_loss: 1.5474 train_acc: 0.2965 | val_loss: 1.4860 val_acc: 0.3551\n",
            "Epoch 16: train_loss: 1.4383 train_acc: 0.3709 | val_loss: 1.4767 val_acc: 0.3542\n",
            "Epoch 17: train_loss: 1.3588 train_acc: 0.3915 | val_loss: 1.3993 val_acc: 0.3887\n",
            "Epoch 18: train_loss: 1.3105 train_acc: 0.4177 | val_loss: 1.3646 val_acc: 0.3797\n",
            "Epoch 19: train_loss: 1.2815 train_acc: 0.4233 | val_loss: 1.3979 val_acc: 0.3896\n",
            "Epoch 20: train_loss: 1.2584 train_acc: 0.4361 | val_loss: 1.4143 val_acc: 0.3860\n",
            "Epoch 21: train_loss: 1.2571 train_acc: 0.4357 | val_loss: 1.3457 val_acc: 0.4124\n",
            "Epoch 22: train_loss: 1.2759 train_acc: 0.4386 | val_loss: 1.4183 val_acc: 0.3787\n",
            "Epoch 23: train_loss: 1.2739 train_acc: 0.4460 | val_loss: 1.3794 val_acc: 0.3969\n",
            "Epoch 24: train_loss: 1.2316 train_acc: 0.4478 | val_loss: 1.3770 val_acc: 0.3969\n",
            "Lowest val_loss: 1.3457, at epoch 21\n",
            "LSTM 30 2 [60]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2718 | val_loss: 1.5785 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5696 train_acc: 0.2701 | val_loss: 1.5745 val_acc: 0.2543\n",
            "Epoch 2: train_loss: 1.5682 train_acc: 0.2719 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5679 train_acc: 0.2693 | val_loss: 1.5716 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5614 train_acc: 0.2820 | val_loss: 1.5511 val_acc: 0.2970\n",
            "Epoch 5: train_loss: 1.5676 train_acc: 0.2750 | val_loss: 1.5718 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5678 train_acc: 0.2721 | val_loss: 1.5705 val_acc: 0.2525\n",
            "Epoch 7: train_loss: 1.5628 train_acc: 0.2796 | val_loss: 1.5565 val_acc: 0.3152\n",
            "Epoch 8: train_loss: 1.5119 train_acc: 0.3339 | val_loss: 1.5247 val_acc: 0.3061\n",
            "Epoch 9: train_loss: 1.4471 train_acc: 0.3663 | val_loss: 1.4228 val_acc: 0.3724\n",
            "Epoch 10: train_loss: 1.4087 train_acc: 0.3931 | val_loss: 1.4070 val_acc: 0.3697\n",
            "Epoch 11: train_loss: 1.3607 train_acc: 0.4017 | val_loss: 1.3922 val_acc: 0.3824\n",
            "Epoch 12: train_loss: 1.3254 train_acc: 0.4033 | val_loss: 1.3786 val_acc: 0.3851\n",
            "Epoch 13: train_loss: 1.3007 train_acc: 0.4178 | val_loss: 1.3556 val_acc: 0.3942\n",
            "Epoch 14: train_loss: 1.2707 train_acc: 0.4301 | val_loss: 1.3408 val_acc: 0.3960\n",
            "Epoch 15: train_loss: 1.2489 train_acc: 0.4402 | val_loss: 1.3396 val_acc: 0.3987\n",
            "Epoch 16: train_loss: 1.2224 train_acc: 0.4589 | val_loss: 1.3319 val_acc: 0.4005\n",
            "Epoch 17: train_loss: 1.2183 train_acc: 0.4583 | val_loss: 1.3326 val_acc: 0.3978\n",
            "Epoch 18: train_loss: 1.1930 train_acc: 0.4682 | val_loss: 1.3307 val_acc: 0.4015\n",
            "Epoch 19: train_loss: 1.1790 train_acc: 0.4793 | val_loss: 1.3333 val_acc: 0.4015\n",
            "Epoch 20: train_loss: 1.1683 train_acc: 0.4857 | val_loss: 1.3276 val_acc: 0.3978\n",
            "Epoch 21: train_loss: 1.1474 train_acc: 0.4970 | val_loss: 1.3398 val_acc: 0.4087\n",
            "Epoch 22: train_loss: 1.1318 train_acc: 0.5047 | val_loss: 1.3564 val_acc: 0.4033\n",
            "Epoch 23: train_loss: 1.1178 train_acc: 0.5109 | val_loss: 1.3579 val_acc: 0.4033\n",
            "Epoch 24: train_loss: 1.0987 train_acc: 0.5212 | val_loss: 1.3722 val_acc: 0.4024\n",
            "Lowest val_loss: 1.3276, at epoch 20\n",
            "LSTM 30 2 [70]\n",
            "Epoch 0: train_loss: 1.5730 train_acc: 0.2692 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2705 | val_loss: 1.5729 val_acc: 0.2734\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2707 | val_loss: 1.5752 val_acc: 0.2743\n",
            "Epoch 3: train_loss: 1.5676 train_acc: 0.2733 | val_loss: 1.5605 val_acc: 0.2861\n",
            "Epoch 4: train_loss: 1.5659 train_acc: 0.2783 | val_loss: 1.5685 val_acc: 0.2734\n",
            "Epoch 5: train_loss: 1.5630 train_acc: 0.2793 | val_loss: 1.5760 val_acc: 0.2770\n",
            "Epoch 6: train_loss: 1.5631 train_acc: 0.2767 | val_loss: 1.5699 val_acc: 0.3243\n",
            "Epoch 7: train_loss: 1.5630 train_acc: 0.2770 | val_loss: 1.5741 val_acc: 0.2570\n",
            "Epoch 8: train_loss: 1.5676 train_acc: 0.2674 | val_loss: 1.5737 val_acc: 0.2543\n",
            "Epoch 9: train_loss: 1.5620 train_acc: 0.2759 | val_loss: 1.5666 val_acc: 0.2643\n",
            "Epoch 10: train_loss: 1.5602 train_acc: 0.2752 | val_loss: 1.5678 val_acc: 0.2643\n",
            "Epoch 11: train_loss: 1.5602 train_acc: 0.2789 | val_loss: 1.5679 val_acc: 0.2643\n",
            "Epoch 12: train_loss: 1.5602 train_acc: 0.2796 | val_loss: 1.5673 val_acc: 0.2643\n",
            "Epoch 13: train_loss: 1.5597 train_acc: 0.2767 | val_loss: 1.5671 val_acc: 0.2634\n",
            "Epoch 14: train_loss: 1.5598 train_acc: 0.2757 | val_loss: 1.5687 val_acc: 0.2634\n",
            "Epoch 15: train_loss: 1.5599 train_acc: 0.2796 | val_loss: 1.5666 val_acc: 0.2652\n",
            "Epoch 16: train_loss: 1.5595 train_acc: 0.2775 | val_loss: 1.5714 val_acc: 0.2652\n",
            "Epoch 17: train_loss: 1.5595 train_acc: 0.2767 | val_loss: 1.5666 val_acc: 0.2679\n",
            "Epoch 18: train_loss: 1.5012 train_acc: 0.3374 | val_loss: 1.4337 val_acc: 0.3706\n",
            "Epoch 19: train_loss: 1.3519 train_acc: 0.3944 | val_loss: 1.3869 val_acc: 0.3824\n",
            "Epoch 20: train_loss: 1.2938 train_acc: 0.4250 | val_loss: 1.3535 val_acc: 0.4096\n",
            "Epoch 21: train_loss: 1.2665 train_acc: 0.4360 | val_loss: 1.3619 val_acc: 0.3969\n",
            "Epoch 22: train_loss: 1.2341 train_acc: 0.4453 | val_loss: 1.4057 val_acc: 0.3688\n",
            "Epoch 23: train_loss: 1.2171 train_acc: 0.4563 | val_loss: 1.3782 val_acc: 0.4024\n",
            "Epoch 24: train_loss: 1.1951 train_acc: 0.4662 | val_loss: 1.3494 val_acc: 0.3987\n",
            "Lowest val_loss: 1.3494, at epoch 24\n",
            "LSTM 40 1 [30]\n",
            "Epoch 0: train_loss: 1.5771 train_acc: 0.2656 | val_loss: 1.5772 val_acc: 0.2498\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2717 | val_loss: 1.5716 val_acc: 0.2443\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2720 | val_loss: 1.5689 val_acc: 0.2725\n",
            "Epoch 3: train_loss: 1.5672 train_acc: 0.2677 | val_loss: 1.5665 val_acc: 0.2634\n",
            "Epoch 4: train_loss: 1.5639 train_acc: 0.2721 | val_loss: 1.5412 val_acc: 0.3243\n",
            "Epoch 5: train_loss: 1.4999 train_acc: 0.3448 | val_loss: 1.4621 val_acc: 0.3524\n",
            "Epoch 6: train_loss: 1.4943 train_acc: 0.3523 | val_loss: 1.5183 val_acc: 0.3261\n",
            "Epoch 7: train_loss: 1.4811 train_acc: 0.3555 | val_loss: 1.4595 val_acc: 0.3524\n",
            "Epoch 8: train_loss: 1.4312 train_acc: 0.3663 | val_loss: 1.4295 val_acc: 0.3660\n",
            "Epoch 9: train_loss: 1.4271 train_acc: 0.3768 | val_loss: 1.4494 val_acc: 0.3624\n",
            "Epoch 10: train_loss: 1.3817 train_acc: 0.3947 | val_loss: 1.3890 val_acc: 0.3769\n",
            "Epoch 11: train_loss: 1.3367 train_acc: 0.4016 | val_loss: 1.3671 val_acc: 0.3860\n",
            "Epoch 12: train_loss: 1.3018 train_acc: 0.4150 | val_loss: 1.3582 val_acc: 0.3860\n",
            "Epoch 13: train_loss: 1.2709 train_acc: 0.4240 | val_loss: 1.3465 val_acc: 0.4069\n",
            "Epoch 14: train_loss: 1.2452 train_acc: 0.4434 | val_loss: 1.3388 val_acc: 0.4069\n",
            "Epoch 15: train_loss: 1.2293 train_acc: 0.4492 | val_loss: 1.3269 val_acc: 0.4124\n",
            "Epoch 16: train_loss: 1.2057 train_acc: 0.4592 | val_loss: 1.3304 val_acc: 0.4105\n",
            "Epoch 17: train_loss: 1.1842 train_acc: 0.4690 | val_loss: 1.3354 val_acc: 0.4114\n",
            "Epoch 18: train_loss: 1.1644 train_acc: 0.4776 | val_loss: 1.3217 val_acc: 0.4251\n",
            "Epoch 19: train_loss: 1.1505 train_acc: 0.4762 | val_loss: 1.3429 val_acc: 0.4169\n",
            "Epoch 20: train_loss: 1.1212 train_acc: 0.4918 | val_loss: 1.3518 val_acc: 0.4187\n",
            "Epoch 21: train_loss: 1.1053 train_acc: 0.5019 | val_loss: 1.3393 val_acc: 0.4160\n",
            "Epoch 22: train_loss: 1.0803 train_acc: 0.5201 | val_loss: 1.3327 val_acc: 0.4133\n",
            "Epoch 23: train_loss: 1.0678 train_acc: 0.5266 | val_loss: 1.3403 val_acc: 0.4214\n",
            "Epoch 24: train_loss: 1.0379 train_acc: 0.5425 | val_loss: 1.3423 val_acc: 0.4087\n",
            "Lowest val_loss: 1.3217, at epoch 18\n",
            "LSTM 40 1 [40]\n",
            "Epoch 0: train_loss: 1.5835 train_acc: 0.2403 | val_loss: 1.5812 val_acc: 0.2625\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2692 | val_loss: 1.5751 val_acc: 0.2716\n",
            "Epoch 2: train_loss: 1.5688 train_acc: 0.2714 | val_loss: 1.5730 val_acc: 0.2570\n",
            "Epoch 3: train_loss: 1.5680 train_acc: 0.2677 | val_loss: 1.5698 val_acc: 0.2661\n",
            "Epoch 4: train_loss: 1.5652 train_acc: 0.2712 | val_loss: 1.5426 val_acc: 0.3215\n",
            "Epoch 5: train_loss: 1.5420 train_acc: 0.3027 | val_loss: 1.5134 val_acc: 0.3279\n",
            "Epoch 6: train_loss: 1.5265 train_acc: 0.3207 | val_loss: 1.5116 val_acc: 0.3342\n",
            "Epoch 7: train_loss: 1.5474 train_acc: 0.2973 | val_loss: 1.5672 val_acc: 0.2725\n",
            "Epoch 8: train_loss: 1.5656 train_acc: 0.2763 | val_loss: 1.5648 val_acc: 0.2743\n",
            "Epoch 9: train_loss: 1.5614 train_acc: 0.2779 | val_loss: 1.5608 val_acc: 0.2761\n",
            "Epoch 10: train_loss: 1.5591 train_acc: 0.2839 | val_loss: 1.5617 val_acc: 0.2752\n",
            "Epoch 11: train_loss: 1.5590 train_acc: 0.2810 | val_loss: 1.5603 val_acc: 0.2934\n",
            "Epoch 12: train_loss: 1.5476 train_acc: 0.2960 | val_loss: 1.5436 val_acc: 0.2979\n",
            "Epoch 13: train_loss: 1.5374 train_acc: 0.3132 | val_loss: 1.5460 val_acc: 0.2925\n",
            "Epoch 14: train_loss: 1.5400 train_acc: 0.3102 | val_loss: 1.5442 val_acc: 0.2943\n",
            "Epoch 15: train_loss: 1.5410 train_acc: 0.3090 | val_loss: 1.5446 val_acc: 0.2906\n",
            "Epoch 16: train_loss: 1.5558 train_acc: 0.2988 | val_loss: 1.5634 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5610 train_acc: 0.2677 | val_loss: 1.5528 val_acc: 0.2843\n",
            "Epoch 18: train_loss: 1.5433 train_acc: 0.2831 | val_loss: 1.5224 val_acc: 0.3306\n",
            "Epoch 19: train_loss: 1.5144 train_acc: 0.3288 | val_loss: 1.5070 val_acc: 0.3261\n",
            "Epoch 20: train_loss: 1.5530 train_acc: 0.2820 | val_loss: 1.5662 val_acc: 0.2480\n",
            "Epoch 21: train_loss: 1.5574 train_acc: 0.2706 | val_loss: 1.5596 val_acc: 0.2579\n",
            "Epoch 22: train_loss: 1.5559 train_acc: 0.2769 | val_loss: 1.5589 val_acc: 0.2589\n",
            "Epoch 23: train_loss: 1.5550 train_acc: 0.2729 | val_loss: 1.5581 val_acc: 0.2616\n",
            "Epoch 24: train_loss: 1.5548 train_acc: 0.2750 | val_loss: 1.5641 val_acc: 0.2589\n",
            "Lowest val_loss: 1.5070, at epoch 19\n",
            "LSTM 40 1 [50]\n",
            "Epoch 0: train_loss: 1.5748 train_acc: 0.2672 | val_loss: 1.5727 val_acc: 0.2561\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2718 | val_loss: 1.5726 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2718 | val_loss: 1.5662 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2724 | val_loss: 1.5564 val_acc: 0.3034\n",
            "Epoch 4: train_loss: 1.5540 train_acc: 0.3083 | val_loss: 1.5319 val_acc: 0.3161\n",
            "Epoch 5: train_loss: 1.5312 train_acc: 0.3127 | val_loss: 1.5155 val_acc: 0.3215\n",
            "Epoch 6: train_loss: 1.5326 train_acc: 0.3195 | val_loss: 1.5701 val_acc: 0.2861\n",
            "Epoch 7: train_loss: 1.5637 train_acc: 0.2735 | val_loss: 1.5672 val_acc: 0.2770\n",
            "Epoch 8: train_loss: 1.5618 train_acc: 0.2845 | val_loss: 1.5630 val_acc: 0.2616\n",
            "Epoch 9: train_loss: 1.5571 train_acc: 0.2860 | val_loss: 1.5544 val_acc: 0.2816\n",
            "Epoch 10: train_loss: 1.5556 train_acc: 0.2924 | val_loss: 1.5540 val_acc: 0.2816\n",
            "Epoch 11: train_loss: 1.5548 train_acc: 0.2968 | val_loss: 1.5675 val_acc: 0.2988\n",
            "Epoch 12: train_loss: 1.5536 train_acc: 0.3047 | val_loss: 1.5656 val_acc: 0.2834\n",
            "Epoch 13: train_loss: 1.5542 train_acc: 0.3056 | val_loss: 1.5647 val_acc: 0.2997\n",
            "Epoch 14: train_loss: 1.5538 train_acc: 0.3055 | val_loss: 1.5693 val_acc: 0.2625\n",
            "Epoch 15: train_loss: 1.5532 train_acc: 0.3055 | val_loss: 1.5633 val_acc: 0.3015\n",
            "Epoch 16: train_loss: 1.5526 train_acc: 0.3063 | val_loss: 1.5638 val_acc: 0.2852\n",
            "Epoch 17: train_loss: 1.5525 train_acc: 0.3058 | val_loss: 1.5701 val_acc: 0.2861\n",
            "Epoch 18: train_loss: 1.5528 train_acc: 0.3054 | val_loss: 1.5712 val_acc: 0.2770\n",
            "Epoch 19: train_loss: 1.5526 train_acc: 0.3058 | val_loss: 1.5701 val_acc: 0.2816\n",
            "Epoch 20: train_loss: 1.5522 train_acc: 0.3057 | val_loss: 1.5673 val_acc: 0.2834\n",
            "Epoch 21: train_loss: 1.5520 train_acc: 0.3068 | val_loss: 1.5725 val_acc: 0.2698\n",
            "Epoch 22: train_loss: 1.5519 train_acc: 0.3062 | val_loss: 1.5727 val_acc: 0.2743\n",
            "Epoch 23: train_loss: 1.5512 train_acc: 0.3072 | val_loss: 1.5634 val_acc: 0.2879\n",
            "Epoch 24: train_loss: 1.5513 train_acc: 0.3070 | val_loss: 1.5695 val_acc: 0.2834\n",
            "Lowest val_loss: 1.5155, at epoch 5\n",
            "LSTM 40 1 [60]\n",
            "Epoch 0: train_loss: 1.5720 train_acc: 0.2630 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2757 | val_loss: 1.5692 val_acc: 0.3134\n",
            "Epoch 2: train_loss: 1.5678 train_acc: 0.2665 | val_loss: 1.5742 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5547 train_acc: 0.2770 | val_loss: 1.5677 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5539 train_acc: 0.2718 | val_loss: 1.5409 val_acc: 0.3406\n",
            "Epoch 5: train_loss: 1.5303 train_acc: 0.3235 | val_loss: 1.4968 val_acc: 0.3388\n",
            "Epoch 6: train_loss: 1.5184 train_acc: 0.3349 | val_loss: 1.5101 val_acc: 0.3415\n",
            "Epoch 7: train_loss: 1.5155 train_acc: 0.3305 | val_loss: 1.5059 val_acc: 0.3315\n",
            "Epoch 8: train_loss: 1.5380 train_acc: 0.3214 | val_loss: 1.5267 val_acc: 0.3206\n",
            "Epoch 9: train_loss: 1.5513 train_acc: 0.3020 | val_loss: 1.5541 val_acc: 0.2979\n",
            "Epoch 10: train_loss: 1.5320 train_acc: 0.3209 | val_loss: 1.5494 val_acc: 0.2616\n",
            "Epoch 11: train_loss: 1.5414 train_acc: 0.2934 | val_loss: 1.5457 val_acc: 0.2834\n",
            "Epoch 12: train_loss: 1.5406 train_acc: 0.2858 | val_loss: 1.5460 val_acc: 0.2688\n",
            "Epoch 13: train_loss: 1.5388 train_acc: 0.2958 | val_loss: 1.5655 val_acc: 0.2525\n",
            "Epoch 14: train_loss: 1.5396 train_acc: 0.2871 | val_loss: 1.5361 val_acc: 0.3043\n",
            "Epoch 15: train_loss: 1.5401 train_acc: 0.2831 | val_loss: 1.5423 val_acc: 0.2970\n",
            "Epoch 16: train_loss: 1.5404 train_acc: 0.2848 | val_loss: 1.5594 val_acc: 0.2725\n",
            "Epoch 17: train_loss: 1.5409 train_acc: 0.2829 | val_loss: 1.5379 val_acc: 0.2779\n",
            "Epoch 18: train_loss: 1.5141 train_acc: 0.3287 | val_loss: 1.5098 val_acc: 0.3279\n",
            "Epoch 19: train_loss: 1.5131 train_acc: 0.3381 | val_loss: 1.5106 val_acc: 0.3297\n",
            "Epoch 20: train_loss: 1.5126 train_acc: 0.3378 | val_loss: 1.5151 val_acc: 0.3179\n",
            "Epoch 21: train_loss: 1.5118 train_acc: 0.3388 | val_loss: 1.5181 val_acc: 0.3052\n",
            "Epoch 22: train_loss: 1.5113 train_acc: 0.3385 | val_loss: 1.5309 val_acc: 0.2979\n",
            "Epoch 23: train_loss: 1.5141 train_acc: 0.3392 | val_loss: 1.5144 val_acc: 0.3161\n",
            "Epoch 24: train_loss: 1.5137 train_acc: 0.3399 | val_loss: 1.5178 val_acc: 0.3124\n",
            "Lowest val_loss: 1.4968, at epoch 5\n",
            "LSTM 40 1 [70]\n",
            "Epoch 0: train_loss: 1.5757 train_acc: 0.2587 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2685 | val_loss: 1.5702 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5675 train_acc: 0.2720 | val_loss: 1.5766 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2694 | val_loss: 1.5490 val_acc: 0.2616\n",
            "Epoch 4: train_loss: 1.5579 train_acc: 0.2837 | val_loss: 1.5298 val_acc: 0.2652\n",
            "Epoch 5: train_loss: 1.5538 train_acc: 0.2948 | val_loss: 1.5700 val_acc: 0.2552\n",
            "Epoch 6: train_loss: 1.5442 train_acc: 0.2860 | val_loss: 1.5548 val_acc: 0.2716\n",
            "Epoch 7: train_loss: 1.5536 train_acc: 0.2731 | val_loss: 1.5533 val_acc: 0.2598\n",
            "Epoch 8: train_loss: 1.5505 train_acc: 0.2808 | val_loss: 1.5501 val_acc: 0.3043\n",
            "Epoch 9: train_loss: 1.5415 train_acc: 0.2822 | val_loss: 1.5485 val_acc: 0.3152\n",
            "Epoch 10: train_loss: 1.5619 train_acc: 0.2705 | val_loss: 1.5584 val_acc: 0.2661\n",
            "Epoch 11: train_loss: 1.5607 train_acc: 0.2827 | val_loss: 1.5781 val_acc: 0.2788\n",
            "Epoch 12: train_loss: 1.5205 train_acc: 0.3221 | val_loss: 1.4869 val_acc: 0.3261\n",
            "Epoch 13: train_loss: 1.5310 train_acc: 0.3144 | val_loss: 1.5768 val_acc: 0.2716\n",
            "Epoch 14: train_loss: 1.5431 train_acc: 0.2892 | val_loss: 1.5766 val_acc: 0.2661\n",
            "Epoch 15: train_loss: 1.5540 train_acc: 0.2777 | val_loss: 1.5605 val_acc: 0.2679\n",
            "Epoch 16: train_loss: 1.5264 train_acc: 0.3120 | val_loss: 1.4982 val_acc: 0.3460\n",
            "Epoch 17: train_loss: 1.5027 train_acc: 0.3351 | val_loss: 1.5527 val_acc: 0.2752\n",
            "Epoch 18: train_loss: 1.5532 train_acc: 0.2814 | val_loss: 1.5487 val_acc: 0.2752\n",
            "Epoch 19: train_loss: 1.5200 train_acc: 0.3105 | val_loss: 1.5315 val_acc: 0.2897\n",
            "Epoch 20: train_loss: 1.5354 train_acc: 0.3099 | val_loss: 1.5016 val_acc: 0.3270\n",
            "Epoch 21: train_loss: 1.4840 train_acc: 0.3397 | val_loss: 1.4667 val_acc: 0.3597\n",
            "Epoch 22: train_loss: 1.4913 train_acc: 0.3282 | val_loss: 1.5047 val_acc: 0.3470\n",
            "Epoch 23: train_loss: 1.4541 train_acc: 0.3687 | val_loss: 1.5023 val_acc: 0.3379\n",
            "Epoch 24: train_loss: 1.4687 train_acc: 0.3556 | val_loss: 1.5037 val_acc: 0.3433\n",
            "Lowest val_loss: 1.4667, at epoch 21\n",
            "LSTM 40 2 [30]\n",
            "Epoch 0: train_loss: 1.5786 train_acc: 0.2642 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2702 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5692 train_acc: 0.2699 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5687 train_acc: 0.2669 | val_loss: 1.5738 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5688 train_acc: 0.2676 | val_loss: 1.5679 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5665 train_acc: 0.2828 | val_loss: 1.5752 val_acc: 0.2307\n",
            "Epoch 6: train_loss: 1.5539 train_acc: 0.2992 | val_loss: 1.5472 val_acc: 0.3097\n",
            "Epoch 7: train_loss: 1.5445 train_acc: 0.3088 | val_loss: 1.5713 val_acc: 0.2561\n",
            "Epoch 8: train_loss: 1.5509 train_acc: 0.2954 | val_loss: 1.5360 val_acc: 0.3097\n",
            "Epoch 9: train_loss: 1.5417 train_acc: 0.3124 | val_loss: 1.5182 val_acc: 0.3288\n",
            "Epoch 10: train_loss: 1.5128 train_acc: 0.3415 | val_loss: 1.5315 val_acc: 0.3143\n",
            "Epoch 11: train_loss: 1.5276 train_acc: 0.3044 | val_loss: 1.5192 val_acc: 0.3124\n",
            "Epoch 12: train_loss: 1.5146 train_acc: 0.3320 | val_loss: 1.5108 val_acc: 0.3306\n",
            "Epoch 13: train_loss: 1.5052 train_acc: 0.3402 | val_loss: 1.5427 val_acc: 0.3034\n",
            "Epoch 14: train_loss: 1.5185 train_acc: 0.3112 | val_loss: 1.5193 val_acc: 0.3025\n",
            "Epoch 15: train_loss: 1.5174 train_acc: 0.3051 | val_loss: 1.5486 val_acc: 0.2879\n",
            "Epoch 16: train_loss: 1.5700 train_acc: 0.2671 | val_loss: 1.5696 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5690 train_acc: 0.2671 | val_loss: 1.5709 val_acc: 0.2525\n",
            "Epoch 18: train_loss: 1.5686 train_acc: 0.2717 | val_loss: 1.5707 val_acc: 0.2525\n",
            "Epoch 19: train_loss: 1.5679 train_acc: 0.2677 | val_loss: 1.5711 val_acc: 0.2807\n",
            "Epoch 20: train_loss: 1.5687 train_acc: 0.2679 | val_loss: 1.5713 val_acc: 0.2870\n",
            "Epoch 21: train_loss: 1.5688 train_acc: 0.2708 | val_loss: 1.5697 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5686 train_acc: 0.2721 | val_loss: 1.5695 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5683 train_acc: 0.2721 | val_loss: 1.5688 val_acc: 0.2879\n",
            "Epoch 24: train_loss: 1.5689 train_acc: 0.2664 | val_loss: 1.5687 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5108, at epoch 12\n",
            "LSTM 40 2 [40]\n",
            "Epoch 0: train_loss: 1.5741 train_acc: 0.2651 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2699 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5690 train_acc: 0.2691 | val_loss: 1.5755 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5686 train_acc: 0.2722 | val_loss: 1.5702 val_acc: 0.2761\n",
            "Epoch 4: train_loss: 1.5691 train_acc: 0.2782 | val_loss: 1.5707 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5672 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5587 train_acc: 0.2849 | val_loss: 1.5744 val_acc: 0.2625\n",
            "Epoch 7: train_loss: 1.5690 train_acc: 0.2660 | val_loss: 1.5766 val_acc: 0.2589\n",
            "Epoch 8: train_loss: 1.5688 train_acc: 0.2697 | val_loss: 1.5750 val_acc: 0.2589\n",
            "Epoch 9: train_loss: 1.5686 train_acc: 0.2699 | val_loss: 1.5749 val_acc: 0.2589\n",
            "Epoch 10: train_loss: 1.5597 train_acc: 0.2815 | val_loss: 1.5611 val_acc: 0.2743\n",
            "Epoch 11: train_loss: 1.5496 train_acc: 0.2931 | val_loss: 1.5557 val_acc: 0.2761\n",
            "Epoch 12: train_loss: 1.5484 train_acc: 0.2930 | val_loss: 1.5581 val_acc: 0.2734\n",
            "Epoch 13: train_loss: 1.5492 train_acc: 0.2907 | val_loss: 1.5549 val_acc: 0.2770\n",
            "Epoch 14: train_loss: 1.5495 train_acc: 0.2911 | val_loss: 1.5543 val_acc: 0.2779\n",
            "Epoch 15: train_loss: 1.5489 train_acc: 0.2905 | val_loss: 1.5569 val_acc: 0.2788\n",
            "Epoch 16: train_loss: 1.5490 train_acc: 0.2915 | val_loss: 1.5550 val_acc: 0.2788\n",
            "Epoch 17: train_loss: 1.5495 train_acc: 0.2882 | val_loss: 1.5582 val_acc: 0.2788\n",
            "Epoch 18: train_loss: 1.5439 train_acc: 0.2947 | val_loss: 1.5569 val_acc: 0.2788\n",
            "Epoch 19: train_loss: 1.5440 train_acc: 0.2946 | val_loss: 1.5571 val_acc: 0.2797\n",
            "Epoch 20: train_loss: 1.5440 train_acc: 0.2941 | val_loss: 1.5570 val_acc: 0.2761\n",
            "Epoch 21: train_loss: 1.5441 train_acc: 0.2925 | val_loss: 1.5576 val_acc: 0.2788\n",
            "Epoch 22: train_loss: 1.5437 train_acc: 0.2953 | val_loss: 1.5591 val_acc: 0.2734\n",
            "Epoch 23: train_loss: 1.5434 train_acc: 0.2994 | val_loss: 1.5476 val_acc: 0.2943\n",
            "Epoch 24: train_loss: 1.5494 train_acc: 0.3049 | val_loss: 1.5488 val_acc: 0.2906\n",
            "Lowest val_loss: 1.5476, at epoch 23\n",
            "LSTM 40 2 [50]\n",
            "Epoch 0: train_loss: 1.5758 train_acc: 0.2697 | val_loss: 1.5736 val_acc: 0.2625\n",
            "Epoch 1: train_loss: 1.5698 train_acc: 0.2653 | val_loss: 1.5719 val_acc: 0.2643\n",
            "Epoch 2: train_loss: 1.5688 train_acc: 0.2699 | val_loss: 1.5716 val_acc: 0.2679\n",
            "Epoch 3: train_loss: 1.5680 train_acc: 0.2700 | val_loss: 1.5641 val_acc: 0.2725\n",
            "Epoch 4: train_loss: 1.5497 train_acc: 0.3007 | val_loss: 1.5358 val_acc: 0.3152\n",
            "Epoch 5: train_loss: 1.5188 train_acc: 0.3378 | val_loss: 1.5272 val_acc: 0.3342\n",
            "Epoch 6: train_loss: 1.5320 train_acc: 0.3262 | val_loss: 1.5072 val_acc: 0.3224\n",
            "Epoch 7: train_loss: 1.4964 train_acc: 0.3457 | val_loss: 1.5010 val_acc: 0.3333\n",
            "Epoch 8: train_loss: 1.4741 train_acc: 0.3470 | val_loss: 1.4667 val_acc: 0.3342\n",
            "Epoch 9: train_loss: 1.4202 train_acc: 0.3667 | val_loss: 1.4081 val_acc: 0.3533\n",
            "Epoch 10: train_loss: 1.3673 train_acc: 0.3890 | val_loss: 1.3888 val_acc: 0.3742\n",
            "Epoch 11: train_loss: 1.3124 train_acc: 0.4144 | val_loss: 1.3980 val_acc: 0.3751\n",
            "Epoch 12: train_loss: 1.2887 train_acc: 0.4243 | val_loss: 1.3834 val_acc: 0.3733\n",
            "Epoch 13: train_loss: 1.2598 train_acc: 0.4438 | val_loss: 1.3559 val_acc: 0.3987\n",
            "Epoch 14: train_loss: 1.2399 train_acc: 0.4524 | val_loss: 1.3561 val_acc: 0.4005\n",
            "Epoch 15: train_loss: 1.2123 train_acc: 0.4647 | val_loss: 1.3722 val_acc: 0.3915\n",
            "Epoch 16: train_loss: 1.1989 train_acc: 0.4726 | val_loss: 1.3764 val_acc: 0.3924\n",
            "Epoch 17: train_loss: 1.1775 train_acc: 0.4835 | val_loss: 1.3498 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 1.1591 train_acc: 0.4946 | val_loss: 1.3791 val_acc: 0.3987\n",
            "Epoch 19: train_loss: 1.1480 train_acc: 0.4952 | val_loss: 1.3661 val_acc: 0.4051\n",
            "Epoch 20: train_loss: 1.1166 train_acc: 0.5164 | val_loss: 1.3885 val_acc: 0.4078\n",
            "Epoch 21: train_loss: 1.1051 train_acc: 0.5183 | val_loss: 1.3948 val_acc: 0.4151\n",
            "Epoch 22: train_loss: 1.0832 train_acc: 0.5328 | val_loss: 1.4286 val_acc: 0.3878\n",
            "Epoch 23: train_loss: 1.0797 train_acc: 0.5348 | val_loss: 1.3800 val_acc: 0.4087\n",
            "Epoch 24: train_loss: 1.0386 train_acc: 0.5583 | val_loss: 1.4017 val_acc: 0.4151\n",
            "Lowest val_loss: 1.3498, at epoch 17\n",
            "LSTM 40 2 [60]\n",
            "Epoch 0: train_loss: 1.5727 train_acc: 0.2700 | val_loss: 1.5762 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2715 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5690 train_acc: 0.2718 | val_loss: 1.5728 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5665 train_acc: 0.2701 | val_loss: 1.5690 val_acc: 0.2934\n",
            "Epoch 4: train_loss: 1.5440 train_acc: 0.2978 | val_loss: 1.4579 val_acc: 0.3606\n",
            "Epoch 5: train_loss: 1.4638 train_acc: 0.3634 | val_loss: 1.4764 val_acc: 0.3342\n",
            "Epoch 6: train_loss: 1.4653 train_acc: 0.3583 | val_loss: 1.4692 val_acc: 0.3442\n",
            "Epoch 7: train_loss: 1.5183 train_acc: 0.3062 | val_loss: 1.5504 val_acc: 0.2807\n",
            "Epoch 8: train_loss: 1.5277 train_acc: 0.2905 | val_loss: 1.5537 val_acc: 0.2552\n",
            "Epoch 9: train_loss: 1.5277 train_acc: 0.2879 | val_loss: 1.5512 val_acc: 0.3015\n",
            "Epoch 10: train_loss: 1.5271 train_acc: 0.2863 | val_loss: 1.5501 val_acc: 0.2589\n",
            "Epoch 11: train_loss: 1.5212 train_acc: 0.2938 | val_loss: 1.5466 val_acc: 0.2888\n",
            "Epoch 12: train_loss: 1.5068 train_acc: 0.3329 | val_loss: 1.4777 val_acc: 0.3451\n",
            "Epoch 13: train_loss: 1.5026 train_acc: 0.3473 | val_loss: 1.4738 val_acc: 0.3406\n",
            "Epoch 14: train_loss: 1.5026 train_acc: 0.3467 | val_loss: 1.5294 val_acc: 0.3043\n",
            "Epoch 15: train_loss: 1.5110 train_acc: 0.3242 | val_loss: 1.5305 val_acc: 0.3015\n",
            "Epoch 16: train_loss: 1.5118 train_acc: 0.3234 | val_loss: 1.5298 val_acc: 0.3025\n",
            "Epoch 17: train_loss: 1.5116 train_acc: 0.3234 | val_loss: 1.5275 val_acc: 0.3034\n",
            "Epoch 18: train_loss: 1.5126 train_acc: 0.3227 | val_loss: 1.5310 val_acc: 0.3015\n",
            "Epoch 19: train_loss: 1.5113 train_acc: 0.3221 | val_loss: 1.5319 val_acc: 0.3015\n",
            "Epoch 20: train_loss: 1.5112 train_acc: 0.3220 | val_loss: 1.5323 val_acc: 0.3015\n",
            "Epoch 21: train_loss: 1.5110 train_acc: 0.3220 | val_loss: 1.5292 val_acc: 0.3025\n",
            "Epoch 22: train_loss: 1.5086 train_acc: 0.3261 | val_loss: 1.5191 val_acc: 0.3143\n",
            "Epoch 23: train_loss: 1.5018 train_acc: 0.3335 | val_loss: 1.5186 val_acc: 0.3143\n",
            "Epoch 24: train_loss: 1.5010 train_acc: 0.3327 | val_loss: 1.5168 val_acc: 0.3134\n",
            "Lowest val_loss: 1.4579, at epoch 4\n",
            "LSTM 40 2 [70]\n",
            "Epoch 0: train_loss: 1.5725 train_acc: 0.2713 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2679 | val_loss: 1.5741 val_acc: 0.2543\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2713 | val_loss: 1.5704 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5685 train_acc: 0.2692 | val_loss: 1.5728 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5679 train_acc: 0.2718 | val_loss: 1.5696 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5666 train_acc: 0.2687 | val_loss: 1.5713 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5660 train_acc: 0.2705 | val_loss: 1.5590 val_acc: 0.2470\n",
            "Epoch 7: train_loss: 1.5423 train_acc: 0.3089 | val_loss: 1.5449 val_acc: 0.2943\n",
            "Epoch 8: train_loss: 1.5240 train_acc: 0.3227 | val_loss: 1.5235 val_acc: 0.3224\n",
            "Epoch 9: train_loss: 1.5180 train_acc: 0.3118 | val_loss: 1.5263 val_acc: 0.3224\n",
            "Epoch 10: train_loss: 1.5355 train_acc: 0.3133 | val_loss: 1.5361 val_acc: 0.3006\n",
            "Epoch 11: train_loss: 1.5063 train_acc: 0.3378 | val_loss: 1.4988 val_acc: 0.3270\n",
            "Epoch 12: train_loss: 1.4887 train_acc: 0.3261 | val_loss: 1.4981 val_acc: 0.3134\n",
            "Epoch 13: train_loss: 1.4886 train_acc: 0.3271 | val_loss: 1.4925 val_acc: 0.3315\n",
            "Epoch 14: train_loss: 1.4865 train_acc: 0.3332 | val_loss: 1.4786 val_acc: 0.3442\n",
            "Epoch 15: train_loss: 1.4861 train_acc: 0.3467 | val_loss: 1.5254 val_acc: 0.2970\n",
            "Epoch 16: train_loss: 1.4947 train_acc: 0.3310 | val_loss: 1.4993 val_acc: 0.3206\n",
            "Epoch 17: train_loss: 1.4888 train_acc: 0.3392 | val_loss: 1.5075 val_acc: 0.3424\n",
            "Epoch 18: train_loss: 1.4948 train_acc: 0.3577 | val_loss: 1.5281 val_acc: 0.3279\n",
            "Epoch 19: train_loss: 1.5039 train_acc: 0.3166 | val_loss: 1.5261 val_acc: 0.3270\n",
            "Epoch 20: train_loss: 1.4994 train_acc: 0.3150 | val_loss: 1.5329 val_acc: 0.3206\n",
            "Epoch 21: train_loss: 1.4941 train_acc: 0.3257 | val_loss: 1.4892 val_acc: 0.3315\n",
            "Epoch 22: train_loss: 1.4897 train_acc: 0.3367 | val_loss: 1.5180 val_acc: 0.2988\n",
            "Epoch 23: train_loss: 1.4867 train_acc: 0.3395 | val_loss: 1.5101 val_acc: 0.3025\n",
            "Epoch 24: train_loss: 1.4839 train_acc: 0.3413 | val_loss: 1.4924 val_acc: 0.3252\n",
            "Lowest val_loss: 1.4786, at epoch 14\n",
            "LSTM 50 1 [30]\n",
            "Epoch 0: train_loss: 1.5778 train_acc: 0.2566 | val_loss: 1.5725 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2718 | val_loss: 1.5708 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2695 | val_loss: 1.5670 val_acc: 0.2661\n",
            "Epoch 3: train_loss: 1.5674 train_acc: 0.2694 | val_loss: 1.5717 val_acc: 0.2516\n",
            "Epoch 4: train_loss: 1.5587 train_acc: 0.2733 | val_loss: 1.5255 val_acc: 0.3179\n",
            "Epoch 5: train_loss: 1.5107 train_acc: 0.3161 | val_loss: 1.5494 val_acc: 0.2997\n",
            "Epoch 6: train_loss: 1.5232 train_acc: 0.3210 | val_loss: 1.4798 val_acc: 0.3406\n",
            "Epoch 7: train_loss: 1.5032 train_acc: 0.3147 | val_loss: 1.5400 val_acc: 0.3324\n",
            "Epoch 8: train_loss: 1.5317 train_acc: 0.2892 | val_loss: 1.5429 val_acc: 0.3306\n",
            "Epoch 9: train_loss: 1.5098 train_acc: 0.2980 | val_loss: 1.5305 val_acc: 0.3197\n",
            "Epoch 10: train_loss: 1.5222 train_acc: 0.2934 | val_loss: 1.5537 val_acc: 0.2607\n",
            "Epoch 11: train_loss: 1.5392 train_acc: 0.2783 | val_loss: 1.5637 val_acc: 0.2579\n",
            "Epoch 12: train_loss: 1.5315 train_acc: 0.2882 | val_loss: 1.5622 val_acc: 0.2670\n",
            "Epoch 13: train_loss: 1.5035 train_acc: 0.3044 | val_loss: 1.5209 val_acc: 0.3333\n",
            "Epoch 14: train_loss: 1.4906 train_acc: 0.3125 | val_loss: 1.4985 val_acc: 0.3297\n",
            "Epoch 15: train_loss: 1.4878 train_acc: 0.3179 | val_loss: 1.5115 val_acc: 0.3306\n",
            "Epoch 16: train_loss: 1.5140 train_acc: 0.2999 | val_loss: 1.5586 val_acc: 0.2570\n",
            "Epoch 17: train_loss: 1.5362 train_acc: 0.2824 | val_loss: 1.5610 val_acc: 0.2888\n",
            "Epoch 18: train_loss: 1.4991 train_acc: 0.3147 | val_loss: 1.5059 val_acc: 0.3243\n",
            "Epoch 19: train_loss: 1.4986 train_acc: 0.3269 | val_loss: 1.5022 val_acc: 0.3388\n",
            "Epoch 20: train_loss: 1.5331 train_acc: 0.3174 | val_loss: 1.5708 val_acc: 0.2470\n",
            "Epoch 21: train_loss: 1.5693 train_acc: 0.2667 | val_loss: 1.5686 val_acc: 0.2698\n",
            "Epoch 22: train_loss: 1.5692 train_acc: 0.2726 | val_loss: 1.5704 val_acc: 0.2616\n",
            "Epoch 23: train_loss: 1.5694 train_acc: 0.2670 | val_loss: 1.5650 val_acc: 0.2616\n",
            "Epoch 24: train_loss: 1.5694 train_acc: 0.2678 | val_loss: 1.5696 val_acc: 0.2625\n",
            "Lowest val_loss: 1.4798, at epoch 6\n",
            "LSTM 50 1 [40]\n",
            "Epoch 0: train_loss: 1.5714 train_acc: 0.2707 | val_loss: 1.5794 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2697 | val_loss: 1.5697 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5675 train_acc: 0.2715 | val_loss: 1.5562 val_acc: 0.3079\n",
            "Epoch 3: train_loss: 1.5565 train_acc: 0.2852 | val_loss: 1.4877 val_acc: 0.3560\n",
            "Epoch 4: train_loss: 1.5010 train_acc: 0.3497 | val_loss: 1.5162 val_acc: 0.3134\n",
            "Epoch 5: train_loss: 1.5383 train_acc: 0.3147 | val_loss: 1.5383 val_acc: 0.3233\n",
            "Epoch 6: train_loss: 1.5186 train_acc: 0.3274 | val_loss: 1.5216 val_acc: 0.3233\n",
            "Epoch 7: train_loss: 1.5150 train_acc: 0.3240 | val_loss: 1.5206 val_acc: 0.3224\n",
            "Epoch 8: train_loss: 1.5114 train_acc: 0.3258 | val_loss: 1.5150 val_acc: 0.3243\n",
            "Epoch 9: train_loss: 1.5127 train_acc: 0.3264 | val_loss: 1.5329 val_acc: 0.3233\n",
            "Epoch 10: train_loss: 1.5238 train_acc: 0.3263 | val_loss: 1.5233 val_acc: 0.3261\n",
            "Epoch 11: train_loss: 1.5294 train_acc: 0.3276 | val_loss: 1.5380 val_acc: 0.3106\n",
            "Epoch 12: train_loss: 1.5286 train_acc: 0.3283 | val_loss: 1.5293 val_acc: 0.3215\n",
            "Epoch 13: train_loss: 1.5257 train_acc: 0.3289 | val_loss: 1.5252 val_acc: 0.3243\n",
            "Epoch 14: train_loss: 1.5234 train_acc: 0.3295 | val_loss: 1.5175 val_acc: 0.3261\n",
            "Epoch 15: train_loss: 1.5422 train_acc: 0.2937 | val_loss: 1.5589 val_acc: 0.2670\n",
            "Epoch 16: train_loss: 1.5562 train_acc: 0.2747 | val_loss: 1.5787 val_acc: 0.2516\n",
            "Epoch 17: train_loss: 1.5689 train_acc: 0.2677 | val_loss: 1.5728 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5683 train_acc: 0.2692 | val_loss: 1.5726 val_acc: 0.2525\n",
            "Epoch 19: train_loss: 1.5689 train_acc: 0.2710 | val_loss: 1.5737 val_acc: 0.2516\n",
            "Epoch 20: train_loss: 1.5685 train_acc: 0.2699 | val_loss: 1.5751 val_acc: 0.2525\n",
            "Epoch 21: train_loss: 1.5682 train_acc: 0.2685 | val_loss: 1.5722 val_acc: 0.2525\n",
            "Epoch 22: train_loss: 1.5678 train_acc: 0.2721 | val_loss: 1.5788 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5680 train_acc: 0.2673 | val_loss: 1.5748 val_acc: 0.2525\n",
            "Epoch 24: train_loss: 1.5656 train_acc: 0.2656 | val_loss: 1.5688 val_acc: 0.2543\n",
            "Lowest val_loss: 1.4877, at epoch 3\n",
            "LSTM 50 1 [50]\n",
            "Epoch 0: train_loss: 1.5716 train_acc: 0.2691 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2719 | val_loss: 1.5726 val_acc: 0.2688\n",
            "Epoch 2: train_loss: 1.5672 train_acc: 0.2693 | val_loss: 1.5812 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5667 train_acc: 0.2715 | val_loss: 1.5945 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5636 train_acc: 0.2763 | val_loss: 1.5556 val_acc: 0.3243\n",
            "Epoch 5: train_loss: 1.5580 train_acc: 0.2781 | val_loss: 1.5899 val_acc: 0.2325\n",
            "Epoch 6: train_loss: 1.5648 train_acc: 0.2697 | val_loss: 1.5730 val_acc: 0.2470\n",
            "Epoch 7: train_loss: 1.5589 train_acc: 0.2722 | val_loss: 1.5582 val_acc: 0.2843\n",
            "Epoch 8: train_loss: 1.5630 train_acc: 0.2705 | val_loss: 1.5715 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5631 train_acc: 0.2711 | val_loss: 1.5669 val_acc: 0.2734\n",
            "Epoch 10: train_loss: 1.5621 train_acc: 0.2776 | val_loss: 1.6279 val_acc: 0.2797\n",
            "Epoch 11: train_loss: 1.5600 train_acc: 0.2779 | val_loss: 1.5755 val_acc: 0.3088\n",
            "Epoch 12: train_loss: 1.5430 train_acc: 0.3062 | val_loss: 1.4749 val_acc: 0.3442\n",
            "Epoch 13: train_loss: 1.4031 train_acc: 0.3830 | val_loss: 1.4882 val_acc: 0.3197\n",
            "Epoch 14: train_loss: 1.3098 train_acc: 0.4126 | val_loss: 1.4040 val_acc: 0.3597\n",
            "Epoch 15: train_loss: 1.2634 train_acc: 0.4341 | val_loss: 1.4979 val_acc: 0.3406\n",
            "Epoch 16: train_loss: 1.2356 train_acc: 0.4462 | val_loss: 1.4372 val_acc: 0.3724\n",
            "Epoch 17: train_loss: 1.2037 train_acc: 0.4635 | val_loss: 1.3683 val_acc: 0.3896\n",
            "Epoch 18: train_loss: 1.1991 train_acc: 0.4651 | val_loss: 1.3930 val_acc: 0.3824\n",
            "Epoch 19: train_loss: 1.1638 train_acc: 0.4828 | val_loss: 1.4040 val_acc: 0.3896\n",
            "Epoch 20: train_loss: 1.1474 train_acc: 0.4892 | val_loss: 1.3929 val_acc: 0.3933\n",
            "Epoch 21: train_loss: 1.1210 train_acc: 0.5015 | val_loss: 1.4007 val_acc: 0.4015\n",
            "Epoch 22: train_loss: 1.0982 train_acc: 0.5154 | val_loss: 1.4213 val_acc: 0.3833\n",
            "Epoch 23: train_loss: 1.0835 train_acc: 0.5178 | val_loss: 1.4322 val_acc: 0.3915\n",
            "Epoch 24: train_loss: 1.0474 train_acc: 0.5387 | val_loss: 1.5003 val_acc: 0.3906\n",
            "Lowest val_loss: 1.3683, at epoch 17\n",
            "LSTM 50 1 [60]\n",
            "Epoch 0: train_loss: 1.5715 train_acc: 0.2715 | val_loss: 1.5720 val_acc: 0.2543\n",
            "Epoch 1: train_loss: 1.5678 train_acc: 0.2708 | val_loss: 1.5698 val_acc: 0.2489\n",
            "Epoch 2: train_loss: 1.5668 train_acc: 0.2704 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5660 train_acc: 0.2728 | val_loss: 1.5794 val_acc: 0.2743\n",
            "Epoch 4: train_loss: 1.5388 train_acc: 0.3110 | val_loss: 1.4768 val_acc: 0.3488\n",
            "Epoch 5: train_loss: 1.4703 train_acc: 0.3617 | val_loss: 1.4980 val_acc: 0.3551\n",
            "Epoch 6: train_loss: 1.5006 train_acc: 0.3342 | val_loss: 1.4518 val_acc: 0.3569\n",
            "Epoch 7: train_loss: 1.4481 train_acc: 0.3645 | val_loss: 1.4399 val_acc: 0.3488\n",
            "Epoch 8: train_loss: 1.4253 train_acc: 0.3792 | val_loss: 1.4112 val_acc: 0.3706\n",
            "Epoch 9: train_loss: 1.4130 train_acc: 0.3703 | val_loss: 1.3935 val_acc: 0.3860\n",
            "Epoch 10: train_loss: 1.3755 train_acc: 0.3930 | val_loss: 1.3601 val_acc: 0.3878\n",
            "Epoch 11: train_loss: 1.3290 train_acc: 0.4015 | val_loss: 1.3355 val_acc: 0.3951\n",
            "Epoch 12: train_loss: 1.2889 train_acc: 0.4230 | val_loss: 1.3582 val_acc: 0.4015\n",
            "Epoch 13: train_loss: 1.2563 train_acc: 0.4338 | val_loss: 1.3323 val_acc: 0.4133\n",
            "Epoch 14: train_loss: 1.2267 train_acc: 0.4486 | val_loss: 1.3355 val_acc: 0.4196\n",
            "Epoch 15: train_loss: 1.2038 train_acc: 0.4556 | val_loss: 1.3341 val_acc: 0.4133\n",
            "Epoch 16: train_loss: 1.1907 train_acc: 0.4684 | val_loss: 1.3457 val_acc: 0.4178\n",
            "Epoch 17: train_loss: 1.1667 train_acc: 0.4817 | val_loss: 1.3470 val_acc: 0.4033\n",
            "Epoch 18: train_loss: 1.1432 train_acc: 0.4933 | val_loss: 1.3526 val_acc: 0.4096\n",
            "Epoch 19: train_loss: 1.1258 train_acc: 0.5005 | val_loss: 1.3509 val_acc: 0.4078\n",
            "Epoch 20: train_loss: 1.0927 train_acc: 0.5179 | val_loss: 1.3760 val_acc: 0.4087\n",
            "Epoch 21: train_loss: 1.0752 train_acc: 0.5325 | val_loss: 1.3692 val_acc: 0.4114\n",
            "Epoch 22: train_loss: 1.0454 train_acc: 0.5446 | val_loss: 1.4482 val_acc: 0.3969\n",
            "Epoch 23: train_loss: 1.0275 train_acc: 0.5576 | val_loss: 1.3796 val_acc: 0.3960\n",
            "Epoch 24: train_loss: 0.9879 train_acc: 0.5779 | val_loss: 1.4486 val_acc: 0.4033\n",
            "Lowest val_loss: 1.3323, at epoch 13\n",
            "LSTM 50 1 [70]\n",
            "Epoch 0: train_loss: 1.5719 train_acc: 0.2672 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5684 train_acc: 0.2688 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5676 train_acc: 0.2653 | val_loss: 1.5670 val_acc: 0.2643\n",
            "Epoch 3: train_loss: 1.5665 train_acc: 0.2701 | val_loss: 1.5719 val_acc: 0.2934\n",
            "Epoch 4: train_loss: 1.5658 train_acc: 0.2691 | val_loss: 1.6045 val_acc: 0.2525\n",
            "Epoch 5: train_loss: 1.5636 train_acc: 0.2725 | val_loss: 1.5597 val_acc: 0.2525\n",
            "Epoch 6: train_loss: 1.5306 train_acc: 0.3052 | val_loss: 1.5423 val_acc: 0.3043\n",
            "Epoch 7: train_loss: 1.5258 train_acc: 0.3120 | val_loss: 1.5434 val_acc: 0.3134\n",
            "Epoch 8: train_loss: 1.5267 train_acc: 0.3063 | val_loss: 1.5522 val_acc: 0.2916\n",
            "Epoch 9: train_loss: 1.5290 train_acc: 0.2974 | val_loss: 1.5518 val_acc: 0.2879\n",
            "Epoch 10: train_loss: 1.5253 train_acc: 0.2987 | val_loss: 1.5513 val_acc: 0.3215\n",
            "Epoch 11: train_loss: 1.5377 train_acc: 0.2858 | val_loss: 1.5789 val_acc: 0.2543\n",
            "Epoch 12: train_loss: 1.5418 train_acc: 0.2841 | val_loss: 1.5907 val_acc: 0.2961\n",
            "Epoch 13: train_loss: 1.5329 train_acc: 0.2982 | val_loss: 1.4979 val_acc: 0.3488\n",
            "Epoch 14: train_loss: 1.5036 train_acc: 0.3408 | val_loss: 1.5380 val_acc: 0.3170\n",
            "Epoch 15: train_loss: 1.5240 train_acc: 0.3054 | val_loss: 1.5475 val_acc: 0.3143\n",
            "Epoch 16: train_loss: 1.5335 train_acc: 0.2897 | val_loss: 1.5370 val_acc: 0.3043\n",
            "Epoch 17: train_loss: 1.5227 train_acc: 0.3074 | val_loss: 1.5347 val_acc: 0.3279\n",
            "Epoch 18: train_loss: 1.5501 train_acc: 0.2728 | val_loss: 1.5252 val_acc: 0.3197\n",
            "Epoch 19: train_loss: 1.5452 train_acc: 0.2864 | val_loss: 1.4935 val_acc: 0.3351\n",
            "Epoch 20: train_loss: 1.4157 train_acc: 0.3739 | val_loss: 1.4202 val_acc: 0.3751\n",
            "Epoch 21: train_loss: 1.3255 train_acc: 0.4095 | val_loss: 1.3614 val_acc: 0.3942\n",
            "Epoch 22: train_loss: 1.2865 train_acc: 0.4272 | val_loss: 1.3405 val_acc: 0.4060\n",
            "Epoch 23: train_loss: 1.2691 train_acc: 0.4313 | val_loss: 1.3449 val_acc: 0.3878\n",
            "Epoch 24: train_loss: 1.2451 train_acc: 0.4382 | val_loss: 1.3541 val_acc: 0.4015\n",
            "Lowest val_loss: 1.3405, at epoch 22\n",
            "LSTM 50 2 [30]\n",
            "Epoch 0: train_loss: 1.5748 train_acc: 0.2628 | val_loss: 1.5804 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2687 | val_loss: 1.5780 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5689 train_acc: 0.2714 | val_loss: 1.5735 val_acc: 0.2443\n",
            "Epoch 3: train_loss: 1.5693 train_acc: 0.2659 | val_loss: 1.5721 val_acc: 0.2425\n",
            "Epoch 4: train_loss: 1.5672 train_acc: 0.2706 | val_loss: 1.5568 val_acc: 0.2770\n",
            "Epoch 5: train_loss: 1.5684 train_acc: 0.2676 | val_loss: 1.5645 val_acc: 0.2634\n",
            "Epoch 6: train_loss: 1.5635 train_acc: 0.2779 | val_loss: 1.5622 val_acc: 0.2934\n",
            "Epoch 7: train_loss: 1.5613 train_acc: 0.2885 | val_loss: 1.5759 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5685 train_acc: 0.2705 | val_loss: 1.5750 val_acc: 0.2652\n",
            "Epoch 9: train_loss: 1.5689 train_acc: 0.2651 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5688 train_acc: 0.2669 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5683 train_acc: 0.2719 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5682 train_acc: 0.2717 | val_loss: 1.5750 val_acc: 0.2552\n",
            "Epoch 13: train_loss: 1.5690 train_acc: 0.2644 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5685 train_acc: 0.2665 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5685 train_acc: 0.2702 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5683 train_acc: 0.2691 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5568, at epoch 4\n",
            "LSTM 50 2 [40]\n",
            "Epoch 0: train_loss: 1.5750 train_acc: 0.2637 | val_loss: 1.5760 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2699 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5693 train_acc: 0.2680 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5687 train_acc: 0.2642 | val_loss: 1.5698 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5675 train_acc: 0.2679 | val_loss: 1.5727 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5681 train_acc: 0.2653 | val_loss: 1.5799 val_acc: 0.2543\n",
            "Epoch 6: train_loss: 1.5678 train_acc: 0.2718 | val_loss: 1.5665 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5662 train_acc: 0.2667 | val_loss: 1.5668 val_acc: 0.2543\n",
            "Epoch 8: train_loss: 1.5648 train_acc: 0.2664 | val_loss: 1.5706 val_acc: 0.2670\n",
            "Epoch 9: train_loss: 1.5631 train_acc: 0.2715 | val_loss: 1.5592 val_acc: 0.3206\n",
            "Epoch 10: train_loss: 1.5574 train_acc: 0.2905 | val_loss: 1.5607 val_acc: 0.2779\n",
            "Epoch 11: train_loss: 1.5646 train_acc: 0.2842 | val_loss: 1.5659 val_acc: 0.2643\n",
            "Epoch 12: train_loss: 1.5523 train_acc: 0.2870 | val_loss: 1.5404 val_acc: 0.3134\n",
            "Epoch 13: train_loss: 1.5369 train_acc: 0.3069 | val_loss: 1.5368 val_acc: 0.2825\n",
            "Epoch 14: train_loss: 1.5140 train_acc: 0.3189 | val_loss: 1.5324 val_acc: 0.3061\n",
            "Epoch 15: train_loss: 1.5068 train_acc: 0.3423 | val_loss: 1.5066 val_acc: 0.3252\n",
            "Epoch 16: train_loss: 1.5028 train_acc: 0.3380 | val_loss: 1.5064 val_acc: 0.3070\n",
            "Epoch 17: train_loss: 1.4724 train_acc: 0.3571 | val_loss: 1.4482 val_acc: 0.3615\n",
            "Epoch 18: train_loss: 1.4708 train_acc: 0.3556 | val_loss: 1.4817 val_acc: 0.3524\n",
            "Epoch 19: train_loss: 1.4919 train_acc: 0.3556 | val_loss: 1.5220 val_acc: 0.3252\n",
            "Epoch 20: train_loss: 1.4792 train_acc: 0.3580 | val_loss: 1.5243 val_acc: 0.3370\n",
            "Epoch 21: train_loss: 1.4742 train_acc: 0.3564 | val_loss: 1.4962 val_acc: 0.3215\n",
            "Epoch 22: train_loss: 1.4734 train_acc: 0.3512 | val_loss: 1.4820 val_acc: 0.3488\n",
            "Epoch 23: train_loss: 1.4562 train_acc: 0.3545 | val_loss: 1.4625 val_acc: 0.3533\n",
            "Epoch 24: train_loss: 1.4399 train_acc: 0.3629 | val_loss: 1.4462 val_acc: 0.3451\n",
            "Lowest val_loss: 1.4462, at epoch 24\n",
            "LSTM 50 2 [50]\n",
            "Epoch 0: train_loss: 1.5760 train_acc: 0.2633 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2657 | val_loss: 1.5740 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2715 | val_loss: 1.5723 val_acc: 0.2579\n",
            "Epoch 3: train_loss: 1.5702 train_acc: 0.2636 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5699 train_acc: 0.2688 | val_loss: 1.5739 val_acc: 0.2552\n",
            "Epoch 5: train_loss: 1.5686 train_acc: 0.2690 | val_loss: 1.5721 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5627 train_acc: 0.2811 | val_loss: 1.5673 val_acc: 0.2988\n",
            "Epoch 7: train_loss: 1.5683 train_acc: 0.2717 | val_loss: 1.5742 val_acc: 0.2543\n",
            "Epoch 8: train_loss: 1.5690 train_acc: 0.2686 | val_loss: 1.5742 val_acc: 0.2543\n",
            "Epoch 9: train_loss: 1.5691 train_acc: 0.2693 | val_loss: 1.5742 val_acc: 0.2543\n",
            "Epoch 10: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5742 val_acc: 0.2543\n",
            "Epoch 11: train_loss: 1.5686 train_acc: 0.2707 | val_loss: 1.5732 val_acc: 0.2543\n",
            "Epoch 12: train_loss: 1.5683 train_acc: 0.2702 | val_loss: 1.5752 val_acc: 0.2543\n",
            "Epoch 13: train_loss: 1.5687 train_acc: 0.2688 | val_loss: 1.5734 val_acc: 0.2997\n",
            "Epoch 14: train_loss: 1.5684 train_acc: 0.2719 | val_loss: 1.5736 val_acc: 0.2543\n",
            "Epoch 15: train_loss: 1.5690 train_acc: 0.2649 | val_loss: 1.5745 val_acc: 0.2543\n",
            "Epoch 16: train_loss: 1.5685 train_acc: 0.2670 | val_loss: 1.5736 val_acc: 0.2525\n",
            "Epoch 17: train_loss: 1.5689 train_acc: 0.2718 | val_loss: 1.5735 val_acc: 0.2543\n",
            "Epoch 18: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5736 val_acc: 0.2543\n",
            "Epoch 19: train_loss: 1.5681 train_acc: 0.2718 | val_loss: 1.5775 val_acc: 0.2525\n",
            "Epoch 20: train_loss: 1.5690 train_acc: 0.2700 | val_loss: 1.5732 val_acc: 0.2543\n",
            "Epoch 21: train_loss: 1.5686 train_acc: 0.2740 | val_loss: 1.5719 val_acc: 0.3415\n",
            "Epoch 22: train_loss: 1.5103 train_acc: 0.3320 | val_loss: 1.4459 val_acc: 0.3669\n",
            "Epoch 23: train_loss: 1.3868 train_acc: 0.3879 | val_loss: 1.4422 val_acc: 0.3333\n",
            "Epoch 24: train_loss: 1.3055 train_acc: 0.4168 | val_loss: 1.3876 val_acc: 0.3806\n",
            "Lowest val_loss: 1.3876, at epoch 24\n",
            "LSTM 50 2 [60]\n",
            "Epoch 0: train_loss: 1.5743 train_acc: 0.2663 | val_loss: 1.5803 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2687 | val_loss: 1.5736 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5691 train_acc: 0.2722 | val_loss: 1.5678 val_acc: 0.2834\n",
            "Epoch 3: train_loss: 1.5676 train_acc: 0.2725 | val_loss: 1.5540 val_acc: 0.3015\n",
            "Epoch 4: train_loss: 1.5447 train_acc: 0.3068 | val_loss: 1.5506 val_acc: 0.2879\n",
            "Epoch 5: train_loss: 1.5503 train_acc: 0.2908 | val_loss: 1.5641 val_acc: 0.2770\n",
            "Epoch 6: train_loss: 1.5527 train_acc: 0.2948 | val_loss: 1.5651 val_acc: 0.2752\n",
            "Epoch 7: train_loss: 1.5550 train_acc: 0.2772 | val_loss: 1.5691 val_acc: 0.2625\n",
            "Epoch 8: train_loss: 1.5566 train_acc: 0.2802 | val_loss: 1.5665 val_acc: 0.2707\n",
            "Epoch 9: train_loss: 1.5555 train_acc: 0.2804 | val_loss: 1.5662 val_acc: 0.2716\n",
            "Epoch 10: train_loss: 1.5567 train_acc: 0.2777 | val_loss: 1.5661 val_acc: 0.2716\n",
            "Epoch 11: train_loss: 1.5556 train_acc: 0.2814 | val_loss: 1.5603 val_acc: 0.2807\n",
            "Epoch 12: train_loss: 1.5464 train_acc: 0.2887 | val_loss: 1.5205 val_acc: 0.3252\n",
            "Epoch 13: train_loss: 1.5415 train_acc: 0.2978 | val_loss: 1.5595 val_acc: 0.2489\n",
            "Epoch 14: train_loss: 1.5646 train_acc: 0.2770 | val_loss: 1.5695 val_acc: 0.3115\n",
            "Epoch 15: train_loss: 1.5667 train_acc: 0.2718 | val_loss: 1.5531 val_acc: 0.2698\n",
            "Epoch 16: train_loss: 1.5575 train_acc: 0.2710 | val_loss: 1.5584 val_acc: 0.2525\n",
            "Epoch 17: train_loss: 1.5595 train_acc: 0.2719 | val_loss: 1.5579 val_acc: 0.2916\n",
            "Epoch 18: train_loss: 1.5646 train_acc: 0.2782 | val_loss: 1.5658 val_acc: 0.2870\n",
            "Epoch 19: train_loss: 1.5137 train_acc: 0.3420 | val_loss: 1.5364 val_acc: 0.2952\n",
            "Epoch 20: train_loss: 1.4022 train_acc: 0.3793 | val_loss: 1.4775 val_acc: 0.3324\n",
            "Epoch 21: train_loss: 1.3538 train_acc: 0.3867 | val_loss: 1.4666 val_acc: 0.3406\n",
            "Epoch 22: train_loss: 1.3070 train_acc: 0.4075 | val_loss: 1.3791 val_acc: 0.3815\n",
            "Epoch 23: train_loss: 1.2792 train_acc: 0.4232 | val_loss: 1.3600 val_acc: 0.3869\n",
            "Epoch 24: train_loss: 1.2527 train_acc: 0.4379 | val_loss: 1.3555 val_acc: 0.3960\n",
            "Lowest val_loss: 1.3555, at epoch 24\n",
            "LSTM 50 2 [70]\n",
            "Epoch 0: train_loss: 1.5736 train_acc: 0.2615 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5732 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2690 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5610 train_acc: 0.2717 | val_loss: 1.5452 val_acc: 0.3279\n",
            "Epoch 4: train_loss: 1.5540 train_acc: 0.2795 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5675 train_acc: 0.2616 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5675 train_acc: 0.2719 | val_loss: 1.5738 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5675 train_acc: 0.2702 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5677 train_acc: 0.2649 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5674 train_acc: 0.2717 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5672 train_acc: 0.2700 | val_loss: 1.5734 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5671 train_acc: 0.2700 | val_loss: 1.5720 val_acc: 0.2516\n",
            "Epoch 12: train_loss: 1.5673 train_acc: 0.2717 | val_loss: 1.5725 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5533 train_acc: 0.2739 | val_loss: 1.5616 val_acc: 0.3524\n",
            "Epoch 14: train_loss: 1.5709 train_acc: 0.2678 | val_loss: 1.5710 val_acc: 0.2688\n",
            "Epoch 15: train_loss: 1.5698 train_acc: 0.2673 | val_loss: 1.5683 val_acc: 0.2688\n",
            "Epoch 16: train_loss: 1.5691 train_acc: 0.2718 | val_loss: 1.5704 val_acc: 0.2725\n",
            "Epoch 17: train_loss: 1.5690 train_acc: 0.2637 | val_loss: 1.5687 val_acc: 0.2625\n",
            "Epoch 18: train_loss: 1.5689 train_acc: 0.2717 | val_loss: 1.5678 val_acc: 0.2743\n",
            "Epoch 19: train_loss: 1.5686 train_acc: 0.2699 | val_loss: 1.5697 val_acc: 0.2698\n",
            "Epoch 20: train_loss: 1.5685 train_acc: 0.2688 | val_loss: 1.5682 val_acc: 0.2707\n",
            "Epoch 21: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5679 val_acc: 0.2707\n",
            "Epoch 22: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5680 val_acc: 0.2707\n",
            "Epoch 23: train_loss: 1.5688 train_acc: 0.2618 | val_loss: 1.5683 val_acc: 0.2698\n",
            "Epoch 24: train_loss: 1.5684 train_acc: 0.2700 | val_loss: 1.5686 val_acc: 0.2634\n",
            "Lowest val_loss: 1.5452, at epoch 3\n",
            "LSTM 60 1 [30]\n",
            "Epoch 0: train_loss: 1.5796 train_acc: 0.2444 | val_loss: 1.5717 val_acc: 0.3015\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2688 | val_loss: 1.5578 val_acc: 0.2743\n",
            "Epoch 2: train_loss: 1.5702 train_acc: 0.2725 | val_loss: 1.5742 val_acc: 0.2153\n",
            "Epoch 3: train_loss: 1.5552 train_acc: 0.2793 | val_loss: 1.5737 val_acc: 0.2162\n",
            "Epoch 4: train_loss: 1.5584 train_acc: 0.2720 | val_loss: 1.5612 val_acc: 0.2807\n",
            "Epoch 5: train_loss: 1.5676 train_acc: 0.2733 | val_loss: 1.5901 val_acc: 0.2552\n",
            "Epoch 6: train_loss: 1.5677 train_acc: 0.2734 | val_loss: 1.5625 val_acc: 0.3333\n",
            "Epoch 7: train_loss: 1.5623 train_acc: 0.2865 | val_loss: 1.5592 val_acc: 0.2761\n",
            "Epoch 8: train_loss: 1.5546 train_acc: 0.2900 | val_loss: 1.5251 val_acc: 0.3188\n",
            "Epoch 9: train_loss: 1.5341 train_acc: 0.3246 | val_loss: 1.5349 val_acc: 0.3034\n",
            "Epoch 10: train_loss: 1.5292 train_acc: 0.3258 | val_loss: 1.5277 val_acc: 0.3170\n",
            "Epoch 11: train_loss: 1.5307 train_acc: 0.3221 | val_loss: 1.5395 val_acc: 0.3043\n",
            "Epoch 12: train_loss: 1.5318 train_acc: 0.3072 | val_loss: 1.5382 val_acc: 0.2652\n",
            "Epoch 13: train_loss: 1.5314 train_acc: 0.3082 | val_loss: 1.5315 val_acc: 0.3070\n",
            "Epoch 14: train_loss: 1.5335 train_acc: 0.3036 | val_loss: 1.5398 val_acc: 0.2943\n",
            "Epoch 15: train_loss: 1.5328 train_acc: 0.3146 | val_loss: 1.5347 val_acc: 0.3070\n",
            "Epoch 16: train_loss: 1.5298 train_acc: 0.3178 | val_loss: 1.5307 val_acc: 0.3061\n",
            "Epoch 17: train_loss: 1.5303 train_acc: 0.3184 | val_loss: 1.5297 val_acc: 0.3079\n",
            "Epoch 18: train_loss: 1.5306 train_acc: 0.3140 | val_loss: 1.5329 val_acc: 0.3124\n",
            "Epoch 19: train_loss: 1.5282 train_acc: 0.3150 | val_loss: 1.5266 val_acc: 0.3170\n",
            "Epoch 20: train_loss: 1.5277 train_acc: 0.3154 | val_loss: 1.5272 val_acc: 0.3288\n",
            "Epoch 21: train_loss: 1.5230 train_acc: 0.3139 | val_loss: 1.5302 val_acc: 0.3152\n",
            "Epoch 22: train_loss: 1.5301 train_acc: 0.3140 | val_loss: 1.5350 val_acc: 0.3161\n",
            "Epoch 23: train_loss: 1.5379 train_acc: 0.3016 | val_loss: 1.5398 val_acc: 0.3442\n",
            "Epoch 24: train_loss: 1.5398 train_acc: 0.3038 | val_loss: 1.5763 val_acc: 0.3088\n",
            "Lowest val_loss: 1.5251, at epoch 8\n",
            "LSTM 60 1 [40]\n",
            "Epoch 0: train_loss: 1.5811 train_acc: 0.2518 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2693 | val_loss: 1.5757 val_acc: 0.2870\n",
            "Epoch 2: train_loss: 1.5693 train_acc: 0.2624 | val_loss: 1.5684 val_acc: 0.2861\n",
            "Epoch 3: train_loss: 1.5676 train_acc: 0.2692 | val_loss: 1.5663 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5665 train_acc: 0.2721 | val_loss: 1.5518 val_acc: 0.2997\n",
            "Epoch 5: train_loss: 1.5359 train_acc: 0.3145 | val_loss: 1.4937 val_acc: 0.3388\n",
            "Epoch 6: train_loss: 1.5665 train_acc: 0.2770 | val_loss: 1.5660 val_acc: 0.2561\n",
            "Epoch 7: train_loss: 1.5316 train_acc: 0.3202 | val_loss: 1.4707 val_acc: 0.3433\n",
            "Epoch 8: train_loss: 1.4349 train_acc: 0.3805 | val_loss: 1.4453 val_acc: 0.3651\n",
            "Epoch 9: train_loss: 1.3715 train_acc: 0.3954 | val_loss: 1.4334 val_acc: 0.3406\n",
            "Epoch 10: train_loss: 1.3116 train_acc: 0.4062 | val_loss: 1.3837 val_acc: 0.3542\n",
            "Epoch 11: train_loss: 1.2725 train_acc: 0.4256 | val_loss: 1.3408 val_acc: 0.4260\n",
            "Epoch 12: train_loss: 1.2468 train_acc: 0.4412 | val_loss: 1.3334 val_acc: 0.4260\n",
            "Epoch 13: train_loss: 1.2134 train_acc: 0.4577 | val_loss: 1.3372 val_acc: 0.4178\n",
            "Epoch 14: train_loss: 1.1855 train_acc: 0.4764 | val_loss: 1.3106 val_acc: 0.4287\n",
            "Epoch 15: train_loss: 1.1719 train_acc: 0.4800 | val_loss: 1.3126 val_acc: 0.4242\n",
            "Epoch 16: train_loss: 1.1586 train_acc: 0.4820 | val_loss: 1.3290 val_acc: 0.4342\n",
            "Epoch 17: train_loss: 1.1268 train_acc: 0.4966 | val_loss: 1.3107 val_acc: 0.4187\n",
            "Epoch 18: train_loss: 1.1088 train_acc: 0.5066 | val_loss: 1.3405 val_acc: 0.4332\n",
            "Epoch 19: train_loss: 1.0893 train_acc: 0.5195 | val_loss: 1.3293 val_acc: 0.4323\n",
            "Epoch 20: train_loss: 1.0561 train_acc: 0.5387 | val_loss: 1.3220 val_acc: 0.4305\n",
            "Epoch 21: train_loss: 1.0351 train_acc: 0.5527 | val_loss: 1.3264 val_acc: 0.4414\n",
            "Epoch 22: train_loss: 1.0125 train_acc: 0.5590 | val_loss: 1.3242 val_acc: 0.4332\n",
            "Epoch 23: train_loss: 0.9843 train_acc: 0.5748 | val_loss: 1.3305 val_acc: 0.4387\n",
            "Epoch 24: train_loss: 0.9580 train_acc: 0.5913 | val_loss: 1.3462 val_acc: 0.4469\n",
            "Lowest val_loss: 1.3106, at epoch 14\n",
            "LSTM 60 1 [50]\n",
            "Epoch 0: train_loss: 1.5772 train_acc: 0.2580 | val_loss: 1.5713 val_acc: 0.2716\n",
            "Epoch 1: train_loss: 1.5682 train_acc: 0.2672 | val_loss: 1.5687 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2674 | val_loss: 1.5586 val_acc: 0.2716\n",
            "Epoch 3: train_loss: 1.5579 train_acc: 0.2859 | val_loss: 1.5674 val_acc: 0.2698\n",
            "Epoch 4: train_loss: 1.5288 train_acc: 0.3056 | val_loss: 1.5039 val_acc: 0.3197\n",
            "Epoch 5: train_loss: 1.5683 train_acc: 0.2691 | val_loss: 1.5839 val_acc: 0.2525\n",
            "Epoch 6: train_loss: 1.5678 train_acc: 0.2665 | val_loss: 1.5833 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5680 train_acc: 0.2718 | val_loss: 1.5774 val_acc: 0.2498\n",
            "Epoch 8: train_loss: 1.5677 train_acc: 0.2691 | val_loss: 1.5725 val_acc: 0.2516\n",
            "Epoch 9: train_loss: 1.5667 train_acc: 0.2726 | val_loss: 1.5762 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5660 train_acc: 0.2692 | val_loss: 1.5791 val_acc: 0.2516\n",
            "Epoch 11: train_loss: 1.5652 train_acc: 0.2704 | val_loss: 1.5718 val_acc: 0.2788\n",
            "Epoch 12: train_loss: 1.5641 train_acc: 0.2732 | val_loss: 1.6133 val_acc: 0.2607\n",
            "Epoch 13: train_loss: 1.5642 train_acc: 0.2672 | val_loss: 1.5709 val_acc: 0.2834\n",
            "Epoch 14: train_loss: 1.5624 train_acc: 0.2693 | val_loss: 1.5855 val_acc: 0.2643\n",
            "Epoch 15: train_loss: 1.5611 train_acc: 0.2722 | val_loss: 1.5567 val_acc: 0.2670\n",
            "Epoch 16: train_loss: 1.5531 train_acc: 0.2864 | val_loss: 1.5029 val_acc: 0.3342\n",
            "Epoch 17: train_loss: 1.5508 train_acc: 0.2794 | val_loss: 1.5704 val_acc: 0.2961\n",
            "Epoch 18: train_loss: 1.5638 train_acc: 0.2705 | val_loss: 1.5587 val_acc: 0.2661\n",
            "Epoch 19: train_loss: 1.5422 train_acc: 0.2832 | val_loss: 1.4944 val_acc: 0.3751\n",
            "Epoch 20: train_loss: 1.4827 train_acc: 0.3391 | val_loss: 1.4734 val_acc: 0.3551\n",
            "Epoch 21: train_loss: 1.4309 train_acc: 0.3737 | val_loss: 1.4464 val_acc: 0.3678\n",
            "Epoch 22: train_loss: 1.4147 train_acc: 0.3897 | val_loss: 1.4127 val_acc: 0.3842\n",
            "Epoch 23: train_loss: 1.3852 train_acc: 0.3948 | val_loss: 1.4158 val_acc: 0.3824\n",
            "Epoch 24: train_loss: 1.3715 train_acc: 0.3952 | val_loss: 1.3851 val_acc: 0.4060\n",
            "Lowest val_loss: 1.3851, at epoch 24\n",
            "LSTM 60 1 [60]\n",
            "Epoch 0: train_loss: 1.5722 train_acc: 0.2654 | val_loss: 1.5759 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2707 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5670 train_acc: 0.2697 | val_loss: 1.5717 val_acc: 0.2552\n",
            "Epoch 3: train_loss: 1.5664 train_acc: 0.2707 | val_loss: 1.5639 val_acc: 0.2507\n",
            "Epoch 4: train_loss: 1.5527 train_acc: 0.2894 | val_loss: 1.5850 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5680 train_acc: 0.2702 | val_loss: 1.5775 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5660 train_acc: 0.2700 | val_loss: 1.5850 val_acc: 0.2543\n",
            "Epoch 7: train_loss: 1.5654 train_acc: 0.2674 | val_loss: 1.5895 val_acc: 0.2234\n",
            "Epoch 8: train_loss: 1.5648 train_acc: 0.2750 | val_loss: 1.6054 val_acc: 0.2461\n",
            "Epoch 9: train_loss: 1.5639 train_acc: 0.2710 | val_loss: 1.5891 val_acc: 0.2616\n",
            "Epoch 10: train_loss: 1.5570 train_acc: 0.2838 | val_loss: 1.5493 val_acc: 0.3270\n",
            "Epoch 11: train_loss: 1.5638 train_acc: 0.2767 | val_loss: 1.5847 val_acc: 0.2361\n",
            "Epoch 12: train_loss: 1.5628 train_acc: 0.2732 | val_loss: 1.5938 val_acc: 0.2498\n",
            "Epoch 13: train_loss: 1.5619 train_acc: 0.2746 | val_loss: 1.5765 val_acc: 0.2434\n",
            "Epoch 14: train_loss: 1.5598 train_acc: 0.2760 | val_loss: 1.6267 val_acc: 0.2507\n",
            "Epoch 15: train_loss: 1.5570 train_acc: 0.2741 | val_loss: 1.6346 val_acc: 0.2734\n",
            "Epoch 16: train_loss: 1.5530 train_acc: 0.2963 | val_loss: 1.5653 val_acc: 0.3106\n",
            "Epoch 17: train_loss: 1.4737 train_acc: 0.3675 | val_loss: 1.4758 val_acc: 0.3542\n",
            "Epoch 18: train_loss: 1.4053 train_acc: 0.3907 | val_loss: 1.4292 val_acc: 0.3615\n",
            "Epoch 19: train_loss: 1.3327 train_acc: 0.4054 | val_loss: 1.4181 val_acc: 0.3760\n",
            "Epoch 20: train_loss: 1.3046 train_acc: 0.4210 | val_loss: 1.4113 val_acc: 0.3597\n",
            "Epoch 21: train_loss: 1.2744 train_acc: 0.4276 | val_loss: 1.3939 val_acc: 0.3878\n",
            "Epoch 22: train_loss: 1.2446 train_acc: 0.4405 | val_loss: 1.4239 val_acc: 0.3887\n",
            "Epoch 23: train_loss: 1.2174 train_acc: 0.4546 | val_loss: 1.4395 val_acc: 0.3733\n",
            "Epoch 24: train_loss: 1.2037 train_acc: 0.4592 | val_loss: 1.3814 val_acc: 0.3933\n",
            "Lowest val_loss: 1.3814, at epoch 24\n",
            "LSTM 60 1 [70]\n",
            "Epoch 0: train_loss: 1.5750 train_acc: 0.2653 | val_loss: 1.5734 val_acc: 0.2480\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2704 | val_loss: 1.5697 val_acc: 0.3115\n",
            "Epoch 2: train_loss: 1.5677 train_acc: 0.2667 | val_loss: 1.5721 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5672 train_acc: 0.2713 | val_loss: 1.5615 val_acc: 0.2616\n",
            "Epoch 4: train_loss: 1.5654 train_acc: 0.2676 | val_loss: 1.5627 val_acc: 0.2507\n",
            "Epoch 5: train_loss: 1.5277 train_acc: 0.3206 | val_loss: 1.5593 val_acc: 0.2961\n",
            "Epoch 6: train_loss: 1.5341 train_acc: 0.2942 | val_loss: 1.4933 val_acc: 0.3324\n",
            "Epoch 7: train_loss: 1.5692 train_acc: 0.2740 | val_loss: 1.5738 val_acc: 0.2788\n",
            "Epoch 8: train_loss: 1.5681 train_acc: 0.2691 | val_loss: 1.5677 val_acc: 0.2797\n",
            "Epoch 9: train_loss: 1.5685 train_acc: 0.2724 | val_loss: 1.5708 val_acc: 0.2752\n",
            "Epoch 10: train_loss: 1.5595 train_acc: 0.2907 | val_loss: 1.5559 val_acc: 0.2952\n",
            "Epoch 11: train_loss: 1.5385 train_acc: 0.3079 | val_loss: 1.5627 val_acc: 0.2725\n",
            "Epoch 12: train_loss: 1.5496 train_acc: 0.2898 | val_loss: 1.5281 val_acc: 0.2770\n",
            "Epoch 13: train_loss: 1.5542 train_acc: 0.2812 | val_loss: 1.5747 val_acc: 0.2589\n",
            "Epoch 14: train_loss: 1.5649 train_acc: 0.2754 | val_loss: 1.5655 val_acc: 0.2507\n",
            "Epoch 15: train_loss: 1.5638 train_acc: 0.2715 | val_loss: 1.5612 val_acc: 0.2698\n",
            "Epoch 16: train_loss: 1.5616 train_acc: 0.2761 | val_loss: 1.5822 val_acc: 0.2579\n",
            "Epoch 17: train_loss: 1.5587 train_acc: 0.2810 | val_loss: 1.5871 val_acc: 0.2598\n",
            "Epoch 18: train_loss: 1.5592 train_acc: 0.2808 | val_loss: 1.5611 val_acc: 0.3143\n",
            "Epoch 19: train_loss: 1.5294 train_acc: 0.3186 | val_loss: 1.5449 val_acc: 0.2852\n",
            "Epoch 20: train_loss: 1.4803 train_acc: 0.3441 | val_loss: 1.5548 val_acc: 0.2961\n",
            "Epoch 21: train_loss: 1.4268 train_acc: 0.3826 | val_loss: 1.4824 val_acc: 0.3460\n",
            "Epoch 22: train_loss: 1.4222 train_acc: 0.3901 | val_loss: 1.3978 val_acc: 0.3815\n",
            "Epoch 23: train_loss: 1.3958 train_acc: 0.3847 | val_loss: 1.4072 val_acc: 0.3606\n",
            "Epoch 24: train_loss: 1.3698 train_acc: 0.3974 | val_loss: 1.4196 val_acc: 0.3497\n",
            "Lowest val_loss: 1.3978, at epoch 22\n",
            "LSTM 60 2 [30]\n",
            "Epoch 0: train_loss: 1.5746 train_acc: 0.2693 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2672 | val_loss: 1.5732 val_acc: 0.2489\n",
            "Epoch 2: train_loss: 1.5693 train_acc: 0.2681 | val_loss: 1.5715 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5677 train_acc: 0.2686 | val_loss: 1.5925 val_acc: 0.2707\n",
            "Epoch 4: train_loss: 1.5655 train_acc: 0.2719 | val_loss: 1.5830 val_acc: 0.2552\n",
            "Epoch 5: train_loss: 1.5680 train_acc: 0.2705 | val_loss: 1.5571 val_acc: 0.2716\n",
            "Epoch 6: train_loss: 1.5607 train_acc: 0.2856 | val_loss: 1.5748 val_acc: 0.2561\n",
            "Epoch 7: train_loss: 1.5651 train_acc: 0.2783 | val_loss: 1.5730 val_acc: 0.2561\n",
            "Epoch 8: train_loss: 1.5616 train_acc: 0.2779 | val_loss: 1.5584 val_acc: 0.2870\n",
            "Epoch 9: train_loss: 1.5406 train_acc: 0.3137 | val_loss: 1.5093 val_acc: 0.3015\n",
            "Epoch 10: train_loss: 1.5069 train_acc: 0.3317 | val_loss: 1.5017 val_acc: 0.3315\n",
            "Epoch 11: train_loss: 1.5260 train_acc: 0.3186 | val_loss: 1.5729 val_acc: 0.2552\n",
            "Epoch 12: train_loss: 1.5644 train_acc: 0.2769 | val_loss: 1.5724 val_acc: 0.2561\n",
            "Epoch 13: train_loss: 1.5634 train_acc: 0.2784 | val_loss: 1.5715 val_acc: 0.2561\n",
            "Epoch 14: train_loss: 1.5610 train_acc: 0.2777 | val_loss: 1.5700 val_acc: 0.2625\n",
            "Epoch 15: train_loss: 1.5599 train_acc: 0.2818 | val_loss: 1.5708 val_acc: 0.2607\n",
            "Epoch 16: train_loss: 1.5605 train_acc: 0.2815 | val_loss: 1.5759 val_acc: 0.2525\n",
            "Epoch 17: train_loss: 1.5672 train_acc: 0.2728 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5673 train_acc: 0.2690 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5668 train_acc: 0.2712 | val_loss: 1.5752 val_acc: 0.2525\n",
            "Epoch 20: train_loss: 1.5667 train_acc: 0.2732 | val_loss: 1.5756 val_acc: 0.2525\n",
            "Epoch 21: train_loss: 1.5670 train_acc: 0.2683 | val_loss: 1.5760 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5668 train_acc: 0.2731 | val_loss: 1.5749 val_acc: 0.2525\n",
            "Epoch 23: train_loss: 1.5671 train_acc: 0.2683 | val_loss: 1.5750 val_acc: 0.2525\n",
            "Epoch 24: train_loss: 1.5666 train_acc: 0.2713 | val_loss: 1.5747 val_acc: 0.2525\n",
            "Lowest val_loss: 1.5017, at epoch 10\n",
            "LSTM 60 2 [40]\n",
            "Epoch 0: train_loss: 1.5788 train_acc: 0.2556 | val_loss: 1.5750 val_acc: 0.2543\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2628 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5691 train_acc: 0.2687 | val_loss: 1.5762 val_acc: 0.2589\n",
            "Epoch 3: train_loss: 1.5694 train_acc: 0.2691 | val_loss: 1.5733 val_acc: 0.2879\n",
            "Epoch 4: train_loss: 1.5692 train_acc: 0.2622 | val_loss: 1.5784 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5695 train_acc: 0.2681 | val_loss: 1.5745 val_acc: 0.2552\n",
            "Epoch 6: train_loss: 1.5693 train_acc: 0.2683 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5690 train_acc: 0.2680 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5690 train_acc: 0.2673 | val_loss: 1.5740 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2552\n",
            "Epoch 10: train_loss: 1.5686 train_acc: 0.2702 | val_loss: 1.5769 val_acc: 0.2552\n",
            "Epoch 11: train_loss: 1.5677 train_acc: 0.2677 | val_loss: 1.5809 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5580 train_acc: 0.2871 | val_loss: 1.5541 val_acc: 0.3025\n",
            "Epoch 13: train_loss: 1.5008 train_acc: 0.3395 | val_loss: 1.4994 val_acc: 0.3315\n",
            "Epoch 14: train_loss: 1.4174 train_acc: 0.3683 | val_loss: 1.4163 val_acc: 0.3787\n",
            "Epoch 15: train_loss: 1.3546 train_acc: 0.3920 | val_loss: 1.3847 val_acc: 0.3851\n",
            "Epoch 16: train_loss: 1.3155 train_acc: 0.4122 | val_loss: 1.3698 val_acc: 0.3833\n",
            "Epoch 17: train_loss: 1.2993 train_acc: 0.4187 | val_loss: 1.4473 val_acc: 0.3533\n",
            "Epoch 18: train_loss: 1.2681 train_acc: 0.4321 | val_loss: 1.3769 val_acc: 0.3860\n",
            "Epoch 19: train_loss: 1.2389 train_acc: 0.4482 | val_loss: 1.3801 val_acc: 0.3860\n",
            "Epoch 20: train_loss: 1.2232 train_acc: 0.4568 | val_loss: 1.3344 val_acc: 0.4087\n",
            "Epoch 21: train_loss: 1.2071 train_acc: 0.4652 | val_loss: 1.3560 val_acc: 0.3887\n",
            "Epoch 22: train_loss: 1.1855 train_acc: 0.4759 | val_loss: 1.3559 val_acc: 0.4214\n",
            "Epoch 23: train_loss: 1.1634 train_acc: 0.4868 | val_loss: 1.3698 val_acc: 0.3942\n",
            "Epoch 24: train_loss: 1.1418 train_acc: 0.4925 | val_loss: 1.3518 val_acc: 0.4233\n",
            "Lowest val_loss: 1.3344, at epoch 20\n",
            "LSTM 60 2 [50]\n",
            "Epoch 0: train_loss: 1.5771 train_acc: 0.2574 | val_loss: 1.5779 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2644 | val_loss: 1.5734 val_acc: 0.2788\n",
            "Epoch 2: train_loss: 1.5692 train_acc: 0.2658 | val_loss: 1.5685 val_acc: 0.2688\n",
            "Epoch 3: train_loss: 1.5541 train_acc: 0.2953 | val_loss: 1.5122 val_acc: 0.3442\n",
            "Epoch 4: train_loss: 1.5254 train_acc: 0.3179 | val_loss: 1.5409 val_acc: 0.2934\n",
            "Epoch 5: train_loss: 1.5413 train_acc: 0.3153 | val_loss: 1.5439 val_acc: 0.3034\n",
            "Epoch 6: train_loss: 1.5527 train_acc: 0.2859 | val_loss: 1.5113 val_acc: 0.3397\n",
            "Epoch 7: train_loss: 1.5132 train_acc: 0.3291 | val_loss: 1.5285 val_acc: 0.2861\n",
            "Epoch 8: train_loss: 1.4967 train_acc: 0.3384 | val_loss: 1.5145 val_acc: 0.3279\n",
            "Epoch 9: train_loss: 1.4965 train_acc: 0.3430 | val_loss: 1.5192 val_acc: 0.3088\n",
            "Epoch 10: train_loss: 1.4977 train_acc: 0.3306 | val_loss: 1.5191 val_acc: 0.3006\n",
            "Epoch 11: train_loss: 1.5062 train_acc: 0.3234 | val_loss: 1.4988 val_acc: 0.3333\n",
            "Epoch 12: train_loss: 1.4811 train_acc: 0.3433 | val_loss: 1.5024 val_acc: 0.3342\n",
            "Epoch 13: train_loss: 1.4624 train_acc: 0.3501 | val_loss: 1.5483 val_acc: 0.2879\n",
            "Epoch 14: train_loss: 1.4703 train_acc: 0.3501 | val_loss: 1.4860 val_acc: 0.3424\n",
            "Epoch 15: train_loss: 1.5057 train_acc: 0.3397 | val_loss: 1.4992 val_acc: 0.3424\n",
            "Epoch 16: train_loss: 1.5130 train_acc: 0.3296 | val_loss: 1.5339 val_acc: 0.3088\n",
            "Epoch 17: train_loss: 1.5207 train_acc: 0.3226 | val_loss: 1.4711 val_acc: 0.3370\n",
            "Epoch 18: train_loss: 1.5034 train_acc: 0.3356 | val_loss: 1.5233 val_acc: 0.3233\n",
            "Epoch 19: train_loss: 1.4992 train_acc: 0.3338 | val_loss: 1.5027 val_acc: 0.3388\n",
            "Epoch 20: train_loss: 1.4867 train_acc: 0.3418 | val_loss: 1.4871 val_acc: 0.3642\n",
            "Epoch 21: train_loss: 1.4570 train_acc: 0.3629 | val_loss: 1.4411 val_acc: 0.3660\n",
            "Epoch 22: train_loss: 1.4230 train_acc: 0.3762 | val_loss: 1.4401 val_acc: 0.3415\n",
            "Epoch 23: train_loss: 1.3900 train_acc: 0.3880 | val_loss: 1.4173 val_acc: 0.3560\n",
            "Epoch 24: train_loss: 1.3554 train_acc: 0.4003 | val_loss: 1.4464 val_acc: 0.3479\n",
            "Lowest val_loss: 1.4173, at epoch 23\n",
            "LSTM 60 2 [60]\n",
            "Epoch 0: train_loss: 1.5770 train_acc: 0.2637 | val_loss: 1.5754 val_acc: 0.2625\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2681 | val_loss: 1.5745 val_acc: 0.2679\n",
            "Epoch 2: train_loss: 1.5693 train_acc: 0.2732 | val_loss: 1.5704 val_acc: 0.3297\n",
            "Epoch 3: train_loss: 1.5685 train_acc: 0.2665 | val_loss: 1.5644 val_acc: 0.2979\n",
            "Epoch 4: train_loss: 1.5578 train_acc: 0.2927 | val_loss: 1.5716 val_acc: 0.2698\n",
            "Epoch 5: train_loss: 1.5685 train_acc: 0.2691 | val_loss: 1.5712 val_acc: 0.2661\n",
            "Epoch 6: train_loss: 1.5688 train_acc: 0.2652 | val_loss: 1.5755 val_acc: 0.2625\n",
            "Epoch 7: train_loss: 1.5690 train_acc: 0.2704 | val_loss: 1.5741 val_acc: 0.2625\n",
            "Epoch 8: train_loss: 1.5691 train_acc: 0.2659 | val_loss: 1.5741 val_acc: 0.1826\n",
            "Epoch 9: train_loss: 1.5698 train_acc: 0.2700 | val_loss: 1.5750 val_acc: 0.2552\n",
            "Epoch 10: train_loss: 1.5684 train_acc: 0.2726 | val_loss: 1.5749 val_acc: 0.2625\n",
            "Epoch 11: train_loss: 1.5688 train_acc: 0.2658 | val_loss: 1.5747 val_acc: 0.2579\n",
            "Epoch 12: train_loss: 1.5687 train_acc: 0.2697 | val_loss: 1.5784 val_acc: 0.2543\n",
            "Epoch 13: train_loss: 1.5692 train_acc: 0.2706 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5684 train_acc: 0.2722 | val_loss: 1.5742 val_acc: 0.2661\n",
            "Epoch 15: train_loss: 1.5686 train_acc: 0.2713 | val_loss: 1.5743 val_acc: 0.2625\n",
            "Epoch 16: train_loss: 1.5688 train_acc: 0.2652 | val_loss: 1.5745 val_acc: 0.2552\n",
            "Epoch 17: train_loss: 1.5688 train_acc: 0.2706 | val_loss: 1.5750 val_acc: 0.2679\n",
            "Epoch 18: train_loss: 1.5685 train_acc: 0.2701 | val_loss: 1.5754 val_acc: 0.2670\n",
            "Epoch 19: train_loss: 1.5690 train_acc: 0.2659 | val_loss: 1.5774 val_acc: 0.2543\n",
            "Epoch 20: train_loss: 1.5689 train_acc: 0.2719 | val_loss: 1.5741 val_acc: 0.2552\n",
            "Epoch 21: train_loss: 1.5684 train_acc: 0.2719 | val_loss: 1.5756 val_acc: 0.2552\n",
            "Epoch 22: train_loss: 1.5685 train_acc: 0.2664 | val_loss: 1.5746 val_acc: 0.2552\n",
            "Epoch 23: train_loss: 1.5682 train_acc: 0.2719 | val_loss: 1.5748 val_acc: 0.2552\n",
            "Epoch 24: train_loss: 1.5685 train_acc: 0.2681 | val_loss: 1.5753 val_acc: 0.2543\n",
            "Lowest val_loss: 1.5644, at epoch 3\n",
            "LSTM 60 2 [70]\n",
            "Epoch 0: train_loss: 1.5768 train_acc: 0.2616 | val_loss: 1.5776 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2685 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2683 | val_loss: 1.5800 val_acc: 0.2625\n",
            "Epoch 3: train_loss: 1.5687 train_acc: 0.2683 | val_loss: 1.5597 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5510 train_acc: 0.3045 | val_loss: 1.5779 val_acc: 0.2634\n",
            "Epoch 5: train_loss: 1.5684 train_acc: 0.2691 | val_loss: 1.5713 val_acc: 0.2561\n",
            "Epoch 6: train_loss: 1.5678 train_acc: 0.2686 | val_loss: 1.5718 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5679 train_acc: 0.2722 | val_loss: 1.5680 val_acc: 0.3025\n",
            "Epoch 8: train_loss: 1.5681 train_acc: 0.2712 | val_loss: 1.5642 val_acc: 0.2788\n",
            "Epoch 9: train_loss: 1.5651 train_acc: 0.2811 | val_loss: 1.5761 val_acc: 0.2679\n",
            "Epoch 10: train_loss: 1.5703 train_acc: 0.2650 | val_loss: 1.5735 val_acc: 0.2598\n",
            "Epoch 11: train_loss: 1.5693 train_acc: 0.2688 | val_loss: 1.5735 val_acc: 0.2589\n",
            "Epoch 12: train_loss: 1.5698 train_acc: 0.2649 | val_loss: 1.5735 val_acc: 0.2561\n",
            "Epoch 13: train_loss: 1.5689 train_acc: 0.2708 | val_loss: 1.5760 val_acc: 0.2561\n",
            "Epoch 14: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5735 val_acc: 0.2598\n",
            "Epoch 15: train_loss: 1.5677 train_acc: 0.2721 | val_loss: 1.5669 val_acc: 0.2734\n",
            "Epoch 16: train_loss: 1.5621 train_acc: 0.2868 | val_loss: 1.5296 val_acc: 0.3370\n",
            "Epoch 17: train_loss: 1.5471 train_acc: 0.3027 | val_loss: 1.5853 val_acc: 0.2698\n",
            "Epoch 18: train_loss: 1.5697 train_acc: 0.2679 | val_loss: 1.5667 val_acc: 0.2725\n",
            "Epoch 19: train_loss: 1.5688 train_acc: 0.2731 | val_loss: 1.5669 val_acc: 0.2625\n",
            "Epoch 20: train_loss: 1.5692 train_acc: 0.2669 | val_loss: 1.5676 val_acc: 0.2734\n",
            "Epoch 21: train_loss: 1.5697 train_acc: 0.2664 | val_loss: 1.5679 val_acc: 0.2725\n",
            "Epoch 22: train_loss: 1.5691 train_acc: 0.2719 | val_loss: 1.5647 val_acc: 0.2725\n",
            "Epoch 23: train_loss: 1.5700 train_acc: 0.2649 | val_loss: 1.5670 val_acc: 0.2934\n",
            "Epoch 24: train_loss: 1.5684 train_acc: 0.2732 | val_loss: 1.5617 val_acc: 0.2997\n",
            "Lowest val_loss: 1.5296, at epoch 16\n",
            "LSTM 70 1 [30]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2659 | val_loss: 1.5765 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2718 | val_loss: 1.5711 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2662 | val_loss: 1.5743 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5674 train_acc: 0.2649 | val_loss: 1.5812 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5678 train_acc: 0.2705 | val_loss: 1.5640 val_acc: 0.3215\n",
            "Epoch 5: train_loss: 1.5665 train_acc: 0.2720 | val_loss: 1.5420 val_acc: 0.3006\n",
            "Epoch 6: train_loss: 1.5640 train_acc: 0.2762 | val_loss: 1.5712 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5654 train_acc: 0.2724 | val_loss: 1.5625 val_acc: 0.2543\n",
            "Epoch 8: train_loss: 1.5641 train_acc: 0.2736 | val_loss: 1.5674 val_acc: 0.2552\n",
            "Epoch 9: train_loss: 1.5580 train_acc: 0.2773 | val_loss: 1.5644 val_acc: 0.3134\n",
            "Epoch 10: train_loss: 1.5537 train_acc: 0.2962 | val_loss: 1.5560 val_acc: 0.3061\n",
            "Epoch 11: train_loss: 1.5330 train_acc: 0.3270 | val_loss: 1.5621 val_acc: 0.3079\n",
            "Epoch 12: train_loss: 1.5681 train_acc: 0.2791 | val_loss: 1.5757 val_acc: 0.2598\n",
            "Epoch 13: train_loss: 1.5668 train_acc: 0.2748 | val_loss: 1.5712 val_acc: 0.2598\n",
            "Epoch 14: train_loss: 1.5668 train_acc: 0.2752 | val_loss: 1.5704 val_acc: 0.2625\n",
            "Epoch 15: train_loss: 1.5668 train_acc: 0.2749 | val_loss: 1.5698 val_acc: 0.2607\n",
            "Epoch 16: train_loss: 1.5661 train_acc: 0.2759 | val_loss: 1.5683 val_acc: 0.2625\n",
            "Epoch 17: train_loss: 1.5679 train_acc: 0.2706 | val_loss: 1.5694 val_acc: 0.2634\n",
            "Epoch 18: train_loss: 1.5647 train_acc: 0.2756 | val_loss: 1.5655 val_acc: 0.2688\n",
            "Epoch 19: train_loss: 1.5612 train_acc: 0.2823 | val_loss: 1.5632 val_acc: 0.2661\n",
            "Epoch 20: train_loss: 1.5107 train_acc: 0.3453 | val_loss: 1.5229 val_acc: 0.3279\n",
            "Epoch 21: train_loss: 1.5112 train_acc: 0.3308 | val_loss: 1.5640 val_acc: 0.2743\n",
            "Epoch 22: train_loss: 1.5534 train_acc: 0.2928 | val_loss: 1.5449 val_acc: 0.2888\n",
            "Epoch 23: train_loss: 1.5353 train_acc: 0.3178 | val_loss: 1.5308 val_acc: 0.3370\n",
            "Epoch 24: train_loss: 1.5109 train_acc: 0.3251 | val_loss: 1.5423 val_acc: 0.2661\n",
            "Lowest val_loss: 1.5229, at epoch 20\n",
            "LSTM 70 1 [40]\n",
            "Epoch 0: train_loss: 1.5737 train_acc: 0.2687 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2686 | val_loss: 1.5706 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5672 train_acc: 0.2676 | val_loss: 1.5662 val_acc: 0.2570\n",
            "Epoch 3: train_loss: 1.5663 train_acc: 0.2664 | val_loss: 1.5604 val_acc: 0.3379\n",
            "Epoch 4: train_loss: 1.5581 train_acc: 0.2808 | val_loss: 1.4909 val_acc: 0.3569\n",
            "Epoch 5: train_loss: 1.5289 train_acc: 0.3256 | val_loss: 1.5644 val_acc: 0.2888\n",
            "Epoch 6: train_loss: 1.5419 train_acc: 0.3141 | val_loss: 1.5693 val_acc: 0.2679\n",
            "Epoch 7: train_loss: 1.5447 train_acc: 0.3086 | val_loss: 1.5615 val_acc: 0.2952\n",
            "Epoch 8: train_loss: 1.5443 train_acc: 0.2981 | val_loss: 1.5627 val_acc: 0.2797\n",
            "Epoch 9: train_loss: 1.5408 train_acc: 0.3092 | val_loss: 1.5543 val_acc: 0.3115\n",
            "Epoch 10: train_loss: 1.5339 train_acc: 0.3146 | val_loss: 1.5402 val_acc: 0.3006\n",
            "Epoch 11: train_loss: 1.5367 train_acc: 0.3181 | val_loss: 1.5904 val_acc: 0.2525\n",
            "Epoch 12: train_loss: 1.5511 train_acc: 0.2893 | val_loss: 1.5663 val_acc: 0.2552\n",
            "Epoch 13: train_loss: 1.5500 train_acc: 0.2912 | val_loss: 1.5704 val_acc: 0.2489\n",
            "Epoch 14: train_loss: 1.5492 train_acc: 0.2911 | val_loss: 1.5671 val_acc: 0.2816\n",
            "Epoch 15: train_loss: 1.5424 train_acc: 0.3045 | val_loss: 1.5656 val_acc: 0.2498\n",
            "Epoch 16: train_loss: 1.5434 train_acc: 0.2975 | val_loss: 1.5597 val_acc: 0.3106\n",
            "Epoch 17: train_loss: 1.5274 train_acc: 0.3104 | val_loss: 1.5207 val_acc: 0.3297\n",
            "Epoch 18: train_loss: 1.4989 train_acc: 0.3317 | val_loss: 1.4243 val_acc: 0.3569\n",
            "Epoch 19: train_loss: 1.3593 train_acc: 0.3972 | val_loss: 1.3793 val_acc: 0.3560\n",
            "Epoch 20: train_loss: 1.2970 train_acc: 0.4171 | val_loss: 1.3719 val_acc: 0.3760\n",
            "Epoch 21: train_loss: 1.2639 train_acc: 0.4329 | val_loss: 1.4097 val_acc: 0.3824\n",
            "Epoch 22: train_loss: 1.2449 train_acc: 0.4472 | val_loss: 1.4203 val_acc: 0.3751\n",
            "Epoch 23: train_loss: 1.2217 train_acc: 0.4504 | val_loss: 1.3762 val_acc: 0.3887\n",
            "Epoch 24: train_loss: 1.2042 train_acc: 0.4587 | val_loss: 1.3668 val_acc: 0.3960\n",
            "Lowest val_loss: 1.3668, at epoch 24\n",
            "LSTM 70 1 [50]\n",
            "Epoch 0: train_loss: 1.5757 train_acc: 0.2760 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2710 | val_loss: 1.5722 val_acc: 0.2498\n",
            "Epoch 2: train_loss: 1.5689 train_acc: 0.2628 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5681 train_acc: 0.2664 | val_loss: 1.5671 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5663 train_acc: 0.2747 | val_loss: 1.5554 val_acc: 0.2652\n",
            "Epoch 5: train_loss: 1.5585 train_acc: 0.2821 | val_loss: 1.5327 val_acc: 0.2834\n",
            "Epoch 6: train_loss: 1.5144 train_acc: 0.3239 | val_loss: 1.5359 val_acc: 0.3261\n",
            "Epoch 7: train_loss: 1.5568 train_acc: 0.2693 | val_loss: 1.5607 val_acc: 0.2561\n",
            "Epoch 8: train_loss: 1.5314 train_acc: 0.2896 | val_loss: 1.5235 val_acc: 0.3324\n",
            "Epoch 9: train_loss: 1.5555 train_acc: 0.2807 | val_loss: 1.5590 val_acc: 0.2461\n",
            "Epoch 10: train_loss: 1.5428 train_acc: 0.2837 | val_loss: 1.5436 val_acc: 0.2670\n",
            "Epoch 11: train_loss: 1.5325 train_acc: 0.2882 | val_loss: 1.5509 val_acc: 0.2825\n",
            "Epoch 12: train_loss: 1.5451 train_acc: 0.2832 | val_loss: 1.5566 val_acc: 0.2589\n",
            "Epoch 13: train_loss: 1.5584 train_acc: 0.2745 | val_loss: 1.5538 val_acc: 0.2716\n",
            "Epoch 14: train_loss: 1.5467 train_acc: 0.2793 | val_loss: 1.5817 val_acc: 0.2825\n",
            "Epoch 15: train_loss: 1.5538 train_acc: 0.2808 | val_loss: 1.6166 val_acc: 0.3088\n",
            "Epoch 16: train_loss: 1.5368 train_acc: 0.3139 | val_loss: 1.5623 val_acc: 0.2843\n",
            "Epoch 17: train_loss: 1.5419 train_acc: 0.3058 | val_loss: 1.5687 val_acc: 0.2725\n",
            "Epoch 18: train_loss: 1.5206 train_acc: 0.3106 | val_loss: 1.5536 val_acc: 0.2816\n",
            "Epoch 19: train_loss: 1.5553 train_acc: 0.2763 | val_loss: 1.5609 val_acc: 0.2498\n",
            "Epoch 20: train_loss: 1.5471 train_acc: 0.2835 | val_loss: 1.6033 val_acc: 0.2979\n",
            "Epoch 21: train_loss: 1.4885 train_acc: 0.3393 | val_loss: 1.5434 val_acc: 0.3233\n",
            "Epoch 22: train_loss: 1.4559 train_acc: 0.3655 | val_loss: 1.4951 val_acc: 0.3551\n",
            "Epoch 23: train_loss: 1.4149 train_acc: 0.3752 | val_loss: 1.4437 val_acc: 0.3533\n",
            "Epoch 24: train_loss: 1.4302 train_acc: 0.3766 | val_loss: 1.4989 val_acc: 0.3315\n",
            "Lowest val_loss: 1.4437, at epoch 23\n",
            "LSTM 70 1 [60]\n",
            "Epoch 0: train_loss: 1.5738 train_acc: 0.2590 | val_loss: 1.5710 val_acc: 0.2543\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2671 | val_loss: 1.5717 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5677 train_acc: 0.2688 | val_loss: 1.5642 val_acc: 0.2661\n",
            "Epoch 3: train_loss: 1.5655 train_acc: 0.2724 | val_loss: 1.5608 val_acc: 0.3134\n",
            "Epoch 4: train_loss: 1.5646 train_acc: 0.2707 | val_loss: 1.5466 val_acc: 0.2543\n",
            "Epoch 5: train_loss: 1.5262 train_acc: 0.3260 | val_loss: 1.5298 val_acc: 0.3224\n",
            "Epoch 6: train_loss: 1.5190 train_acc: 0.3332 | val_loss: 1.5485 val_acc: 0.2816\n",
            "Epoch 7: train_loss: 1.5396 train_acc: 0.3018 | val_loss: 1.5728 val_acc: 0.2543\n",
            "Epoch 8: train_loss: 1.5488 train_acc: 0.2846 | val_loss: 1.5636 val_acc: 0.2670\n",
            "Epoch 9: train_loss: 1.5473 train_acc: 0.2835 | val_loss: 1.5830 val_acc: 0.2589\n",
            "Epoch 10: train_loss: 1.5407 train_acc: 0.2956 | val_loss: 1.5287 val_acc: 0.3542\n",
            "Epoch 11: train_loss: 1.5335 train_acc: 0.3144 | val_loss: 1.5437 val_acc: 0.3252\n",
            "Epoch 12: train_loss: 1.5344 train_acc: 0.3167 | val_loss: 1.4934 val_acc: 0.3497\n",
            "Epoch 13: train_loss: 1.5516 train_acc: 0.2830 | val_loss: 1.5678 val_acc: 0.2552\n",
            "Epoch 14: train_loss: 1.5631 train_acc: 0.2718 | val_loss: 1.5687 val_acc: 0.2507\n",
            "Epoch 15: train_loss: 1.5626 train_acc: 0.2690 | val_loss: 1.5653 val_acc: 0.2707\n",
            "Epoch 16: train_loss: 1.5604 train_acc: 0.2754 | val_loss: 1.5654 val_acc: 0.2734\n",
            "Epoch 17: train_loss: 1.5618 train_acc: 0.2687 | val_loss: 1.5579 val_acc: 0.3061\n",
            "Epoch 18: train_loss: 1.5342 train_acc: 0.2910 | val_loss: 1.5202 val_acc: 0.3488\n",
            "Epoch 19: train_loss: 1.5625 train_acc: 0.2687 | val_loss: 1.5779 val_acc: 0.2916\n",
            "Epoch 20: train_loss: 1.5607 train_acc: 0.2762 | val_loss: 1.5484 val_acc: 0.3261\n",
            "Epoch 21: train_loss: 1.5620 train_acc: 0.2784 | val_loss: 1.6347 val_acc: 0.2616\n",
            "Epoch 22: train_loss: 1.5636 train_acc: 0.2660 | val_loss: 1.5591 val_acc: 0.2525\n",
            "Epoch 23: train_loss: 1.5427 train_acc: 0.2884 | val_loss: 1.5667 val_acc: 0.2834\n",
            "Epoch 24: train_loss: 1.5355 train_acc: 0.3040 | val_loss: 1.5494 val_acc: 0.3106\n",
            "Lowest val_loss: 1.4934, at epoch 12\n",
            "LSTM 70 1 [70]\n",
            "Epoch 0: train_loss: 1.5751 train_acc: 0.2640 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2697 | val_loss: 1.5758 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5680 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2636 | val_loss: 1.5594 val_acc: 0.2779\n",
            "Epoch 4: train_loss: 1.5658 train_acc: 0.2727 | val_loss: 1.5274 val_acc: 0.3115\n",
            "Epoch 5: train_loss: 1.5498 train_acc: 0.2910 | val_loss: 1.5720 val_acc: 0.2398\n",
            "Epoch 6: train_loss: 1.5623 train_acc: 0.2707 | val_loss: 1.5583 val_acc: 0.3188\n",
            "Epoch 7: train_loss: 1.5146 train_acc: 0.3387 | val_loss: 1.4701 val_acc: 0.3388\n",
            "Epoch 8: train_loss: 1.5185 train_acc: 0.3208 | val_loss: 1.5969 val_acc: 0.2443\n",
            "Epoch 9: train_loss: 1.5673 train_acc: 0.2607 | val_loss: 1.5836 val_acc: 0.2371\n",
            "Epoch 10: train_loss: 1.5663 train_acc: 0.2702 | val_loss: 1.5820 val_acc: 0.2380\n",
            "Epoch 11: train_loss: 1.5655 train_acc: 0.2698 | val_loss: 1.5768 val_acc: 0.2316\n",
            "Epoch 12: train_loss: 1.5654 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2443\n",
            "Epoch 13: train_loss: 1.5649 train_acc: 0.2770 | val_loss: 1.5742 val_acc: 0.2988\n",
            "Epoch 14: train_loss: 1.5630 train_acc: 0.2715 | val_loss: 1.5750 val_acc: 0.2507\n",
            "Epoch 15: train_loss: 1.5619 train_acc: 0.2756 | val_loss: 1.5770 val_acc: 0.2716\n",
            "Epoch 16: train_loss: 1.5631 train_acc: 0.2824 | val_loss: 1.5735 val_acc: 0.3106\n",
            "Epoch 17: train_loss: 1.5641 train_acc: 0.2759 | val_loss: 1.5547 val_acc: 0.3061\n",
            "Epoch 18: train_loss: 1.5622 train_acc: 0.2699 | val_loss: 1.5713 val_acc: 0.2952\n",
            "Epoch 19: train_loss: 1.5599 train_acc: 0.2746 | val_loss: 1.5335 val_acc: 0.3306\n",
            "Epoch 20: train_loss: 1.5378 train_acc: 0.2948 | val_loss: 1.4878 val_acc: 0.3533\n",
            "Epoch 21: train_loss: 1.5343 train_acc: 0.3092 | val_loss: 1.5585 val_acc: 0.2734\n",
            "Epoch 22: train_loss: 1.5346 train_acc: 0.2857 | val_loss: 1.5657 val_acc: 0.2616\n",
            "Epoch 23: train_loss: 1.5344 train_acc: 0.2842 | val_loss: 1.5308 val_acc: 0.3079\n",
            "Epoch 24: train_loss: 1.4702 train_acc: 0.3435 | val_loss: 1.5469 val_acc: 0.3143\n",
            "Lowest val_loss: 1.4701, at epoch 7\n",
            "LSTM 70 2 [30]\n",
            "Epoch 0: train_loss: 1.5747 train_acc: 0.2609 | val_loss: 1.5731 val_acc: 0.2643\n",
            "Epoch 1: train_loss: 1.5694 train_acc: 0.2715 | val_loss: 1.5717 val_acc: 0.2607\n",
            "Epoch 2: train_loss: 1.5691 train_acc: 0.2672 | val_loss: 1.5722 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5682 train_acc: 0.2717 | val_loss: 1.5679 val_acc: 0.2634\n",
            "Epoch 4: train_loss: 1.5638 train_acc: 0.2843 | val_loss: 1.5611 val_acc: 0.3034\n",
            "Epoch 5: train_loss: 1.5694 train_acc: 0.2632 | val_loss: 1.5690 val_acc: 0.3043\n",
            "Epoch 6: train_loss: 1.5677 train_acc: 0.2683 | val_loss: 1.5679 val_acc: 0.2906\n",
            "Epoch 7: train_loss: 1.5667 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2607\n",
            "Epoch 8: train_loss: 1.5640 train_acc: 0.2728 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5671 train_acc: 0.2735 | val_loss: 1.5691 val_acc: 0.3015\n",
            "Epoch 10: train_loss: 1.5671 train_acc: 0.2731 | val_loss: 1.5646 val_acc: 0.2607\n",
            "Epoch 11: train_loss: 1.5647 train_acc: 0.2683 | val_loss: 1.5495 val_acc: 0.3342\n",
            "Epoch 12: train_loss: 1.5398 train_acc: 0.3171 | val_loss: 1.5889 val_acc: 0.2607\n",
            "Epoch 13: train_loss: 1.5695 train_acc: 0.2647 | val_loss: 1.5737 val_acc: 0.2589\n",
            "Epoch 14: train_loss: 1.5686 train_acc: 0.2574 | val_loss: 1.5712 val_acc: 0.2507\n",
            "Epoch 15: train_loss: 1.5677 train_acc: 0.2734 | val_loss: 1.5699 val_acc: 0.2552\n",
            "Epoch 16: train_loss: 1.5637 train_acc: 0.2782 | val_loss: 1.5571 val_acc: 0.2861\n",
            "Epoch 17: train_loss: 1.5622 train_acc: 0.2760 | val_loss: 1.5790 val_acc: 0.2543\n",
            "Epoch 18: train_loss: 1.5678 train_acc: 0.2662 | val_loss: 1.5686 val_acc: 0.2779\n",
            "Epoch 19: train_loss: 1.5664 train_acc: 0.2715 | val_loss: 1.5690 val_acc: 0.2852\n",
            "Epoch 20: train_loss: 1.5665 train_acc: 0.2718 | val_loss: 1.5633 val_acc: 0.3224\n",
            "Epoch 21: train_loss: 1.5596 train_acc: 0.2876 | val_loss: 1.5383 val_acc: 0.3379\n",
            "Epoch 22: train_loss: 1.5195 train_acc: 0.3283 | val_loss: 1.4951 val_acc: 0.3688\n",
            "Epoch 23: train_loss: 1.5182 train_acc: 0.3100 | val_loss: 1.5583 val_acc: 0.3115\n",
            "Epoch 24: train_loss: 1.4869 train_acc: 0.3441 | val_loss: 1.4635 val_acc: 0.3597\n",
            "Lowest val_loss: 1.4635, at epoch 24\n",
            "LSTM 70 2 [40]\n",
            "Epoch 0: train_loss: 1.5761 train_acc: 0.2631 | val_loss: 1.5734 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2708 | val_loss: 1.5483 val_acc: 0.3197\n",
            "Epoch 2: train_loss: 1.5635 train_acc: 0.2827 | val_loss: 1.5719 val_acc: 0.2652\n",
            "Epoch 3: train_loss: 1.5641 train_acc: 0.2718 | val_loss: 1.5671 val_acc: 0.2670\n",
            "Epoch 4: train_loss: 1.5591 train_acc: 0.2680 | val_loss: 1.5603 val_acc: 0.2552\n",
            "Epoch 5: train_loss: 1.5418 train_acc: 0.2938 | val_loss: 1.5174 val_acc: 0.3379\n",
            "Epoch 6: train_loss: 1.5127 train_acc: 0.3395 | val_loss: 1.4874 val_acc: 0.3351\n",
            "Epoch 7: train_loss: 1.5080 train_acc: 0.3399 | val_loss: 1.5019 val_acc: 0.3297\n",
            "Epoch 8: train_loss: 1.5263 train_acc: 0.3188 | val_loss: 1.5379 val_acc: 0.2988\n",
            "Epoch 9: train_loss: 1.5641 train_acc: 0.2699 | val_loss: 1.5688 val_acc: 0.2852\n",
            "Epoch 10: train_loss: 1.5691 train_acc: 0.2647 | val_loss: 1.5683 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5684 train_acc: 0.2720 | val_loss: 1.5673 val_acc: 0.2852\n",
            "Epoch 12: train_loss: 1.5679 train_acc: 0.2712 | val_loss: 1.5665 val_acc: 0.2589\n",
            "Epoch 13: train_loss: 1.5687 train_acc: 0.2680 | val_loss: 1.5637 val_acc: 0.2552\n",
            "Epoch 14: train_loss: 1.5680 train_acc: 0.2707 | val_loss: 1.5602 val_acc: 0.2988\n",
            "Epoch 15: train_loss: 1.5676 train_acc: 0.2738 | val_loss: 1.5665 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5680 train_acc: 0.2718 | val_loss: 1.5619 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5679 train_acc: 0.2718 | val_loss: 1.5547 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5715 train_acc: 0.2743 | val_loss: 1.5756 val_acc: 0.2625\n",
            "Epoch 19: train_loss: 1.5695 train_acc: 0.2692 | val_loss: 1.5720 val_acc: 0.2625\n",
            "Epoch 20: train_loss: 1.5688 train_acc: 0.2697 | val_loss: 1.5715 val_acc: 0.2579\n",
            "Epoch 21: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5710 val_acc: 0.2589\n",
            "Epoch 22: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5713 val_acc: 0.2616\n",
            "Epoch 23: train_loss: 1.5679 train_acc: 0.2719 | val_loss: 1.5710 val_acc: 0.2579\n",
            "Epoch 24: train_loss: 1.5670 train_acc: 0.2718 | val_loss: 1.5575 val_acc: 0.2579\n",
            "Lowest val_loss: 1.4874, at epoch 6\n",
            "LSTM 70 2 [50]\n",
            "Epoch 0: train_loss: 1.5754 train_acc: 0.2664 | val_loss: 1.5738 val_acc: 0.2416\n",
            "Epoch 1: train_loss: 1.5703 train_acc: 0.2710 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5694 train_acc: 0.2646 | val_loss: 1.5736 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5683 train_acc: 0.2671 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5685 train_acc: 0.2717 | val_loss: 1.5679 val_acc: 0.2525\n",
            "Epoch 5: train_loss: 1.5684 train_acc: 0.2669 | val_loss: 1.5646 val_acc: 0.2525\n",
            "Epoch 6: train_loss: 1.5664 train_acc: 0.2781 | val_loss: 1.5641 val_acc: 0.2779\n",
            "Epoch 7: train_loss: 1.5545 train_acc: 0.3007 | val_loss: 1.5561 val_acc: 0.2888\n",
            "Epoch 8: train_loss: 1.5612 train_acc: 0.2877 | val_loss: 1.5552 val_acc: 0.2897\n",
            "Epoch 9: train_loss: 1.5503 train_acc: 0.2971 | val_loss: 1.5454 val_acc: 0.2961\n",
            "Epoch 10: train_loss: 1.5382 train_acc: 0.3165 | val_loss: 1.5338 val_acc: 0.3143\n",
            "Epoch 11: train_loss: 1.5607 train_acc: 0.2801 | val_loss: 1.5744 val_acc: 0.2589\n",
            "Epoch 12: train_loss: 1.5699 train_acc: 0.2700 | val_loss: 1.5749 val_acc: 0.2616\n",
            "Epoch 13: train_loss: 1.5689 train_acc: 0.2681 | val_loss: 1.5745 val_acc: 0.2525\n",
            "Epoch 14: train_loss: 1.5687 train_acc: 0.2678 | val_loss: 1.5754 val_acc: 0.2525\n",
            "Epoch 15: train_loss: 1.5688 train_acc: 0.2660 | val_loss: 1.5754 val_acc: 0.2525\n",
            "Epoch 16: train_loss: 1.5685 train_acc: 0.2714 | val_loss: 1.5753 val_acc: 0.2589\n",
            "Epoch 17: train_loss: 1.5684 train_acc: 0.2677 | val_loss: 1.5754 val_acc: 0.2525\n",
            "Epoch 18: train_loss: 1.5688 train_acc: 0.2698 | val_loss: 1.5759 val_acc: 0.2525\n",
            "Epoch 19: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2525\n",
            "Epoch 20: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2525\n",
            "Epoch 21: train_loss: 1.5687 train_acc: 0.2694 | val_loss: 1.5753 val_acc: 0.2525\n",
            "Epoch 22: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5743 val_acc: 0.2525\n",
            "Epoch 23: train_loss: 1.5683 train_acc: 0.2708 | val_loss: 1.5762 val_acc: 0.2525\n",
            "Epoch 24: train_loss: 1.5685 train_acc: 0.2695 | val_loss: 1.5751 val_acc: 0.2525\n",
            "Lowest val_loss: 1.5338, at epoch 10\n",
            "LSTM 70 2 [60]\n",
            "Epoch 0: train_loss: 1.5729 train_acc: 0.2623 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2659 | val_loss: 1.5728 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5684 train_acc: 0.2680 | val_loss: 1.5684 val_acc: 0.3233\n",
            "Epoch 3: train_loss: 1.5657 train_acc: 0.2760 | val_loss: 1.5432 val_acc: 0.3134\n",
            "Epoch 4: train_loss: 1.5618 train_acc: 0.2808 | val_loss: 1.5182 val_acc: 0.3288\n",
            "Epoch 5: train_loss: 1.5701 train_acc: 0.2695 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5688 train_acc: 0.2685 | val_loss: 1.5793 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5690 train_acc: 0.2686 | val_loss: 1.5728 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5687 train_acc: 0.2680 | val_loss: 1.5717 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5679 train_acc: 0.2725 | val_loss: 1.5687 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5682 train_acc: 0.2693 | val_loss: 1.5674 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5589 train_acc: 0.2913 | val_loss: 1.5138 val_acc: 0.3560\n",
            "Epoch 12: train_loss: 1.5631 train_acc: 0.2832 | val_loss: 1.5845 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5690 train_acc: 0.2674 | val_loss: 1.5739 val_acc: 0.2561\n",
            "Epoch 14: train_loss: 1.5682 train_acc: 0.2708 | val_loss: 1.5742 val_acc: 0.2561\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2708 | val_loss: 1.5782 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5679 train_acc: 0.2677 | val_loss: 1.5770 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5675 train_acc: 0.2712 | val_loss: 1.5826 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5678 train_acc: 0.2677 | val_loss: 1.6039 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5676 train_acc: 0.2681 | val_loss: 1.5583 val_acc: 0.2570\n",
            "Epoch 20: train_loss: 1.5623 train_acc: 0.2811 | val_loss: 1.5477 val_acc: 0.2861\n",
            "Epoch 21: train_loss: 1.5544 train_acc: 0.2829 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5629 train_acc: 0.2680 | val_loss: 1.5626 val_acc: 0.2616\n",
            "Epoch 23: train_loss: 1.5520 train_acc: 0.2777 | val_loss: 1.5720 val_acc: 0.2525\n",
            "Epoch 24: train_loss: 1.5566 train_acc: 0.2644 | val_loss: 1.5691 val_acc: 0.2561\n",
            "Lowest val_loss: 1.5138, at epoch 11\n",
            "LSTM 70 2 [70]\n",
            "Epoch 0: train_loss: 1.5739 train_acc: 0.2677 | val_loss: 1.5816 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5701 train_acc: 0.2711 | val_loss: 1.5743 val_acc: 0.2598\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2664 | val_loss: 1.5861 val_acc: 0.2634\n",
            "Epoch 3: train_loss: 1.5687 train_acc: 0.2710 | val_loss: 1.5645 val_acc: 0.3088\n",
            "Epoch 4: train_loss: 1.5562 train_acc: 0.2958 | val_loss: 1.5664 val_acc: 0.2897\n",
            "Epoch 5: train_loss: 1.5501 train_acc: 0.3008 | val_loss: 1.5587 val_acc: 0.3043\n",
            "Epoch 6: train_loss: 1.5504 train_acc: 0.3070 | val_loss: 1.5582 val_acc: 0.3079\n",
            "Epoch 7: train_loss: 1.5499 train_acc: 0.3075 | val_loss: 1.5578 val_acc: 0.3079\n",
            "Epoch 8: train_loss: 1.5501 train_acc: 0.3081 | val_loss: 1.5580 val_acc: 0.3079\n",
            "Epoch 9: train_loss: 1.5498 train_acc: 0.3078 | val_loss: 1.5592 val_acc: 0.3106\n",
            "Epoch 10: train_loss: 1.5479 train_acc: 0.3097 | val_loss: 1.5433 val_acc: 0.3206\n",
            "Epoch 11: train_loss: 1.5494 train_acc: 0.2932 | val_loss: 1.5625 val_acc: 0.2834\n",
            "Epoch 12: train_loss: 1.5538 train_acc: 0.2832 | val_loss: 1.5622 val_acc: 0.2834\n",
            "Epoch 13: train_loss: 1.5538 train_acc: 0.2822 | val_loss: 1.5694 val_acc: 0.2670\n",
            "Epoch 14: train_loss: 1.5642 train_acc: 0.2705 | val_loss: 1.5765 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5651 train_acc: 0.2684 | val_loss: 1.5736 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5646 train_acc: 0.2688 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5648 train_acc: 0.2708 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5643 train_acc: 0.2701 | val_loss: 1.5726 val_acc: 0.2525\n",
            "Epoch 19: train_loss: 1.5646 train_acc: 0.2660 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5647 train_acc: 0.2713 | val_loss: 1.5723 val_acc: 0.2988\n",
            "Epoch 21: train_loss: 1.5636 train_acc: 0.2717 | val_loss: 1.5736 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5645 train_acc: 0.2666 | val_loss: 1.5778 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5649 train_acc: 0.2726 | val_loss: 1.5743 val_acc: 0.3161\n",
            "Epoch 24: train_loss: 1.5646 train_acc: 0.2698 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5433, at epoch 10\n",
            "LSTM 80 1 [30]\n",
            "Epoch 0: train_loss: 1.5754 train_acc: 0.2550 | val_loss: 1.5768 val_acc: 0.2652\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2638 | val_loss: 1.5707 val_acc: 0.2561\n",
            "Epoch 2: train_loss: 1.5688 train_acc: 0.2685 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5691 train_acc: 0.2711 | val_loss: 1.5708 val_acc: 0.3270\n",
            "Epoch 4: train_loss: 1.5679 train_acc: 0.2738 | val_loss: 1.5676 val_acc: 0.2634\n",
            "Epoch 5: train_loss: 1.5673 train_acc: 0.2708 | val_loss: 1.5653 val_acc: 0.2561\n",
            "Epoch 6: train_loss: 1.5656 train_acc: 0.2726 | val_loss: 1.5566 val_acc: 0.2607\n",
            "Epoch 7: train_loss: 1.5654 train_acc: 0.2687 | val_loss: 1.5616 val_acc: 0.2698\n",
            "Epoch 8: train_loss: 1.5591 train_acc: 0.2788 | val_loss: 1.6298 val_acc: 0.2543\n",
            "Epoch 9: train_loss: 1.5528 train_acc: 0.2963 | val_loss: 1.5351 val_acc: 0.3143\n",
            "Epoch 10: train_loss: 1.5623 train_acc: 0.2774 | val_loss: 1.5686 val_acc: 0.2598\n",
            "Epoch 11: train_loss: 1.5621 train_acc: 0.2870 | val_loss: 1.6829 val_acc: 0.2589\n",
            "Epoch 12: train_loss: 1.5194 train_acc: 0.3353 | val_loss: 1.6269 val_acc: 0.2997\n",
            "Epoch 13: train_loss: 1.5538 train_acc: 0.2868 | val_loss: 1.5846 val_acc: 0.2761\n",
            "Epoch 14: train_loss: 1.4947 train_acc: 0.3439 | val_loss: 1.4613 val_acc: 0.3642\n",
            "Epoch 15: train_loss: 1.4087 train_acc: 0.3765 | val_loss: 1.4108 val_acc: 0.3951\n",
            "Epoch 16: train_loss: 1.3362 train_acc: 0.3982 | val_loss: 1.3584 val_acc: 0.4024\n",
            "Epoch 17: train_loss: 1.2928 train_acc: 0.4154 | val_loss: 1.3646 val_acc: 0.3969\n",
            "Epoch 18: train_loss: 1.2530 train_acc: 0.4315 | val_loss: 1.3505 val_acc: 0.4033\n",
            "Epoch 19: train_loss: 1.2217 train_acc: 0.4524 | val_loss: 1.3932 val_acc: 0.3906\n",
            "Epoch 20: train_loss: 1.1948 train_acc: 0.4641 | val_loss: 1.3578 val_acc: 0.4124\n",
            "Epoch 21: train_loss: 1.1723 train_acc: 0.4795 | val_loss: 1.3815 val_acc: 0.3969\n",
            "Epoch 22: train_loss: 1.1456 train_acc: 0.4911 | val_loss: 1.3903 val_acc: 0.4042\n",
            "Epoch 23: train_loss: 1.1168 train_acc: 0.5075 | val_loss: 1.3794 val_acc: 0.4169\n",
            "Epoch 24: train_loss: 1.0899 train_acc: 0.5210 | val_loss: 1.3788 val_acc: 0.3951\n",
            "Lowest val_loss: 1.3505, at epoch 18\n",
            "LSTM 80 1 [40]\n",
            "Epoch 0: train_loss: 1.5780 train_acc: 0.2496 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5701 train_acc: 0.2679 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5690 train_acc: 0.2692 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5686 train_acc: 0.2725 | val_loss: 1.5737 val_acc: 0.2688\n",
            "Epoch 4: train_loss: 1.5685 train_acc: 0.2640 | val_loss: 1.5720 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5686 train_acc: 0.2719 | val_loss: 1.5713 val_acc: 0.2525\n",
            "Epoch 6: train_loss: 1.5680 train_acc: 0.2720 | val_loss: 1.5713 val_acc: 0.2543\n",
            "Epoch 7: train_loss: 1.5672 train_acc: 0.2718 | val_loss: 1.5758 val_acc: 0.2698\n",
            "Epoch 8: train_loss: 1.5657 train_acc: 0.2749 | val_loss: 1.5488 val_acc: 0.2834\n",
            "Epoch 9: train_loss: 1.5647 train_acc: 0.2773 | val_loss: 1.5696 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5655 train_acc: 0.2743 | val_loss: 1.5708 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5673 train_acc: 0.2727 | val_loss: 1.5647 val_acc: 0.2752\n",
            "Epoch 12: train_loss: 1.5654 train_acc: 0.2704 | val_loss: 1.5659 val_acc: 0.2716\n",
            "Epoch 13: train_loss: 1.5556 train_acc: 0.2963 | val_loss: 1.5161 val_acc: 0.3379\n",
            "Epoch 14: train_loss: 1.5275 train_acc: 0.3361 | val_loss: 1.4868 val_acc: 0.3370\n",
            "Epoch 15: train_loss: 1.4195 train_acc: 0.3859 | val_loss: 1.4292 val_acc: 0.3479\n",
            "Epoch 16: train_loss: 1.3293 train_acc: 0.4072 | val_loss: 1.4286 val_acc: 0.3460\n",
            "Epoch 17: train_loss: 1.2740 train_acc: 0.4274 | val_loss: 1.3723 val_acc: 0.3760\n",
            "Epoch 18: train_loss: 1.2326 train_acc: 0.4394 | val_loss: 1.3697 val_acc: 0.3769\n",
            "Epoch 19: train_loss: 1.1992 train_acc: 0.4622 | val_loss: 1.3401 val_acc: 0.4005\n",
            "Epoch 20: train_loss: 1.1703 train_acc: 0.4827 | val_loss: 1.3940 val_acc: 0.3742\n",
            "Epoch 21: train_loss: 1.1404 train_acc: 0.4947 | val_loss: 1.3898 val_acc: 0.3715\n",
            "Epoch 22: train_loss: 1.0955 train_acc: 0.5119 | val_loss: 1.3872 val_acc: 0.4005\n",
            "Epoch 23: train_loss: 1.0664 train_acc: 0.5259 | val_loss: 1.3771 val_acc: 0.3933\n",
            "Epoch 24: train_loss: 1.0334 train_acc: 0.5544 | val_loss: 1.4060 val_acc: 0.3942\n",
            "Lowest val_loss: 1.3401, at epoch 19\n",
            "LSTM 80 1 [50]\n",
            "Epoch 0: train_loss: 1.5732 train_acc: 0.2710 | val_loss: 1.5726 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2713 | val_loss: 1.5705 val_acc: 0.2498\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2721 | val_loss: 1.5725 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5665 train_acc: 0.2663 | val_loss: 1.5682 val_acc: 0.2443\n",
            "Epoch 4: train_loss: 1.5642 train_acc: 0.2692 | val_loss: 1.5479 val_acc: 0.2761\n",
            "Epoch 5: train_loss: 1.5631 train_acc: 0.2699 | val_loss: 1.5593 val_acc: 0.3079\n",
            "Epoch 6: train_loss: 1.5578 train_acc: 0.2772 | val_loss: 1.5650 val_acc: 0.2843\n",
            "Epoch 7: train_loss: 1.5366 train_acc: 0.3092 | val_loss: 1.4847 val_acc: 0.3324\n",
            "Epoch 8: train_loss: 1.4402 train_acc: 0.3675 | val_loss: 1.4091 val_acc: 0.3724\n",
            "Epoch 9: train_loss: 1.3754 train_acc: 0.3961 | val_loss: 1.3761 val_acc: 0.3924\n",
            "Epoch 10: train_loss: 1.3271 train_acc: 0.4067 | val_loss: 1.3545 val_acc: 0.4060\n",
            "Epoch 11: train_loss: 1.2868 train_acc: 0.4175 | val_loss: 1.3908 val_acc: 0.3996\n",
            "Epoch 12: train_loss: 1.2553 train_acc: 0.4350 | val_loss: 1.3668 val_acc: 0.4124\n",
            "Epoch 13: train_loss: 1.2163 train_acc: 0.4551 | val_loss: 1.3989 val_acc: 0.4151\n",
            "Epoch 14: train_loss: 1.1871 train_acc: 0.4753 | val_loss: 1.3728 val_acc: 0.4260\n",
            "Epoch 15: train_loss: 1.1678 train_acc: 0.4828 | val_loss: 1.4119 val_acc: 0.4242\n",
            "Epoch 16: train_loss: 1.1405 train_acc: 0.4982 | val_loss: 1.3985 val_acc: 0.4360\n",
            "Epoch 17: train_loss: 1.1039 train_acc: 0.5139 | val_loss: 1.3921 val_acc: 0.4305\n",
            "Epoch 18: train_loss: 1.0742 train_acc: 0.5350 | val_loss: 1.3984 val_acc: 0.4351\n",
            "Epoch 19: train_loss: 1.0615 train_acc: 0.5425 | val_loss: 1.4455 val_acc: 0.4151\n",
            "Epoch 20: train_loss: 1.0063 train_acc: 0.5658 | val_loss: 1.4534 val_acc: 0.4142\n",
            "Epoch 21: train_loss: 0.9767 train_acc: 0.5873 | val_loss: 1.4394 val_acc: 0.4087\n",
            "Epoch 22: train_loss: 0.9313 train_acc: 0.6019 | val_loss: 1.5161 val_acc: 0.4033\n",
            "Epoch 23: train_loss: 0.8931 train_acc: 0.6224 | val_loss: 1.5263 val_acc: 0.4042\n",
            "Epoch 24: train_loss: 0.8617 train_acc: 0.6461 | val_loss: 1.5583 val_acc: 0.3978\n",
            "Lowest val_loss: 1.3545, at epoch 10\n",
            "LSTM 80 1 [60]\n",
            "Epoch 0: train_loss: 1.5728 train_acc: 0.2609 | val_loss: 1.5709 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2697 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5677 train_acc: 0.2705 | val_loss: 1.5640 val_acc: 0.2579\n",
            "Epoch 3: train_loss: 1.5673 train_acc: 0.2711 | val_loss: 1.5652 val_acc: 0.2970\n",
            "Epoch 4: train_loss: 1.5610 train_acc: 0.2803 | val_loss: 1.4871 val_acc: 0.3542\n",
            "Epoch 5: train_loss: 1.5475 train_acc: 0.3026 | val_loss: 1.5746 val_acc: 0.2416\n",
            "Epoch 6: train_loss: 1.5671 train_acc: 0.2690 | val_loss: 1.5746 val_acc: 0.2298\n",
            "Epoch 7: train_loss: 1.5648 train_acc: 0.2722 | val_loss: 1.5766 val_acc: 0.2398\n",
            "Epoch 8: train_loss: 1.5636 train_acc: 0.2676 | val_loss: 1.5602 val_acc: 0.2952\n",
            "Epoch 9: train_loss: 1.5598 train_acc: 0.2798 | val_loss: 1.5794 val_acc: 0.2425\n",
            "Epoch 10: train_loss: 1.5183 train_acc: 0.3097 | val_loss: 1.5325 val_acc: 0.2925\n",
            "Epoch 11: train_loss: 1.5031 train_acc: 0.3136 | val_loss: 1.5246 val_acc: 0.3034\n",
            "Epoch 12: train_loss: 1.5667 train_acc: 0.2787 | val_loss: 1.5608 val_acc: 0.2652\n",
            "Epoch 13: train_loss: 1.5401 train_acc: 0.3198 | val_loss: 1.5713 val_acc: 0.2643\n",
            "Epoch 14: train_loss: 1.5534 train_acc: 0.2849 | val_loss: 1.6018 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5668 train_acc: 0.2727 | val_loss: 1.5674 val_acc: 0.2480\n",
            "Epoch 16: train_loss: 1.5654 train_acc: 0.2734 | val_loss: 1.5745 val_acc: 0.2461\n",
            "Epoch 17: train_loss: 1.5651 train_acc: 0.2720 | val_loss: 1.5703 val_acc: 0.2489\n",
            "Epoch 18: train_loss: 1.5630 train_acc: 0.2734 | val_loss: 1.5814 val_acc: 0.2425\n",
            "Epoch 19: train_loss: 1.5625 train_acc: 0.2691 | val_loss: 1.5805 val_acc: 0.2579\n",
            "Epoch 20: train_loss: 1.5610 train_acc: 0.2742 | val_loss: 1.5803 val_acc: 0.2625\n",
            "Epoch 21: train_loss: 1.5602 train_acc: 0.2779 | val_loss: 1.5869 val_acc: 0.3243\n",
            "Epoch 22: train_loss: 1.5411 train_acc: 0.3002 | val_loss: 1.5865 val_acc: 0.3025\n",
            "Epoch 23: train_loss: 1.5616 train_acc: 0.2801 | val_loss: 1.6306 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5606 train_acc: 0.2687 | val_loss: 1.8306 val_acc: 0.2661\n",
            "Lowest val_loss: 1.4871, at epoch 4\n",
            "LSTM 80 1 [70]\n",
            "Epoch 0: train_loss: 1.5750 train_acc: 0.2599 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2626 | val_loss: 1.5712 val_acc: 0.2716\n",
            "Epoch 2: train_loss: 1.5684 train_acc: 0.2658 | val_loss: 1.5729 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5666 train_acc: 0.2720 | val_loss: 1.5596 val_acc: 0.2788\n",
            "Epoch 4: train_loss: 1.5655 train_acc: 0.2681 | val_loss: 1.5326 val_acc: 0.3170\n",
            "Epoch 5: train_loss: 1.5422 train_acc: 0.2937 | val_loss: 1.5037 val_acc: 0.3270\n",
            "Epoch 6: train_loss: 1.5543 train_acc: 0.2738 | val_loss: 1.5605 val_acc: 0.3043\n",
            "Epoch 7: train_loss: 1.5497 train_acc: 0.2711 | val_loss: 1.5325 val_acc: 0.3324\n",
            "Epoch 8: train_loss: 1.5412 train_acc: 0.2925 | val_loss: 1.5480 val_acc: 0.3070\n",
            "Epoch 9: train_loss: 1.5434 train_acc: 0.2884 | val_loss: 1.5500 val_acc: 0.3088\n",
            "Epoch 10: train_loss: 1.5407 train_acc: 0.2906 | val_loss: 1.5634 val_acc: 0.3079\n",
            "Epoch 11: train_loss: 1.5394 train_acc: 0.2911 | val_loss: 1.5386 val_acc: 0.3361\n",
            "Epoch 12: train_loss: 1.5361 train_acc: 0.3015 | val_loss: 1.4990 val_acc: 0.3297\n",
            "Epoch 13: train_loss: 1.5178 train_acc: 0.3265 | val_loss: 1.4861 val_acc: 0.3588\n",
            "Epoch 14: train_loss: 1.5383 train_acc: 0.2953 | val_loss: 1.5709 val_acc: 0.2434\n",
            "Epoch 15: train_loss: 1.5423 train_acc: 0.2766 | val_loss: 1.5709 val_acc: 0.3015\n",
            "Epoch 16: train_loss: 1.5384 train_acc: 0.2891 | val_loss: 1.5468 val_acc: 0.3070\n",
            "Epoch 17: train_loss: 1.4882 train_acc: 0.3446 | val_loss: 1.4870 val_acc: 0.3479\n",
            "Epoch 18: train_loss: 1.5561 train_acc: 0.2768 | val_loss: 1.6342 val_acc: 0.2570\n",
            "Epoch 19: train_loss: 1.5569 train_acc: 0.2714 | val_loss: 1.6217 val_acc: 0.2797\n",
            "Epoch 20: train_loss: 1.5541 train_acc: 0.2790 | val_loss: 1.6315 val_acc: 0.2843\n",
            "Epoch 21: train_loss: 1.5487 train_acc: 0.2794 | val_loss: 1.7052 val_acc: 0.3043\n",
            "Epoch 22: train_loss: 1.5370 train_acc: 0.2920 | val_loss: 1.5822 val_acc: 0.3243\n",
            "Epoch 23: train_loss: 1.4823 train_acc: 0.3386 | val_loss: 1.4810 val_acc: 0.3397\n",
            "Epoch 24: train_loss: 1.4377 train_acc: 0.3770 | val_loss: 1.4309 val_acc: 0.3851\n",
            "Lowest val_loss: 1.4309, at epoch 24\n",
            "LSTM 80 2 [30]\n",
            "Epoch 0: train_loss: 1.5748 train_acc: 0.2590 | val_loss: 1.5778 val_acc: 0.2561\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2670 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5688 train_acc: 0.2759 | val_loss: 1.5770 val_acc: 0.2625\n",
            "Epoch 3: train_loss: 1.5691 train_acc: 0.2688 | val_loss: 1.5691 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5685 train_acc: 0.2660 | val_loss: 1.5676 val_acc: 0.2516\n",
            "Epoch 5: train_loss: 1.5672 train_acc: 0.2701 | val_loss: 1.5612 val_acc: 0.2552\n",
            "Epoch 6: train_loss: 1.5648 train_acc: 0.2688 | val_loss: 1.5742 val_acc: 0.2570\n",
            "Epoch 7: train_loss: 1.5676 train_acc: 0.2729 | val_loss: 1.5769 val_acc: 0.2525\n",
            "Epoch 8: train_loss: 1.5684 train_acc: 0.2671 | val_loss: 1.5783 val_acc: 0.2525\n",
            "Epoch 9: train_loss: 1.5688 train_acc: 0.2704 | val_loss: 1.5770 val_acc: 0.2516\n",
            "Epoch 10: train_loss: 1.5682 train_acc: 0.2708 | val_loss: 1.5753 val_acc: 0.2516\n",
            "Epoch 11: train_loss: 1.5681 train_acc: 0.2688 | val_loss: 1.5760 val_acc: 0.2525\n",
            "Epoch 12: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5750 val_acc: 0.2661\n",
            "Epoch 13: train_loss: 1.5689 train_acc: 0.2614 | val_loss: 1.5747 val_acc: 0.2925\n",
            "Epoch 14: train_loss: 1.5681 train_acc: 0.2685 | val_loss: 1.5739 val_acc: 0.2525\n",
            "Epoch 15: train_loss: 1.5666 train_acc: 0.2669 | val_loss: 1.5763 val_acc: 0.2516\n",
            "Epoch 16: train_loss: 1.5677 train_acc: 0.2671 | val_loss: 1.5748 val_acc: 0.2525\n",
            "Epoch 17: train_loss: 1.5673 train_acc: 0.2684 | val_loss: 1.5738 val_acc: 0.2525\n",
            "Epoch 18: train_loss: 1.5678 train_acc: 0.2721 | val_loss: 1.5742 val_acc: 0.2525\n",
            "Epoch 19: train_loss: 1.5669 train_acc: 0.2705 | val_loss: 1.5744 val_acc: 0.2525\n",
            "Epoch 20: train_loss: 1.5671 train_acc: 0.2725 | val_loss: 1.5746 val_acc: 0.2525\n",
            "Epoch 21: train_loss: 1.5680 train_acc: 0.2707 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5688 train_acc: 0.2671 | val_loss: 1.5765 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5692 train_acc: 0.2684 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5688 train_acc: 0.2643 | val_loss: 1.5741 val_acc: 0.2525\n",
            "Lowest val_loss: 1.5612, at epoch 5\n",
            "LSTM 80 2 [40]\n",
            "Epoch 0: train_loss: 1.5730 train_acc: 0.2590 | val_loss: 1.5827 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2706 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5695 train_acc: 0.2650 | val_loss: 1.5725 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5694 train_acc: 0.2718 | val_loss: 1.5702 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5681 train_acc: 0.2732 | val_loss: 1.5487 val_acc: 0.3424\n",
            "Epoch 5: train_loss: 1.5692 train_acc: 0.2811 | val_loss: 1.5721 val_acc: 0.2543\n",
            "Epoch 6: train_loss: 1.5685 train_acc: 0.2694 | val_loss: 1.5676 val_acc: 0.2688\n",
            "Epoch 7: train_loss: 1.5671 train_acc: 0.2721 | val_loss: 1.5571 val_acc: 0.3224\n",
            "Epoch 8: train_loss: 1.5626 train_acc: 0.2739 | val_loss: 1.5628 val_acc: 0.3297\n",
            "Epoch 9: train_loss: 1.5651 train_acc: 0.2769 | val_loss: 1.5790 val_acc: 0.2543\n",
            "Epoch 10: train_loss: 1.5353 train_acc: 0.3250 | val_loss: 1.4853 val_acc: 0.3442\n",
            "Epoch 11: train_loss: 1.5050 train_acc: 0.3454 | val_loss: 1.4984 val_acc: 0.3406\n",
            "Epoch 12: train_loss: 1.4998 train_acc: 0.3317 | val_loss: 1.5730 val_acc: 0.2407\n",
            "Epoch 13: train_loss: 1.5547 train_acc: 0.2693 | val_loss: 1.5780 val_acc: 0.2489\n",
            "Epoch 14: train_loss: 1.5417 train_acc: 0.3037 | val_loss: 1.5026 val_acc: 0.3370\n",
            "Epoch 15: train_loss: 1.5181 train_acc: 0.3230 | val_loss: 1.5340 val_acc: 0.3079\n",
            "Epoch 16: train_loss: 1.5147 train_acc: 0.3313 | val_loss: 1.4602 val_acc: 0.3361\n",
            "Epoch 17: train_loss: 1.4903 train_acc: 0.3419 | val_loss: 1.5369 val_acc: 0.3043\n",
            "Epoch 18: train_loss: 1.5210 train_acc: 0.3126 | val_loss: 1.5371 val_acc: 0.3015\n",
            "Epoch 19: train_loss: 1.4799 train_acc: 0.3387 | val_loss: 1.4515 val_acc: 0.3388\n",
            "Epoch 20: train_loss: 1.4482 train_acc: 0.3654 | val_loss: 1.4517 val_acc: 0.3506\n",
            "Epoch 21: train_loss: 1.4256 train_acc: 0.3683 | val_loss: 1.4218 val_acc: 0.3560\n",
            "Epoch 22: train_loss: 1.4209 train_acc: 0.3677 | val_loss: 1.4114 val_acc: 0.3660\n",
            "Epoch 23: train_loss: 1.4149 train_acc: 0.3738 | val_loss: 1.3967 val_acc: 0.3588\n",
            "Epoch 24: train_loss: 1.3744 train_acc: 0.3866 | val_loss: 1.3818 val_acc: 0.3724\n",
            "Lowest val_loss: 1.3818, at epoch 24\n",
            "LSTM 80 2 [50]\n",
            "Epoch 0: train_loss: 1.5719 train_acc: 0.2681 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2702 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5682 train_acc: 0.2712 | val_loss: 1.5700 val_acc: 0.2516\n",
            "Epoch 3: train_loss: 1.5589 train_acc: 0.2822 | val_loss: 1.5841 val_acc: 0.2916\n",
            "Epoch 4: train_loss: 1.5703 train_acc: 0.2646 | val_loss: 1.5725 val_acc: 0.2725\n",
            "Epoch 5: train_loss: 1.5691 train_acc: 0.2697 | val_loss: 1.5726 val_acc: 0.2625\n",
            "Epoch 6: train_loss: 1.5687 train_acc: 0.2736 | val_loss: 1.5729 val_acc: 0.2652\n",
            "Epoch 7: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5737 val_acc: 0.2634\n",
            "Epoch 8: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5731 val_acc: 0.2634\n",
            "Epoch 9: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5731 val_acc: 0.2643\n",
            "Epoch 10: train_loss: 1.5683 train_acc: 0.2733 | val_loss: 1.5729 val_acc: 0.2625\n",
            "Epoch 11: train_loss: 1.5688 train_acc: 0.2721 | val_loss: 1.5784 val_acc: 0.2625\n",
            "Epoch 12: train_loss: 1.5692 train_acc: 0.2688 | val_loss: 1.5725 val_acc: 0.2643\n",
            "Epoch 13: train_loss: 1.5687 train_acc: 0.2658 | val_loss: 1.5727 val_acc: 0.2698\n",
            "Epoch 14: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5728 val_acc: 0.2661\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2617 | val_loss: 1.5727 val_acc: 0.2679\n",
            "Epoch 16: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5747 val_acc: 0.2643\n",
            "Epoch 17: train_loss: 1.5686 train_acc: 0.2672 | val_loss: 1.5734 val_acc: 0.2634\n",
            "Epoch 18: train_loss: 1.5690 train_acc: 0.2685 | val_loss: 1.5733 val_acc: 0.2607\n",
            "Epoch 19: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5731 val_acc: 0.2643\n",
            "Epoch 20: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5734 val_acc: 0.2625\n",
            "Epoch 21: train_loss: 1.5682 train_acc: 0.2664 | val_loss: 1.5726 val_acc: 0.2625\n",
            "Epoch 22: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5731 val_acc: 0.2643\n",
            "Epoch 23: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5732 val_acc: 0.2625\n",
            "Epoch 24: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5727 val_acc: 0.2643\n",
            "Lowest val_loss: 1.5700, at epoch 2\n",
            "LSTM 80 2 [60]\n",
            "Epoch 0: train_loss: 1.5723 train_acc: 0.2694 | val_loss: 1.5767 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2647 | val_loss: 1.5773 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2718 | val_loss: 1.5703 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5592 train_acc: 0.2949 | val_loss: 1.5104 val_acc: 0.3479\n",
            "Epoch 4: train_loss: 1.5202 train_acc: 0.3384 | val_loss: 1.5716 val_acc: 0.2625\n",
            "Epoch 5: train_loss: 1.5136 train_acc: 0.3420 | val_loss: 1.4873 val_acc: 0.3397\n",
            "Epoch 6: train_loss: 1.5390 train_acc: 0.2917 | val_loss: 1.5391 val_acc: 0.2925\n",
            "Epoch 7: train_loss: 1.5351 train_acc: 0.2859 | val_loss: 1.5573 val_acc: 0.2625\n",
            "Epoch 8: train_loss: 1.5356 train_acc: 0.2820 | val_loss: 1.5544 val_acc: 0.2570\n",
            "Epoch 9: train_loss: 1.5352 train_acc: 0.2827 | val_loss: 1.5524 val_acc: 0.2643\n",
            "Epoch 10: train_loss: 1.5444 train_acc: 0.2822 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5683 train_acc: 0.2693 | val_loss: 1.5883 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5684 train_acc: 0.2715 | val_loss: 1.5762 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5683 train_acc: 0.2692 | val_loss: 1.5776 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5788 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5682 train_acc: 0.2686 | val_loss: 1.5808 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5680 train_acc: 0.2708 | val_loss: 1.5952 val_acc: 0.2716\n",
            "Epoch 20: train_loss: 1.5685 train_acc: 0.2719 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5681 train_acc: 0.2724 | val_loss: 1.5739 val_acc: 0.2661\n",
            "Epoch 22: train_loss: 1.5681 train_acc: 0.2710 | val_loss: 1.5759 val_acc: 0.2716\n",
            "Epoch 23: train_loss: 1.5677 train_acc: 0.2719 | val_loss: 1.5731 val_acc: 0.2734\n",
            "Epoch 24: train_loss: 1.5676 train_acc: 0.2727 | val_loss: 1.5725 val_acc: 0.2625\n",
            "Lowest val_loss: 1.4873, at epoch 5\n",
            "LSTM 80 2 [70]\n",
            "Epoch 0: train_loss: 1.5733 train_acc: 0.2702 | val_loss: 1.5820 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2694 | val_loss: 1.5768 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5696 train_acc: 0.2694 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5539 train_acc: 0.2886 | val_loss: 1.5526 val_acc: 0.2843\n",
            "Epoch 4: train_loss: 1.5299 train_acc: 0.2876 | val_loss: 1.5337 val_acc: 0.2752\n",
            "Epoch 5: train_loss: 1.5165 train_acc: 0.3082 | val_loss: 1.5479 val_acc: 0.2616\n",
            "Epoch 6: train_loss: 1.5147 train_acc: 0.3009 | val_loss: 1.5306 val_acc: 0.2734\n",
            "Epoch 7: train_loss: 1.4768 train_acc: 0.3484 | val_loss: 1.4875 val_acc: 0.3379\n",
            "Epoch 8: train_loss: 1.5469 train_acc: 0.2969 | val_loss: 1.5503 val_acc: 0.2934\n",
            "Epoch 9: train_loss: 1.5429 train_acc: 0.3072 | val_loss: 1.5464 val_acc: 0.2934\n",
            "Epoch 10: train_loss: 1.5442 train_acc: 0.3063 | val_loss: 1.5465 val_acc: 0.2925\n",
            "Epoch 11: train_loss: 1.5434 train_acc: 0.3072 | val_loss: 1.5449 val_acc: 0.2943\n",
            "Epoch 12: train_loss: 1.5419 train_acc: 0.3092 | val_loss: 1.5435 val_acc: 0.2961\n",
            "Epoch 13: train_loss: 1.5454 train_acc: 0.3031 | val_loss: 1.5477 val_acc: 0.2879\n",
            "Epoch 14: train_loss: 1.5459 train_acc: 0.3042 | val_loss: 1.5453 val_acc: 0.2934\n",
            "Epoch 15: train_loss: 1.5433 train_acc: 0.3075 | val_loss: 1.5437 val_acc: 0.2943\n",
            "Epoch 16: train_loss: 1.5434 train_acc: 0.3068 | val_loss: 1.5472 val_acc: 0.2888\n",
            "Epoch 17: train_loss: 1.5427 train_acc: 0.3070 | val_loss: 1.5429 val_acc: 0.2952\n",
            "Epoch 18: train_loss: 1.5295 train_acc: 0.3201 | val_loss: 1.5249 val_acc: 0.2861\n",
            "Epoch 19: train_loss: 1.5013 train_acc: 0.3167 | val_loss: 1.5199 val_acc: 0.3088\n",
            "Epoch 20: train_loss: 1.5109 train_acc: 0.3072 | val_loss: 1.5550 val_acc: 0.2879\n",
            "Epoch 21: train_loss: 1.5391 train_acc: 0.2842 | val_loss: 1.5565 val_acc: 0.3224\n",
            "Epoch 22: train_loss: 1.5388 train_acc: 0.2848 | val_loss: 1.5541 val_acc: 0.2761\n",
            "Epoch 23: train_loss: 1.5395 train_acc: 0.2760 | val_loss: 1.5547 val_acc: 0.2634\n",
            "Epoch 24: train_loss: 1.5388 train_acc: 0.2796 | val_loss: 1.5556 val_acc: 0.3088\n",
            "Lowest val_loss: 1.4875, at epoch 7\n",
            "LSTM 100 1 [30]\n",
            "Epoch 0: train_loss: 1.5738 train_acc: 0.2601 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2679 | val_loss: 1.5727 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2717 | val_loss: 1.5718 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5675 train_acc: 0.2706 | val_loss: 1.5728 val_acc: 0.2779\n",
            "Epoch 4: train_loss: 1.5669 train_acc: 0.2642 | val_loss: 1.5643 val_acc: 0.2579\n",
            "Epoch 5: train_loss: 1.5430 train_acc: 0.2966 | val_loss: 1.4916 val_acc: 0.3361\n",
            "Epoch 6: train_loss: 1.5678 train_acc: 0.2691 | val_loss: 1.5728 val_acc: 0.2570\n",
            "Epoch 7: train_loss: 1.5686 train_acc: 0.2683 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5679 train_acc: 0.2722 | val_loss: 1.5724 val_acc: 0.2380\n",
            "Epoch 9: train_loss: 1.5681 train_acc: 0.2687 | val_loss: 1.5718 val_acc: 0.2434\n",
            "Epoch 10: train_loss: 1.5677 train_acc: 0.2710 | val_loss: 1.5716 val_acc: 0.2543\n",
            "Epoch 11: train_loss: 1.5667 train_acc: 0.2726 | val_loss: 1.5903 val_acc: 0.2525\n",
            "Epoch 12: train_loss: 1.5648 train_acc: 0.2824 | val_loss: 1.5720 val_acc: 0.2461\n",
            "Epoch 13: train_loss: 1.5647 train_acc: 0.2714 | val_loss: 1.5711 val_acc: 0.2425\n",
            "Epoch 14: train_loss: 1.5516 train_acc: 0.3078 | val_loss: 1.5532 val_acc: 0.2961\n",
            "Epoch 15: train_loss: 1.5445 train_acc: 0.3129 | val_loss: 1.5802 val_acc: 0.2925\n",
            "Epoch 16: train_loss: 1.5445 train_acc: 0.3077 | val_loss: 1.5553 val_acc: 0.2888\n",
            "Epoch 17: train_loss: 1.5371 train_acc: 0.3026 | val_loss: 1.5660 val_acc: 0.3061\n",
            "Epoch 18: train_loss: 1.5335 train_acc: 0.3047 | val_loss: 1.5329 val_acc: 0.3342\n",
            "Epoch 19: train_loss: 1.5259 train_acc: 0.3235 | val_loss: 1.4985 val_acc: 0.3460\n",
            "Epoch 20: train_loss: 1.4884 train_acc: 0.3556 | val_loss: 1.4469 val_acc: 0.3579\n",
            "Epoch 21: train_loss: 1.3747 train_acc: 0.3883 | val_loss: 1.4030 val_acc: 0.3760\n",
            "Epoch 22: train_loss: 1.2899 train_acc: 0.4276 | val_loss: 1.3546 val_acc: 0.3951\n",
            "Epoch 23: train_loss: 1.2486 train_acc: 0.4418 | val_loss: 1.3291 val_acc: 0.4015\n",
            "Epoch 24: train_loss: 1.2131 train_acc: 0.4606 | val_loss: 1.3518 val_acc: 0.4051\n",
            "Lowest val_loss: 1.3291, at epoch 23\n",
            "LSTM 100 1 [40]\n",
            "Epoch 0: train_loss: 1.5782 train_acc: 0.2540 | val_loss: 1.5751 val_acc: 0.2943\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2654 | val_loss: 1.5719 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5682 train_acc: 0.2748 | val_loss: 1.5794 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5697 train_acc: 0.2677 | val_loss: 1.5714 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5685 train_acc: 0.2679 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5665 train_acc: 0.2639 | val_loss: 1.5649 val_acc: 0.2589\n",
            "Epoch 6: train_loss: 1.5667 train_acc: 0.2711 | val_loss: 1.5514 val_acc: 0.3088\n",
            "Epoch 7: train_loss: 1.5623 train_acc: 0.2836 | val_loss: 1.5528 val_acc: 0.2970\n",
            "Epoch 8: train_loss: 1.5645 train_acc: 0.2720 | val_loss: 1.5544 val_acc: 0.2743\n",
            "Epoch 9: train_loss: 1.5488 train_acc: 0.2973 | val_loss: 1.5911 val_acc: 0.2897\n",
            "Epoch 10: train_loss: 1.3948 train_acc: 0.3876 | val_loss: 1.4787 val_acc: 0.3479\n",
            "Epoch 11: train_loss: 1.3177 train_acc: 0.4161 | val_loss: 1.4578 val_acc: 0.3597\n",
            "Epoch 12: train_loss: 1.2659 train_acc: 0.4387 | val_loss: 1.3775 val_acc: 0.3842\n",
            "Epoch 13: train_loss: 1.2325 train_acc: 0.4466 | val_loss: 1.3732 val_acc: 0.3860\n",
            "Epoch 14: train_loss: 1.2130 train_acc: 0.4568 | val_loss: 1.4075 val_acc: 0.3933\n",
            "Epoch 15: train_loss: 1.1782 train_acc: 0.4691 | val_loss: 1.3937 val_acc: 0.3915\n",
            "Epoch 16: train_loss: 1.1597 train_acc: 0.4837 | val_loss: 1.4432 val_acc: 0.3869\n",
            "Epoch 17: train_loss: 1.1335 train_acc: 0.4943 | val_loss: 1.4567 val_acc: 0.3769\n",
            "Epoch 18: train_loss: 1.1023 train_acc: 0.5119 | val_loss: 1.4756 val_acc: 0.3960\n",
            "Epoch 19: train_loss: 1.0711 train_acc: 0.5262 | val_loss: 1.5086 val_acc: 0.3896\n",
            "Epoch 20: train_loss: 1.0356 train_acc: 0.5489 | val_loss: 1.4969 val_acc: 0.3933\n",
            "Epoch 21: train_loss: 0.9983 train_acc: 0.5611 | val_loss: 1.6198 val_acc: 0.3942\n",
            "Epoch 22: train_loss: 0.9648 train_acc: 0.5827 | val_loss: 1.5452 val_acc: 0.3869\n",
            "Epoch 23: train_loss: 0.9296 train_acc: 0.6026 | val_loss: 1.5762 val_acc: 0.3996\n",
            "Epoch 24: train_loss: 0.8822 train_acc: 0.6254 | val_loss: 1.6221 val_acc: 0.3833\n",
            "Lowest val_loss: 1.3732, at epoch 13\n",
            "LSTM 100 1 [50]\n",
            "Epoch 0: train_loss: 1.5719 train_acc: 0.2698 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2710 | val_loss: 1.5722 val_acc: 0.2570\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2719 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5667 train_acc: 0.2672 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5643 train_acc: 0.2720 | val_loss: 1.5770 val_acc: 0.2425\n",
            "Epoch 5: train_loss: 1.5661 train_acc: 0.2705 | val_loss: 1.5714 val_acc: 0.2480\n",
            "Epoch 6: train_loss: 1.5639 train_acc: 0.2692 | val_loss: 1.5793 val_acc: 0.2643\n",
            "Epoch 7: train_loss: 1.5547 train_acc: 0.2988 | val_loss: 1.5736 val_acc: 0.2625\n",
            "Epoch 8: train_loss: 1.5697 train_acc: 0.2659 | val_loss: 1.5734 val_acc: 0.2707\n",
            "Epoch 9: train_loss: 1.5688 train_acc: 0.2705 | val_loss: 1.5739 val_acc: 0.2616\n",
            "Epoch 10: train_loss: 1.5691 train_acc: 0.2688 | val_loss: 1.5702 val_acc: 0.2516\n",
            "Epoch 11: train_loss: 1.5677 train_acc: 0.2690 | val_loss: 1.5736 val_acc: 0.2616\n",
            "Epoch 12: train_loss: 1.5674 train_acc: 0.2665 | val_loss: 1.5694 val_acc: 0.2598\n",
            "Epoch 13: train_loss: 1.5657 train_acc: 0.2691 | val_loss: 1.5762 val_acc: 0.2579\n",
            "Epoch 14: train_loss: 1.5642 train_acc: 0.2697 | val_loss: 1.5755 val_acc: 0.2779\n",
            "Epoch 15: train_loss: 1.5634 train_acc: 0.2728 | val_loss: 1.5987 val_acc: 0.2661\n",
            "Epoch 16: train_loss: 1.5616 train_acc: 0.2765 | val_loss: 1.5729 val_acc: 0.2489\n",
            "Epoch 17: train_loss: 1.5599 train_acc: 0.2800 | val_loss: 1.5832 val_acc: 0.2298\n",
            "Epoch 18: train_loss: 1.5610 train_acc: 0.2742 | val_loss: 1.5825 val_acc: 0.2398\n",
            "Epoch 19: train_loss: 1.5597 train_acc: 0.2713 | val_loss: 1.5936 val_acc: 0.2698\n",
            "Epoch 20: train_loss: 1.5576 train_acc: 0.2752 | val_loss: 1.5967 val_acc: 0.2916\n",
            "Epoch 21: train_loss: 1.5609 train_acc: 0.2750 | val_loss: 1.5784 val_acc: 0.2525\n",
            "Epoch 22: train_loss: 1.5629 train_acc: 0.2732 | val_loss: 1.5819 val_acc: 0.2852\n",
            "Epoch 23: train_loss: 1.5593 train_acc: 0.2747 | val_loss: 1.6064 val_acc: 0.2716\n",
            "Epoch 24: train_loss: 1.5528 train_acc: 0.2754 | val_loss: 1.7441 val_acc: 0.2698\n",
            "Lowest val_loss: 1.5694, at epoch 12\n",
            "LSTM 100 1 [60]\n",
            "Epoch 0: train_loss: 1.5747 train_acc: 0.2666 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2693 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5680 train_acc: 0.2616 | val_loss: 1.5689 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5671 train_acc: 0.2720 | val_loss: 1.5658 val_acc: 0.2507\n",
            "Epoch 4: train_loss: 1.5655 train_acc: 0.2695 | val_loss: 1.5481 val_acc: 0.2598\n",
            "Epoch 5: train_loss: 1.5645 train_acc: 0.2725 | val_loss: 1.5788 val_acc: 0.2652\n",
            "Epoch 6: train_loss: 1.5600 train_acc: 0.2753 | val_loss: 1.5682 val_acc: 0.2443\n",
            "Epoch 7: train_loss: 1.4765 train_acc: 0.3496 | val_loss: 1.4283 val_acc: 0.3688\n",
            "Epoch 8: train_loss: 1.4057 train_acc: 0.3853 | val_loss: 1.3884 val_acc: 0.3906\n",
            "Epoch 9: train_loss: 1.3600 train_acc: 0.4026 | val_loss: 1.3565 val_acc: 0.3906\n",
            "Epoch 10: train_loss: 1.3069 train_acc: 0.4175 | val_loss: 1.3571 val_acc: 0.4087\n",
            "Epoch 11: train_loss: 1.2803 train_acc: 0.4176 | val_loss: 1.3657 val_acc: 0.4124\n",
            "Epoch 12: train_loss: 1.2382 train_acc: 0.4424 | val_loss: 1.3454 val_acc: 0.4242\n",
            "Epoch 13: train_loss: 1.2145 train_acc: 0.4520 | val_loss: 1.3753 val_acc: 0.4214\n",
            "Epoch 14: train_loss: 1.1772 train_acc: 0.4809 | val_loss: 1.3526 val_acc: 0.4223\n",
            "Epoch 15: train_loss: 1.1616 train_acc: 0.4877 | val_loss: 1.3745 val_acc: 0.4251\n",
            "Epoch 16: train_loss: 1.1252 train_acc: 0.5138 | val_loss: 1.3934 val_acc: 0.4233\n",
            "Epoch 17: train_loss: 1.1051 train_acc: 0.5221 | val_loss: 1.4034 val_acc: 0.4114\n",
            "Epoch 18: train_loss: 1.0688 train_acc: 0.5434 | val_loss: 1.4056 val_acc: 0.4133\n",
            "Epoch 19: train_loss: 1.0335 train_acc: 0.5654 | val_loss: 1.4605 val_acc: 0.4051\n",
            "Epoch 20: train_loss: 1.0050 train_acc: 0.5826 | val_loss: 1.4421 val_acc: 0.4205\n",
            "Epoch 21: train_loss: 0.9740 train_acc: 0.5974 | val_loss: 1.4522 val_acc: 0.4051\n",
            "Epoch 22: train_loss: 0.9360 train_acc: 0.6194 | val_loss: 1.4967 val_acc: 0.4178\n",
            "Epoch 23: train_loss: 0.9009 train_acc: 0.6373 | val_loss: 1.5443 val_acc: 0.4124\n",
            "Epoch 24: train_loss: 0.8709 train_acc: 0.6561 | val_loss: 1.5303 val_acc: 0.4124\n",
            "Lowest val_loss: 1.3454, at epoch 12\n",
            "LSTM 100 1 [70]\n",
            "Epoch 0: train_loss: 1.5729 train_acc: 0.2695 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5686 train_acc: 0.2681 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5673 train_acc: 0.2684 | val_loss: 1.5843 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5670 train_acc: 0.2704 | val_loss: 1.5879 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5661 train_acc: 0.2672 | val_loss: 1.5553 val_acc: 0.2679\n",
            "Epoch 5: train_loss: 1.5506 train_acc: 0.3048 | val_loss: 1.5681 val_acc: 0.2561\n",
            "Epoch 6: train_loss: 1.5653 train_acc: 0.2731 | val_loss: 1.5749 val_acc: 0.2425\n",
            "Epoch 7: train_loss: 1.5531 train_acc: 0.3070 | val_loss: 1.5716 val_acc: 0.2897\n",
            "Epoch 8: train_loss: 1.5377 train_acc: 0.3070 | val_loss: 1.5503 val_acc: 0.2652\n",
            "Epoch 9: train_loss: 1.5654 train_acc: 0.2823 | val_loss: 1.5471 val_acc: 0.3152\n",
            "Epoch 10: train_loss: 1.5201 train_acc: 0.3261 | val_loss: 1.4884 val_acc: 0.3379\n",
            "Epoch 11: train_loss: 1.5219 train_acc: 0.3118 | val_loss: 1.5454 val_acc: 0.2634\n",
            "Epoch 12: train_loss: 1.4908 train_acc: 0.3523 | val_loss: 1.4692 val_acc: 0.3451\n",
            "Epoch 13: train_loss: 1.4810 train_acc: 0.3514 | val_loss: 1.4904 val_acc: 0.3442\n",
            "Epoch 14: train_loss: 1.4863 train_acc: 0.3511 | val_loss: 1.4813 val_acc: 0.3442\n",
            "Epoch 15: train_loss: 1.5234 train_acc: 0.3030 | val_loss: 1.5578 val_acc: 0.2589\n",
            "Epoch 16: train_loss: 1.5254 train_acc: 0.3054 | val_loss: 1.5704 val_acc: 0.2489\n",
            "Epoch 17: train_loss: 1.5501 train_acc: 0.2810 | val_loss: 1.5588 val_acc: 0.3106\n",
            "Epoch 18: train_loss: 1.5331 train_acc: 0.2928 | val_loss: 1.5330 val_acc: 0.3206\n",
            "Epoch 19: train_loss: 1.5459 train_acc: 0.2844 | val_loss: 1.5451 val_acc: 0.3097\n",
            "Epoch 20: train_loss: 1.5389 train_acc: 0.2844 | val_loss: 1.5609 val_acc: 0.2961\n",
            "Epoch 21: train_loss: 1.5316 train_acc: 0.3078 | val_loss: 1.5389 val_acc: 0.3097\n",
            "Epoch 22: train_loss: 1.5123 train_acc: 0.3309 | val_loss: 1.5361 val_acc: 0.3243\n",
            "Epoch 23: train_loss: 1.5061 train_acc: 0.3419 | val_loss: 1.5354 val_acc: 0.3197\n",
            "Epoch 24: train_loss: 1.5071 train_acc: 0.3434 | val_loss: 1.5211 val_acc: 0.3243\n",
            "Lowest val_loss: 1.4692, at epoch 12\n",
            "LSTM 100 2 [30]\n",
            "Epoch 0: train_loss: 1.5739 train_acc: 0.2585 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2673 | val_loss: 1.5792 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2698 | val_loss: 1.5730 val_acc: 0.2707\n",
            "Epoch 3: train_loss: 1.5686 train_acc: 0.2719 | val_loss: 1.5646 val_acc: 0.2906\n",
            "Epoch 4: train_loss: 1.5677 train_acc: 0.2753 | val_loss: 1.5744 val_acc: 0.2607\n",
            "Epoch 5: train_loss: 1.5693 train_acc: 0.2631 | val_loss: 1.5765 val_acc: 0.2543\n",
            "Epoch 6: train_loss: 1.5694 train_acc: 0.2695 | val_loss: 1.5772 val_acc: 0.2543\n",
            "Epoch 7: train_loss: 1.5690 train_acc: 0.2651 | val_loss: 1.5758 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5687 train_acc: 0.2647 | val_loss: 1.5764 val_acc: 0.2543\n",
            "Epoch 9: train_loss: 1.5690 train_acc: 0.2690 | val_loss: 1.5749 val_acc: 0.2543\n",
            "Epoch 10: train_loss: 1.5688 train_acc: 0.2670 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2543\n",
            "Epoch 12: train_loss: 1.5689 train_acc: 0.2690 | val_loss: 1.5754 val_acc: 0.2543\n",
            "Epoch 13: train_loss: 1.5688 train_acc: 0.2697 | val_loss: 1.5778 val_acc: 0.2543\n",
            "Epoch 14: train_loss: 1.5684 train_acc: 0.2653 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2543\n",
            "Epoch 16: train_loss: 1.5679 train_acc: 0.2710 | val_loss: 1.5770 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5753 val_acc: 0.2543\n",
            "Epoch 18: train_loss: 1.5684 train_acc: 0.2697 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5767 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5686 train_acc: 0.2666 | val_loss: 1.5767 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5753 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5646, at epoch 3\n",
            "LSTM 100 2 [40]\n",
            "Epoch 0: train_loss: 1.5732 train_acc: 0.2619 | val_loss: 1.5774 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2741 | val_loss: 1.5708 val_acc: 0.2525\n",
            "Epoch 2: train_loss: 1.5655 train_acc: 0.2872 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5692 train_acc: 0.2694 | val_loss: 1.5763 val_acc: 0.2661\n",
            "Epoch 4: train_loss: 1.5689 train_acc: 0.2693 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5689 train_acc: 0.2695 | val_loss: 1.5739 val_acc: 0.2552\n",
            "Epoch 6: train_loss: 1.5689 train_acc: 0.2639 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5690 train_acc: 0.2685 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5685 train_acc: 0.2660 | val_loss: 1.5717 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5682 train_acc: 0.2674 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5673 train_acc: 0.2714 | val_loss: 1.5780 val_acc: 0.2816\n",
            "Epoch 11: train_loss: 1.5681 train_acc: 0.2697 | val_loss: 1.5571 val_acc: 0.2997\n",
            "Epoch 12: train_loss: 1.5670 train_acc: 0.2752 | val_loss: 1.5527 val_acc: 0.3106\n",
            "Epoch 13: train_loss: 1.5694 train_acc: 0.2722 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5686 train_acc: 0.2699 | val_loss: 1.5748 val_acc: 0.2625\n",
            "Epoch 15: train_loss: 1.5687 train_acc: 0.2690 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5671 train_acc: 0.2733 | val_loss: 1.5738 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5667 train_acc: 0.2713 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5654 train_acc: 0.2724 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5656 train_acc: 0.2695 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5651 train_acc: 0.2712 | val_loss: 1.5759 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5653 train_acc: 0.2740 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5654 train_acc: 0.2683 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5654 train_acc: 0.2739 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5657 train_acc: 0.2739 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5527, at epoch 12\n",
            "LSTM 100 2 [50]\n",
            "Epoch 0: train_loss: 1.5774 train_acc: 0.2541 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5691 train_acc: 0.2685 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5695 train_acc: 0.2678 | val_loss: 1.5799 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5690 train_acc: 0.2719 | val_loss: 1.5732 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5702 train_acc: 0.2636 | val_loss: 1.5751 val_acc: 0.2579\n",
            "Epoch 5: train_loss: 1.5686 train_acc: 0.2699 | val_loss: 1.5729 val_acc: 0.2552\n",
            "Epoch 6: train_loss: 1.5646 train_acc: 0.2784 | val_loss: 1.5698 val_acc: 0.2906\n",
            "Epoch 7: train_loss: 1.5610 train_acc: 0.2918 | val_loss: 1.5706 val_acc: 0.3006\n",
            "Epoch 8: train_loss: 1.5661 train_acc: 0.2757 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5644 train_acc: 0.2780 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5651 train_acc: 0.2745 | val_loss: 1.5767 val_acc: 0.2761\n",
            "Epoch 11: train_loss: 1.5656 train_acc: 0.2791 | val_loss: 1.5740 val_acc: 0.2616\n",
            "Epoch 12: train_loss: 1.5663 train_acc: 0.2659 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5648 train_acc: 0.2688 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5649 train_acc: 0.2678 | val_loss: 1.5753 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5649 train_acc: 0.2724 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5648 train_acc: 0.2705 | val_loss: 1.5739 val_acc: 0.2625\n",
            "Epoch 17: train_loss: 1.5645 train_acc: 0.2654 | val_loss: 1.5737 val_acc: 0.2625\n",
            "Epoch 18: train_loss: 1.5649 train_acc: 0.2667 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5650 train_acc: 0.2732 | val_loss: 1.5742 val_acc: 0.2625\n",
            "Epoch 20: train_loss: 1.5642 train_acc: 0.2699 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5675 train_acc: 0.2692 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5698, at epoch 6\n",
            "LSTM 100 2 [60]\n",
            "Epoch 0: train_loss: 1.5733 train_acc: 0.2688 | val_loss: 1.5755 val_acc: 0.2625\n",
            "Epoch 1: train_loss: 1.5688 train_acc: 0.2666 | val_loss: 1.5767 val_acc: 0.2570\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2674 | val_loss: 1.5698 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5680 train_acc: 0.2678 | val_loss: 1.5649 val_acc: 0.2716\n",
            "Epoch 4: train_loss: 1.5675 train_acc: 0.2720 | val_loss: 1.5677 val_acc: 0.2843\n",
            "Epoch 5: train_loss: 1.5677 train_acc: 0.2706 | val_loss: 1.5580 val_acc: 0.2716\n",
            "Epoch 6: train_loss: 1.5646 train_acc: 0.2802 | val_loss: 1.6091 val_acc: 0.2579\n",
            "Epoch 7: train_loss: 1.5708 train_acc: 0.2697 | val_loss: 1.5683 val_acc: 0.2952\n",
            "Epoch 8: train_loss: 1.5630 train_acc: 0.2772 | val_loss: 1.5691 val_acc: 0.2952\n",
            "Epoch 9: train_loss: 1.5629 train_acc: 0.2763 | val_loss: 1.5694 val_acc: 0.2952\n",
            "Epoch 10: train_loss: 1.5624 train_acc: 0.2721 | val_loss: 1.5686 val_acc: 0.2961\n",
            "Epoch 11: train_loss: 1.5629 train_acc: 0.2786 | val_loss: 1.5691 val_acc: 0.2952\n",
            "Epoch 12: train_loss: 1.5623 train_acc: 0.2777 | val_loss: 1.5709 val_acc: 0.2943\n",
            "Epoch 13: train_loss: 1.5620 train_acc: 0.2783 | val_loss: 1.5718 val_acc: 0.2543\n",
            "Epoch 14: train_loss: 1.5624 train_acc: 0.2795 | val_loss: 1.5701 val_acc: 0.2943\n",
            "Epoch 15: train_loss: 1.5624 train_acc: 0.2748 | val_loss: 1.5694 val_acc: 0.2934\n",
            "Epoch 16: train_loss: 1.5624 train_acc: 0.2763 | val_loss: 1.5710 val_acc: 0.2925\n",
            "Epoch 17: train_loss: 1.5598 train_acc: 0.2774 | val_loss: 1.5716 val_acc: 0.2525\n",
            "Epoch 18: train_loss: 1.5592 train_acc: 0.2794 | val_loss: 1.5718 val_acc: 0.2897\n",
            "Epoch 19: train_loss: 1.5601 train_acc: 0.2814 | val_loss: 1.5706 val_acc: 0.2934\n",
            "Epoch 20: train_loss: 1.5607 train_acc: 0.2776 | val_loss: 1.5704 val_acc: 0.2925\n",
            "Epoch 21: train_loss: 1.5603 train_acc: 0.2796 | val_loss: 1.5666 val_acc: 0.2961\n",
            "Epoch 22: train_loss: 1.5600 train_acc: 0.2824 | val_loss: 1.5688 val_acc: 0.2952\n",
            "Epoch 23: train_loss: 1.5604 train_acc: 0.2790 | val_loss: 1.5674 val_acc: 0.2934\n",
            "Epoch 24: train_loss: 1.5610 train_acc: 0.2817 | val_loss: 1.5692 val_acc: 0.2934\n",
            "Lowest val_loss: 1.5580, at epoch 5\n",
            "LSTM 100 2 [70]\n",
            "Epoch 0: train_loss: 1.5725 train_acc: 0.2598 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5694 train_acc: 0.2706 | val_loss: 1.5736 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2719 | val_loss: 1.5727 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5683 train_acc: 0.2693 | val_loss: 1.5616 val_acc: 0.2725\n",
            "Epoch 4: train_loss: 1.5562 train_acc: 0.2948 | val_loss: 1.5725 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5673 train_acc: 0.2705 | val_loss: 1.5674 val_acc: 0.2952\n",
            "Epoch 6: train_loss: 1.5674 train_acc: 0.2765 | val_loss: 1.5621 val_acc: 0.2852\n",
            "Epoch 7: train_loss: 1.5121 train_acc: 0.3243 | val_loss: 1.4792 val_acc: 0.3342\n",
            "Epoch 8: train_loss: 1.5529 train_acc: 0.2811 | val_loss: 1.5758 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5687 train_acc: 0.2681 | val_loss: 1.5722 val_acc: 0.3460\n",
            "Epoch 10: train_loss: 1.5686 train_acc: 0.2665 | val_loss: 1.5721 val_acc: 0.2861\n",
            "Epoch 11: train_loss: 1.5687 train_acc: 0.2676 | val_loss: 1.5711 val_acc: 0.2579\n",
            "Epoch 12: train_loss: 1.5692 train_acc: 0.2660 | val_loss: 1.5717 val_acc: 0.2589\n",
            "Epoch 13: train_loss: 1.5685 train_acc: 0.2719 | val_loss: 1.5692 val_acc: 0.2634\n",
            "Epoch 14: train_loss: 1.5635 train_acc: 0.2829 | val_loss: 1.5429 val_acc: 0.3324\n",
            "Epoch 15: train_loss: 1.5686 train_acc: 0.2720 | val_loss: 1.5727 val_acc: 0.2807\n",
            "Epoch 16: train_loss: 1.5685 train_acc: 0.2691 | val_loss: 1.5696 val_acc: 0.3052\n",
            "Epoch 17: train_loss: 1.5687 train_acc: 0.2638 | val_loss: 1.5712 val_acc: 0.2698\n",
            "Epoch 18: train_loss: 1.5687 train_acc: 0.2720 | val_loss: 1.5694 val_acc: 0.3506\n",
            "Epoch 19: train_loss: 1.5685 train_acc: 0.2688 | val_loss: 1.5677 val_acc: 0.2716\n",
            "Epoch 20: train_loss: 1.5687 train_acc: 0.2712 | val_loss: 1.5666 val_acc: 0.3515\n",
            "Epoch 21: train_loss: 1.5681 train_acc: 0.2712 | val_loss: 1.5657 val_acc: 0.2670\n",
            "Epoch 22: train_loss: 1.5676 train_acc: 0.2718 | val_loss: 1.5468 val_acc: 0.3197\n",
            "Epoch 23: train_loss: 1.5589 train_acc: 0.2894 | val_loss: 1.5636 val_acc: 0.2634\n",
            "Epoch 24: train_loss: 1.5680 train_acc: 0.2683 | val_loss: 1.5499 val_acc: 0.2688\n",
            "Lowest val_loss: 1.4792, at epoch 7\n",
            "LSTM 150 1 [30]\n",
            "Epoch 0: train_loss: 1.5731 train_acc: 0.2571 | val_loss: 1.5703 val_acc: 0.2679\n",
            "Epoch 1: train_loss: 1.5700 train_acc: 0.2653 | val_loss: 1.5723 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5681 train_acc: 0.2677 | val_loss: 1.5649 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5667 train_acc: 0.2722 | val_loss: 1.5536 val_acc: 0.3206\n",
            "Epoch 4: train_loss: 1.5584 train_acc: 0.2851 | val_loss: 1.5714 val_acc: 0.2579\n",
            "Epoch 5: train_loss: 1.5694 train_acc: 0.2728 | val_loss: 1.5715 val_acc: 0.2579\n",
            "Epoch 6: train_loss: 1.5682 train_acc: 0.2671 | val_loss: 1.5684 val_acc: 0.2561\n",
            "Epoch 7: train_loss: 1.5669 train_acc: 0.2712 | val_loss: 1.5684 val_acc: 0.2561\n",
            "Epoch 8: train_loss: 1.5674 train_acc: 0.2722 | val_loss: 1.5740 val_acc: 0.2371\n",
            "Epoch 9: train_loss: 1.5670 train_acc: 0.2683 | val_loss: 1.5600 val_acc: 0.2861\n",
            "Epoch 10: train_loss: 1.5613 train_acc: 0.2864 | val_loss: 1.5560 val_acc: 0.2797\n",
            "Epoch 11: train_loss: 1.5644 train_acc: 0.2763 | val_loss: 1.5621 val_acc: 0.2725\n",
            "Epoch 12: train_loss: 1.5625 train_acc: 0.2862 | val_loss: 1.5714 val_acc: 0.2543\n",
            "Epoch 13: train_loss: 1.5699 train_acc: 0.2747 | val_loss: 1.5731 val_acc: 0.2552\n",
            "Epoch 14: train_loss: 1.5659 train_acc: 0.2685 | val_loss: 1.5707 val_acc: 0.2543\n",
            "Epoch 15: train_loss: 1.5646 train_acc: 0.2705 | val_loss: 1.5670 val_acc: 0.2543\n",
            "Epoch 16: train_loss: 1.5632 train_acc: 0.2755 | val_loss: 1.5657 val_acc: 0.2552\n",
            "Epoch 17: train_loss: 1.5620 train_acc: 0.2747 | val_loss: 1.5625 val_acc: 0.2570\n",
            "Epoch 18: train_loss: 1.5610 train_acc: 0.2768 | val_loss: 1.5603 val_acc: 0.2634\n",
            "Epoch 19: train_loss: 1.5591 train_acc: 0.2768 | val_loss: 1.5564 val_acc: 0.2634\n",
            "Epoch 20: train_loss: 1.5577 train_acc: 0.2772 | val_loss: 1.5563 val_acc: 0.2752\n",
            "Epoch 21: train_loss: 1.5575 train_acc: 0.2719 | val_loss: 1.5567 val_acc: 0.2897\n",
            "Epoch 22: train_loss: 1.5178 train_acc: 0.3301 | val_loss: 1.6730 val_acc: 0.2734\n",
            "Epoch 23: train_loss: 1.3914 train_acc: 0.3906 | val_loss: 1.4052 val_acc: 0.3751\n",
            "Epoch 24: train_loss: 1.3020 train_acc: 0.4222 | val_loss: 1.3618 val_acc: 0.4069\n",
            "Lowest val_loss: 1.3618, at epoch 24\n",
            "LSTM 150 1 [40]\n",
            "Epoch 0: train_loss: 1.5730 train_acc: 0.2638 | val_loss: 1.5734 val_acc: 0.2570\n",
            "Epoch 1: train_loss: 1.5699 train_acc: 0.2691 | val_loss: 1.5680 val_acc: 0.2779\n",
            "Epoch 2: train_loss: 1.5689 train_acc: 0.2636 | val_loss: 1.5671 val_acc: 0.2552\n",
            "Epoch 3: train_loss: 1.5674 train_acc: 0.2761 | val_loss: 1.5668 val_acc: 0.2616\n",
            "Epoch 4: train_loss: 1.5658 train_acc: 0.2734 | val_loss: 1.5570 val_acc: 0.2670\n",
            "Epoch 5: train_loss: 1.5650 train_acc: 0.2695 | val_loss: 1.5600 val_acc: 0.2743\n",
            "Epoch 6: train_loss: 1.5615 train_acc: 0.2720 | val_loss: 1.5719 val_acc: 0.2616\n",
            "Epoch 7: train_loss: 1.5649 train_acc: 0.2693 | val_loss: 1.5610 val_acc: 0.3143\n",
            "Epoch 8: train_loss: 1.5650 train_acc: 0.2706 | val_loss: 1.5531 val_acc: 0.2661\n",
            "Epoch 9: train_loss: 1.5536 train_acc: 0.2954 | val_loss: 1.5750 val_acc: 0.2897\n",
            "Epoch 10: train_loss: 1.5689 train_acc: 0.2692 | val_loss: 1.5624 val_acc: 0.2561\n",
            "Epoch 11: train_loss: 1.5639 train_acc: 0.2781 | val_loss: 1.5802 val_acc: 0.2579\n",
            "Epoch 12: train_loss: 1.4771 train_acc: 0.3525 | val_loss: 1.5006 val_acc: 0.3179\n",
            "Epoch 13: train_loss: 1.3426 train_acc: 0.4059 | val_loss: 1.4360 val_acc: 0.3615\n",
            "Epoch 14: train_loss: 1.2797 train_acc: 0.4284 | val_loss: 1.4031 val_acc: 0.3751\n",
            "Epoch 15: train_loss: 1.2344 train_acc: 0.4546 | val_loss: 1.3885 val_acc: 0.3833\n",
            "Epoch 16: train_loss: 1.2121 train_acc: 0.4608 | val_loss: 1.4468 val_acc: 0.3651\n",
            "Epoch 17: train_loss: 1.1777 train_acc: 0.4843 | val_loss: 1.3792 val_acc: 0.3960\n",
            "Epoch 18: train_loss: 1.1466 train_acc: 0.4947 | val_loss: 1.4577 val_acc: 0.3724\n",
            "Epoch 19: train_loss: 1.1169 train_acc: 0.5115 | val_loss: 1.4340 val_acc: 0.3869\n",
            "Epoch 20: train_loss: 1.0766 train_acc: 0.5324 | val_loss: 1.4293 val_acc: 0.3896\n",
            "Epoch 21: train_loss: 1.0415 train_acc: 0.5510 | val_loss: 1.4184 val_acc: 0.4078\n",
            "Epoch 22: train_loss: 0.9900 train_acc: 0.5826 | val_loss: 1.5075 val_acc: 0.3878\n",
            "Epoch 23: train_loss: 0.9457 train_acc: 0.6025 | val_loss: 1.5331 val_acc: 0.3942\n",
            "Epoch 24: train_loss: 0.8887 train_acc: 0.6255 | val_loss: 1.5371 val_acc: 0.3778\n",
            "Lowest val_loss: 1.3792, at epoch 17\n",
            "LSTM 150 1 [50]\n",
            "Epoch 0: train_loss: 1.5770 train_acc: 0.2577 | val_loss: 1.5770 val_acc: 0.3088\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2673 | val_loss: 1.5728 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2670 | val_loss: 1.5665 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5683 train_acc: 0.2722 | val_loss: 1.5686 val_acc: 0.2634\n",
            "Epoch 4: train_loss: 1.5652 train_acc: 0.2697 | val_loss: 1.5585 val_acc: 0.2652\n",
            "Epoch 5: train_loss: 1.5555 train_acc: 0.2754 | val_loss: 1.5655 val_acc: 0.3015\n",
            "Epoch 6: train_loss: 1.5588 train_acc: 0.2803 | val_loss: 1.5885 val_acc: 0.2552\n",
            "Epoch 7: train_loss: 1.5634 train_acc: 0.2691 | val_loss: 1.5828 val_acc: 0.2570\n",
            "Epoch 8: train_loss: 1.5611 train_acc: 0.2736 | val_loss: 1.5726 val_acc: 0.3006\n",
            "Epoch 9: train_loss: 1.5606 train_acc: 0.2726 | val_loss: 1.5778 val_acc: 0.2870\n",
            "Epoch 10: train_loss: 1.5604 train_acc: 0.2731 | val_loss: 1.5897 val_acc: 0.2670\n",
            "Epoch 11: train_loss: 1.5547 train_acc: 0.2705 | val_loss: 1.5867 val_acc: 0.3361\n",
            "Epoch 12: train_loss: 1.5617 train_acc: 0.2838 | val_loss: 1.5942 val_acc: 0.2298\n",
            "Epoch 13: train_loss: 1.5640 train_acc: 0.2712 | val_loss: 1.5981 val_acc: 0.2443\n",
            "Epoch 14: train_loss: 1.5635 train_acc: 0.2672 | val_loss: 1.6124 val_acc: 0.2416\n",
            "Epoch 15: train_loss: 1.5611 train_acc: 0.2734 | val_loss: 1.5884 val_acc: 0.2761\n",
            "Epoch 16: train_loss: 1.5580 train_acc: 0.2667 | val_loss: 1.6587 val_acc: 0.3061\n",
            "Epoch 17: train_loss: 1.5524 train_acc: 0.2766 | val_loss: 1.7521 val_acc: 0.2897\n",
            "Epoch 18: train_loss: 1.5530 train_acc: 0.2849 | val_loss: 1.6210 val_acc: 0.3079\n",
            "Epoch 19: train_loss: 1.4936 train_acc: 0.3585 | val_loss: 1.5729 val_acc: 0.3460\n",
            "Epoch 20: train_loss: 1.4672 train_acc: 0.3748 | val_loss: 1.5413 val_acc: 0.3579\n",
            "Epoch 21: train_loss: 1.4130 train_acc: 0.3883 | val_loss: 1.4694 val_acc: 0.3797\n",
            "Epoch 22: train_loss: 1.3735 train_acc: 0.4053 | val_loss: 1.4459 val_acc: 0.3887\n",
            "Epoch 23: train_loss: 1.3187 train_acc: 0.4180 | val_loss: 1.4888 val_acc: 0.3851\n",
            "Epoch 24: train_loss: 1.2696 train_acc: 0.4261 | val_loss: 1.5012 val_acc: 0.3688\n",
            "Lowest val_loss: 1.4459, at epoch 22\n",
            "LSTM 150 1 [60]\n",
            "Epoch 0: train_loss: 1.5741 train_acc: 0.2636 | val_loss: 1.5732 val_acc: 0.2598\n",
            "Epoch 1: train_loss: 1.5681 train_acc: 0.2697 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5688 train_acc: 0.2674 | val_loss: 1.5707 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5681 train_acc: 0.2691 | val_loss: 1.5780 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5660 train_acc: 0.2657 | val_loss: 1.5655 val_acc: 0.3061\n",
            "Epoch 5: train_loss: 1.5629 train_acc: 0.2722 | val_loss: 1.5618 val_acc: 0.2389\n",
            "Epoch 6: train_loss: 1.5613 train_acc: 0.2728 | val_loss: 1.5636 val_acc: 0.3088\n",
            "Epoch 7: train_loss: 1.5612 train_acc: 0.2777 | val_loss: 1.5452 val_acc: 0.3206\n",
            "Epoch 8: train_loss: 1.5590 train_acc: 0.2686 | val_loss: 1.5354 val_acc: 0.3351\n",
            "Epoch 9: train_loss: 1.5409 train_acc: 0.2993 | val_loss: 1.4819 val_acc: 0.3442\n",
            "Epoch 10: train_loss: 1.4868 train_acc: 0.3401 | val_loss: 1.5044 val_acc: 0.3451\n",
            "Epoch 11: train_loss: 1.5240 train_acc: 0.3112 | val_loss: 1.5607 val_acc: 0.2961\n",
            "Epoch 12: train_loss: 1.4822 train_acc: 0.3518 | val_loss: 1.5620 val_acc: 0.3215\n",
            "Epoch 13: train_loss: 1.5065 train_acc: 0.3317 | val_loss: 1.5483 val_acc: 0.2952\n",
            "Epoch 14: train_loss: 1.5166 train_acc: 0.3346 | val_loss: 1.5320 val_acc: 0.3179\n",
            "Epoch 15: train_loss: 1.4986 train_acc: 0.3356 | val_loss: 1.5229 val_acc: 0.3288\n",
            "Epoch 16: train_loss: 1.4848 train_acc: 0.3377 | val_loss: 1.5206 val_acc: 0.3288\n",
            "Epoch 17: train_loss: 1.4908 train_acc: 0.3434 | val_loss: 1.5258 val_acc: 0.3288\n",
            "Epoch 18: train_loss: 1.4824 train_acc: 0.3481 | val_loss: 1.5212 val_acc: 0.3297\n",
            "Epoch 19: train_loss: 1.4823 train_acc: 0.3463 | val_loss: 1.5629 val_acc: 0.2825\n",
            "Epoch 20: train_loss: 1.4885 train_acc: 0.3340 | val_loss: 1.4966 val_acc: 0.3633\n",
            "Epoch 21: train_loss: 1.4084 train_acc: 0.3778 | val_loss: 1.3937 val_acc: 0.3915\n",
            "Epoch 22: train_loss: 1.3152 train_acc: 0.4110 | val_loss: 1.4046 val_acc: 0.3887\n",
            "Epoch 23: train_loss: 1.2758 train_acc: 0.4265 | val_loss: 1.4502 val_acc: 0.3733\n",
            "Epoch 24: train_loss: 1.2383 train_acc: 0.4417 | val_loss: 1.4301 val_acc: 0.4114\n",
            "Lowest val_loss: 1.3937, at epoch 21\n",
            "LSTM 150 1 [70]\n",
            "Epoch 0: train_loss: 1.5728 train_acc: 0.2718 | val_loss: 1.5738 val_acc: 0.2816\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2646 | val_loss: 1.5759 val_acc: 0.2579\n",
            "Epoch 2: train_loss: 1.5676 train_acc: 0.2662 | val_loss: 1.5585 val_acc: 0.2579\n",
            "Epoch 3: train_loss: 1.5674 train_acc: 0.2719 | val_loss: 1.5765 val_acc: 0.2734\n",
            "Epoch 4: train_loss: 1.5511 train_acc: 0.2983 | val_loss: 1.5059 val_acc: 0.3397\n",
            "Epoch 5: train_loss: 1.5559 train_acc: 0.2894 | val_loss: 1.5748 val_acc: 0.2516\n",
            "Epoch 6: train_loss: 1.5686 train_acc: 0.2667 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5686 train_acc: 0.2710 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5669 train_acc: 0.2642 | val_loss: 1.5710 val_acc: 0.2570\n",
            "Epoch 9: train_loss: 1.5678 train_acc: 0.2706 | val_loss: 1.5687 val_acc: 0.2625\n",
            "Epoch 10: train_loss: 1.5675 train_acc: 0.2694 | val_loss: 1.5733 val_acc: 0.2970\n",
            "Epoch 11: train_loss: 1.5654 train_acc: 0.2731 | val_loss: 1.5782 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5637 train_acc: 0.2724 | val_loss: 1.5575 val_acc: 0.2670\n",
            "Epoch 13: train_loss: 1.5572 train_acc: 0.2790 | val_loss: 1.5701 val_acc: 0.2870\n",
            "Epoch 14: train_loss: 1.5405 train_acc: 0.2983 | val_loss: 1.5475 val_acc: 0.3088\n",
            "Epoch 15: train_loss: 1.5175 train_acc: 0.3284 | val_loss: 1.4961 val_acc: 0.3397\n",
            "Epoch 16: train_loss: 1.5363 train_acc: 0.3125 | val_loss: 1.5664 val_acc: 0.2652\n",
            "Epoch 17: train_loss: 1.5527 train_acc: 0.2837 | val_loss: 1.5495 val_acc: 0.2770\n",
            "Epoch 18: train_loss: 1.5119 train_acc: 0.3227 | val_loss: 1.5710 val_acc: 0.2770\n",
            "Epoch 19: train_loss: 1.4966 train_acc: 0.3361 | val_loss: 1.5505 val_acc: 0.2852\n",
            "Epoch 20: train_loss: 1.5206 train_acc: 0.3294 | val_loss: 1.5332 val_acc: 0.3015\n",
            "Epoch 21: train_loss: 1.5043 train_acc: 0.3419 | val_loss: 1.5109 val_acc: 0.3224\n",
            "Epoch 22: train_loss: 1.5111 train_acc: 0.3466 | val_loss: 1.5498 val_acc: 0.3088\n",
            "Epoch 23: train_loss: 1.5187 train_acc: 0.3353 | val_loss: 1.5212 val_acc: 0.3170\n",
            "Epoch 24: train_loss: 1.5083 train_acc: 0.3205 | val_loss: 1.5215 val_acc: 0.3515\n",
            "Lowest val_loss: 1.4961, at epoch 15\n",
            "LSTM 150 2 [30]\n",
            "Epoch 0: train_loss: 1.5726 train_acc: 0.2652 | val_loss: 1.5884 val_acc: 0.2625\n",
            "Epoch 1: train_loss: 1.5696 train_acc: 0.2603 | val_loss: 1.5779 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5689 train_acc: 0.2672 | val_loss: 1.5753 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5625 train_acc: 0.2811 | val_loss: 1.5545 val_acc: 0.2507\n",
            "Epoch 4: train_loss: 1.5690 train_acc: 0.2704 | val_loss: 1.5766 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5687 train_acc: 0.2621 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5759 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5686 train_acc: 0.2684 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5686 train_acc: 0.2676 | val_loss: 1.5765 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5686 train_acc: 0.2660 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5741 val_acc: 0.2516\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5683 train_acc: 0.2698 | val_loss: 1.5753 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5685 train_acc: 0.2690 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5545, at epoch 3\n",
            "LSTM 150 2 [40]\n",
            "Epoch 0: train_loss: 1.5759 train_acc: 0.2584 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5696 train_acc: 0.2672 | val_loss: 1.5719 val_acc: 0.2625\n",
            "Epoch 2: train_loss: 1.5692 train_acc: 0.2697 | val_loss: 1.5755 val_acc: 0.2552\n",
            "Epoch 3: train_loss: 1.5692 train_acc: 0.2711 | val_loss: 1.5729 val_acc: 0.2961\n",
            "Epoch 4: train_loss: 1.5696 train_acc: 0.2635 | val_loss: 1.5709 val_acc: 0.3152\n",
            "Epoch 5: train_loss: 1.5687 train_acc: 0.2647 | val_loss: 1.5708 val_acc: 0.2579\n",
            "Epoch 6: train_loss: 1.5686 train_acc: 0.2698 | val_loss: 1.5652 val_acc: 0.2725\n",
            "Epoch 7: train_loss: 1.5685 train_acc: 0.2706 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5693 train_acc: 0.2680 | val_loss: 1.5785 val_acc: 0.2525\n",
            "Epoch 9: train_loss: 1.5684 train_acc: 0.2708 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5688 train_acc: 0.2719 | val_loss: 1.5751 val_acc: 0.2552\n",
            "Epoch 11: train_loss: 1.5680 train_acc: 0.2714 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5683 train_acc: 0.2719 | val_loss: 1.5753 val_acc: 0.2561\n",
            "Epoch 13: train_loss: 1.5688 train_acc: 0.2702 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5684 train_acc: 0.2688 | val_loss: 1.5756 val_acc: 0.2552\n",
            "Epoch 15: train_loss: 1.5689 train_acc: 0.2646 | val_loss: 1.5751 val_acc: 0.2589\n",
            "Epoch 16: train_loss: 1.5687 train_acc: 0.2699 | val_loss: 1.5777 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5667 train_acc: 0.2717 | val_loss: 1.5678 val_acc: 0.2561\n",
            "Epoch 18: train_loss: 1.5622 train_acc: 0.3003 | val_loss: 1.5647 val_acc: 0.2834\n",
            "Epoch 19: train_loss: 1.5609 train_acc: 0.2882 | val_loss: 1.5732 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5692 train_acc: 0.2714 | val_loss: 1.5734 val_acc: 0.3070\n",
            "Epoch 21: train_loss: 1.5682 train_acc: 0.2717 | val_loss: 1.5740 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5686 train_acc: 0.2705 | val_loss: 1.5734 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5677 train_acc: 0.2766 | val_loss: 1.5701 val_acc: 0.2707\n",
            "Lowest val_loss: 1.5647, at epoch 18\n",
            "LSTM 150 2 [50]\n",
            "Epoch 0: train_loss: 1.5743 train_acc: 0.2551 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5692 train_acc: 0.2715 | val_loss: 1.5723 val_acc: 0.2752\n",
            "Epoch 2: train_loss: 1.5699 train_acc: 0.2712 | val_loss: 1.5741 val_acc: 0.2643\n",
            "Epoch 3: train_loss: 1.5696 train_acc: 0.2695 | val_loss: 1.5626 val_acc: 0.2770\n",
            "Epoch 4: train_loss: 1.5671 train_acc: 0.2797 | val_loss: 1.5698 val_acc: 0.2634\n",
            "Epoch 5: train_loss: 1.5702 train_acc: 0.2658 | val_loss: 1.5697 val_acc: 0.2688\n",
            "Epoch 6: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5696 val_acc: 0.2625\n",
            "Epoch 7: train_loss: 1.5686 train_acc: 0.2697 | val_loss: 1.5693 val_acc: 0.2661\n",
            "Epoch 8: train_loss: 1.5687 train_acc: 0.2650 | val_loss: 1.5707 val_acc: 0.2652\n",
            "Epoch 9: train_loss: 1.5687 train_acc: 0.2694 | val_loss: 1.5713 val_acc: 0.2625\n",
            "Epoch 10: train_loss: 1.5690 train_acc: 0.2658 | val_loss: 1.5691 val_acc: 0.2670\n",
            "Epoch 11: train_loss: 1.5684 train_acc: 0.2678 | val_loss: 1.5701 val_acc: 0.2652\n",
            "Epoch 12: train_loss: 1.5687 train_acc: 0.2688 | val_loss: 1.5689 val_acc: 0.2652\n",
            "Epoch 13: train_loss: 1.5684 train_acc: 0.2721 | val_loss: 1.5703 val_acc: 0.2634\n",
            "Epoch 14: train_loss: 1.5689 train_acc: 0.2692 | val_loss: 1.5703 val_acc: 0.2634\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2693 | val_loss: 1.5708 val_acc: 0.2634\n",
            "Epoch 16: train_loss: 1.5693 train_acc: 0.2695 | val_loss: 1.5704 val_acc: 0.2652\n",
            "Epoch 17: train_loss: 1.5681 train_acc: 0.2718 | val_loss: 1.5709 val_acc: 0.2679\n",
            "Epoch 18: train_loss: 1.5694 train_acc: 0.2677 | val_loss: 1.5700 val_acc: 0.2652\n",
            "Epoch 19: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5710 val_acc: 0.2707\n",
            "Epoch 20: train_loss: 1.5687 train_acc: 0.2698 | val_loss: 1.5698 val_acc: 0.2634\n",
            "Epoch 21: train_loss: 1.5692 train_acc: 0.2718 | val_loss: 1.5703 val_acc: 0.2643\n",
            "Epoch 22: train_loss: 1.5689 train_acc: 0.2674 | val_loss: 1.5701 val_acc: 0.2625\n",
            "Epoch 23: train_loss: 1.5681 train_acc: 0.2718 | val_loss: 1.5705 val_acc: 0.2643\n",
            "Epoch 24: train_loss: 1.5686 train_acc: 0.2706 | val_loss: 1.5708 val_acc: 0.2625\n",
            "Lowest val_loss: 1.5626, at epoch 3\n",
            "LSTM 150 2 [60]\n",
            "Epoch 0: train_loss: 1.5747 train_acc: 0.2645 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5697 train_acc: 0.2708 | val_loss: 1.5736 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5690 train_acc: 0.2720 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5685 train_acc: 0.2691 | val_loss: 1.5725 val_acc: 0.2525\n",
            "Epoch 4: train_loss: 1.5677 train_acc: 0.2695 | val_loss: 1.5804 val_acc: 0.2552\n",
            "Epoch 5: train_loss: 1.5677 train_acc: 0.2715 | val_loss: 1.5974 val_acc: 0.2507\n",
            "Epoch 6: train_loss: 1.5676 train_acc: 0.2680 | val_loss: 1.5782 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5654 train_acc: 0.2721 | val_loss: 1.5792 val_acc: 0.3124\n",
            "Epoch 8: train_loss: 1.5587 train_acc: 0.2896 | val_loss: 1.5637 val_acc: 0.2934\n",
            "Epoch 9: train_loss: 1.5657 train_acc: 0.2684 | val_loss: 1.5568 val_acc: 0.2770\n",
            "Epoch 10: train_loss: 1.5584 train_acc: 0.2831 | val_loss: 1.5807 val_acc: 0.2625\n",
            "Epoch 11: train_loss: 1.5594 train_acc: 0.2782 | val_loss: 1.5819 val_acc: 0.2797\n",
            "Epoch 12: train_loss: 1.5579 train_acc: 0.2749 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5694 train_acc: 0.2658 | val_loss: 1.5747 val_acc: 0.2525\n",
            "Epoch 14: train_loss: 1.5692 train_acc: 0.2687 | val_loss: 1.5761 val_acc: 0.2525\n",
            "Epoch 15: train_loss: 1.5692 train_acc: 0.2662 | val_loss: 1.5758 val_acc: 0.2525\n",
            "Epoch 16: train_loss: 1.5686 train_acc: 0.2711 | val_loss: 1.5749 val_acc: 0.2625\n",
            "Epoch 17: train_loss: 1.5690 train_acc: 0.2664 | val_loss: 1.5762 val_acc: 0.2525\n",
            "Epoch 18: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5757 val_acc: 0.2525\n",
            "Epoch 19: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2525\n",
            "Epoch 20: train_loss: 1.5687 train_acc: 0.2685 | val_loss: 1.5756 val_acc: 0.2525\n",
            "Epoch 21: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5692 train_acc: 0.2694 | val_loss: 1.5752 val_acc: 0.2525\n",
            "Epoch 23: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2525\n",
            "Epoch 24: train_loss: 1.5685 train_acc: 0.2694 | val_loss: 1.5754 val_acc: 0.2525\n",
            "Lowest val_loss: 1.5568, at epoch 9\n",
            "LSTM 150 2 [70]\n",
            "Epoch 0: train_loss: 1.5739 train_acc: 0.2684 | val_loss: 1.5810 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2698 | val_loss: 1.5730 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5690 train_acc: 0.2691 | val_loss: 1.5700 val_acc: 0.3006\n",
            "Epoch 3: train_loss: 1.5729 train_acc: 0.2706 | val_loss: 1.5765 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5694 train_acc: 0.2714 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5694 train_acc: 0.2686 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5689 train_acc: 0.2741 | val_loss: 1.5753 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5683 train_acc: 0.2662 | val_loss: 1.5762 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5691 train_acc: 0.2700 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5684 train_acc: 0.2688 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5685 train_acc: 0.2707 | val_loss: 1.5749 val_acc: 0.2625\n",
            "Epoch 11: train_loss: 1.5691 train_acc: 0.2644 | val_loss: 1.5747 val_acc: 0.2525\n",
            "Epoch 12: train_loss: 1.5696 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5687 train_acc: 0.2707 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5682 train_acc: 0.2697 | val_loss: 1.5777 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5686 train_acc: 0.2701 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5740 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5689 train_acc: 0.2708 | val_loss: 1.5850 val_acc: 0.2371\n",
            "Epoch 20: train_loss: 1.5700 train_acc: 0.2697 | val_loss: 1.5775 val_acc: 0.2652\n",
            "Epoch 21: train_loss: 1.5689 train_acc: 0.2750 | val_loss: 1.5788 val_acc: 0.2525\n",
            "Epoch 22: train_loss: 1.5687 train_acc: 0.2721 | val_loss: 1.5747 val_acc: 0.2343\n",
            "Epoch 23: train_loss: 1.5688 train_acc: 0.2685 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5689 train_acc: 0.2695 | val_loss: 1.5737 val_acc: 0.2407\n",
            "Lowest val_loss: 1.5700, at epoch 2\n",
            "LSTM 200 1 [30]\n",
            "Epoch 0: train_loss: 1.5757 train_acc: 0.2611 | val_loss: 1.5743 val_acc: 0.2516\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2663 | val_loss: 1.5712 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2697 | val_loss: 1.5697 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5666 train_acc: 0.2753 | val_loss: 1.5586 val_acc: 0.2661\n",
            "Epoch 4: train_loss: 1.5671 train_acc: 0.2759 | val_loss: 1.5775 val_acc: 0.2543\n",
            "Epoch 5: train_loss: 1.5685 train_acc: 0.2650 | val_loss: 1.5738 val_acc: 0.2480\n",
            "Epoch 6: train_loss: 1.5671 train_acc: 0.2727 | val_loss: 1.5812 val_acc: 0.2561\n",
            "Epoch 7: train_loss: 1.5614 train_acc: 0.2891 | val_loss: 1.5700 val_acc: 0.2698\n",
            "Epoch 8: train_loss: 1.5669 train_acc: 0.2743 | val_loss: 1.5877 val_acc: 0.2625\n",
            "Epoch 9: train_loss: 1.5640 train_acc: 0.2677 | val_loss: 1.6030 val_acc: 0.2552\n",
            "Epoch 10: train_loss: 1.5627 train_acc: 0.2767 | val_loss: 1.5695 val_acc: 0.3170\n",
            "Epoch 11: train_loss: 1.5624 train_acc: 0.2697 | val_loss: 1.5951 val_acc: 0.2616\n",
            "Epoch 12: train_loss: 1.5616 train_acc: 0.2740 | val_loss: 1.6239 val_acc: 0.2625\n",
            "Epoch 13: train_loss: 1.5517 train_acc: 0.2913 | val_loss: 1.5859 val_acc: 0.2870\n",
            "Epoch 14: train_loss: 1.5351 train_acc: 0.3295 | val_loss: 1.5782 val_acc: 0.2698\n",
            "Epoch 15: train_loss: 1.5666 train_acc: 0.2735 | val_loss: 1.5621 val_acc: 0.2625\n",
            "Epoch 16: train_loss: 1.5599 train_acc: 0.2843 | val_loss: 1.5432 val_acc: 0.2788\n",
            "Epoch 17: train_loss: 1.5626 train_acc: 0.2866 | val_loss: 1.5571 val_acc: 0.2961\n",
            "Epoch 18: train_loss: 1.5534 train_acc: 0.2848 | val_loss: 1.5646 val_acc: 0.2489\n",
            "Epoch 19: train_loss: 1.5611 train_acc: 0.2617 | val_loss: 1.5703 val_acc: 0.2543\n",
            "Epoch 20: train_loss: 1.5695 train_acc: 0.2713 | val_loss: 1.5700 val_acc: 0.3288\n",
            "Epoch 21: train_loss: 1.5689 train_acc: 0.2623 | val_loss: 1.5703 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5713 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5696 train_acc: 0.2700 | val_loss: 1.5702 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5691 train_acc: 0.2701 | val_loss: 1.5697 val_acc: 0.2525\n",
            "Lowest val_loss: 1.5432, at epoch 16\n",
            "LSTM 200 1 [40]\n",
            "Epoch 0: train_loss: 1.5764 train_acc: 0.2638 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5699 train_acc: 0.2690 | val_loss: 1.5734 val_acc: 0.2625\n",
            "Epoch 2: train_loss: 1.5680 train_acc: 0.2720 | val_loss: 1.5714 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5677 train_acc: 0.2718 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5670 train_acc: 0.2684 | val_loss: 1.5555 val_acc: 0.2934\n",
            "Epoch 5: train_loss: 1.5660 train_acc: 0.2690 | val_loss: 1.5637 val_acc: 0.2625\n",
            "Epoch 6: train_loss: 1.5603 train_acc: 0.2753 | val_loss: 1.5552 val_acc: 0.2734\n",
            "Epoch 7: train_loss: 1.5647 train_acc: 0.2677 | val_loss: 1.5672 val_acc: 0.2452\n",
            "Epoch 8: train_loss: 1.5646 train_acc: 0.2697 | val_loss: 1.5571 val_acc: 0.2525\n",
            "Epoch 9: train_loss: 1.5634 train_acc: 0.2739 | val_loss: 1.5547 val_acc: 0.2570\n",
            "Epoch 10: train_loss: 1.5598 train_acc: 0.2790 | val_loss: 1.5770 val_acc: 0.2452\n",
            "Epoch 11: train_loss: 1.5627 train_acc: 0.2715 | val_loss: 1.5642 val_acc: 0.2561\n",
            "Epoch 12: train_loss: 1.5613 train_acc: 0.2646 | val_loss: 1.5668 val_acc: 0.3025\n",
            "Epoch 13: train_loss: 1.5589 train_acc: 0.2772 | val_loss: 1.5998 val_acc: 0.2825\n",
            "Epoch 14: train_loss: 1.5563 train_acc: 0.2760 | val_loss: 1.5646 val_acc: 0.3115\n",
            "Epoch 15: train_loss: 1.5402 train_acc: 0.2907 | val_loss: 1.5764 val_acc: 0.2625\n",
            "Epoch 16: train_loss: 1.5559 train_acc: 0.2802 | val_loss: 1.6538 val_acc: 0.2679\n",
            "Epoch 17: train_loss: 1.5512 train_acc: 0.3024 | val_loss: 1.5916 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5656 train_acc: 0.2719 | val_loss: 1.5866 val_acc: 0.2570\n",
            "Epoch 19: train_loss: 1.5566 train_acc: 0.2887 | val_loss: 1.5587 val_acc: 0.2934\n",
            "Epoch 20: train_loss: 1.5455 train_acc: 0.3126 | val_loss: 1.5097 val_acc: 0.3270\n",
            "Epoch 21: train_loss: 1.5271 train_acc: 0.3081 | val_loss: 1.5156 val_acc: 0.3406\n",
            "Epoch 22: train_loss: 1.5247 train_acc: 0.3006 | val_loss: 1.5994 val_acc: 0.2852\n",
            "Epoch 23: train_loss: 1.5399 train_acc: 0.2995 | val_loss: 1.6043 val_acc: 0.3215\n",
            "Epoch 24: train_loss: 1.4561 train_acc: 0.3551 | val_loss: 1.4778 val_acc: 0.3733\n",
            "Lowest val_loss: 1.4778, at epoch 24\n",
            "LSTM 200 1 [50]\n",
            "Epoch 0: train_loss: 1.5726 train_acc: 0.2701 | val_loss: 1.5704 val_acc: 0.2543\n",
            "Epoch 1: train_loss: 1.5697 train_acc: 0.2726 | val_loss: 1.5668 val_acc: 0.2670\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2650 | val_loss: 1.5642 val_acc: 0.2716\n",
            "Epoch 3: train_loss: 1.5693 train_acc: 0.2708 | val_loss: 1.5787 val_acc: 0.2979\n",
            "Epoch 4: train_loss: 1.5668 train_acc: 0.2710 | val_loss: 1.5689 val_acc: 0.3333\n",
            "Epoch 5: train_loss: 1.5642 train_acc: 0.2834 | val_loss: 1.5167 val_acc: 0.3579\n",
            "Epoch 6: train_loss: 1.5630 train_acc: 0.2791 | val_loss: 1.5784 val_acc: 0.2552\n",
            "Epoch 7: train_loss: 1.5655 train_acc: 0.2664 | val_loss: 1.5818 val_acc: 0.2543\n",
            "Epoch 8: train_loss: 1.5640 train_acc: 0.2674 | val_loss: 1.5932 val_acc: 0.2480\n",
            "Epoch 9: train_loss: 1.5622 train_acc: 0.2722 | val_loss: 1.5743 val_acc: 0.3143\n",
            "Epoch 10: train_loss: 1.5497 train_acc: 0.2960 | val_loss: 1.4547 val_acc: 0.3706\n",
            "Epoch 11: train_loss: 1.5375 train_acc: 0.2986 | val_loss: 1.5482 val_acc: 0.2607\n",
            "Epoch 12: train_loss: 1.5576 train_acc: 0.2787 | val_loss: 1.6006 val_acc: 0.2461\n",
            "Epoch 13: train_loss: 1.5617 train_acc: 0.2740 | val_loss: 1.5857 val_acc: 0.3124\n",
            "Epoch 14: train_loss: 1.5575 train_acc: 0.2782 | val_loss: 1.5576 val_acc: 0.3097\n",
            "Epoch 15: train_loss: 1.5586 train_acc: 0.2841 | val_loss: 1.5976 val_acc: 0.2716\n",
            "Epoch 16: train_loss: 1.5601 train_acc: 0.2862 | val_loss: 1.5821 val_acc: 0.2561\n",
            "Epoch 17: train_loss: 1.5661 train_acc: 0.2698 | val_loss: 1.5822 val_acc: 0.2416\n",
            "Epoch 18: train_loss: 1.5451 train_acc: 0.2931 | val_loss: 1.5144 val_acc: 0.3333\n",
            "Epoch 19: train_loss: 1.5591 train_acc: 0.2852 | val_loss: 1.6026 val_acc: 0.2652\n",
            "Epoch 20: train_loss: 1.5538 train_acc: 0.2733 | val_loss: 1.6001 val_acc: 0.2888\n",
            "Epoch 21: train_loss: 1.5408 train_acc: 0.2802 | val_loss: 1.6052 val_acc: 0.2797\n",
            "Epoch 22: train_loss: 1.5528 train_acc: 0.2743 | val_loss: 1.6461 val_acc: 0.3134\n",
            "Epoch 23: train_loss: 1.4327 train_acc: 0.3660 | val_loss: 1.4665 val_acc: 0.3715\n",
            "Epoch 24: train_loss: 1.3019 train_acc: 0.4118 | val_loss: 1.4544 val_acc: 0.3606\n",
            "Lowest val_loss: 1.4544, at epoch 24\n",
            "LSTM 200 1 [60]\n",
            "Epoch 0: train_loss: 1.5743 train_acc: 0.2645 | val_loss: 1.5724 val_acc: 0.2797\n",
            "Epoch 1: train_loss: 1.5701 train_acc: 0.2624 | val_loss: 1.5704 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5682 train_acc: 0.2720 | val_loss: 1.5721 val_acc: 0.2616\n",
            "Epoch 3: train_loss: 1.5671 train_acc: 0.2691 | val_loss: 1.5936 val_acc: 0.2552\n",
            "Epoch 4: train_loss: 1.5662 train_acc: 0.2642 | val_loss: 1.5641 val_acc: 0.2507\n",
            "Epoch 5: train_loss: 1.5644 train_acc: 0.2664 | val_loss: 1.5671 val_acc: 0.2843\n",
            "Epoch 6: train_loss: 1.5607 train_acc: 0.2724 | val_loss: 1.5919 val_acc: 0.3088\n",
            "Epoch 7: train_loss: 1.5585 train_acc: 0.2728 | val_loss: 1.5417 val_acc: 0.3342\n",
            "Epoch 8: train_loss: 1.5361 train_acc: 0.2995 | val_loss: 1.6076 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5124 train_acc: 0.3236 | val_loss: 1.5516 val_acc: 0.3333\n",
            "Epoch 10: train_loss: 1.5476 train_acc: 0.2931 | val_loss: 1.5727 val_acc: 0.2652\n",
            "Epoch 11: train_loss: 1.5476 train_acc: 0.2828 | val_loss: 1.5480 val_acc: 0.3043\n",
            "Epoch 12: train_loss: 1.5192 train_acc: 0.3318 | val_loss: 1.5734 val_acc: 0.2643\n",
            "Epoch 13: train_loss: 1.5464 train_acc: 0.2897 | val_loss: 1.5571 val_acc: 0.2752\n",
            "Epoch 14: train_loss: 1.5130 train_acc: 0.3155 | val_loss: 1.5458 val_acc: 0.3433\n",
            "Epoch 15: train_loss: 1.4802 train_acc: 0.3608 | val_loss: 1.4475 val_acc: 0.3706\n",
            "Epoch 16: train_loss: 1.3668 train_acc: 0.3988 | val_loss: 1.4265 val_acc: 0.3488\n",
            "Epoch 17: train_loss: 1.3036 train_acc: 0.4135 | val_loss: 1.4203 val_acc: 0.3706\n",
            "Epoch 18: train_loss: 1.2536 train_acc: 0.4408 | val_loss: 1.3746 val_acc: 0.3915\n",
            "Epoch 19: train_loss: 1.2158 train_acc: 0.4482 | val_loss: 1.3975 val_acc: 0.3987\n",
            "Epoch 20: train_loss: 1.1767 train_acc: 0.4786 | val_loss: 1.4399 val_acc: 0.3833\n",
            "Epoch 21: train_loss: 1.1401 train_acc: 0.5002 | val_loss: 1.4741 val_acc: 0.3951\n",
            "Epoch 22: train_loss: 1.0999 train_acc: 0.5179 | val_loss: 1.4467 val_acc: 0.3842\n",
            "Epoch 23: train_loss: 1.0485 train_acc: 0.5451 | val_loss: 1.5333 val_acc: 0.3842\n",
            "Epoch 24: train_loss: 0.9936 train_acc: 0.5695 | val_loss: 1.5298 val_acc: 0.3797\n",
            "Lowest val_loss: 1.3746, at epoch 18\n",
            "LSTM 200 1 [70]\n",
            "Epoch 0: train_loss: 1.5725 train_acc: 0.2652 | val_loss: 1.5762 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5697 train_acc: 0.2663 | val_loss: 1.5695 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5679 train_acc: 0.2718 | val_loss: 1.5610 val_acc: 0.2616\n",
            "Epoch 3: train_loss: 1.5665 train_acc: 0.2673 | val_loss: 1.5720 val_acc: 0.2725\n",
            "Epoch 4: train_loss: 1.5670 train_acc: 0.2700 | val_loss: 1.5436 val_acc: 0.2625\n",
            "Epoch 5: train_loss: 1.5673 train_acc: 0.2740 | val_loss: 1.5684 val_acc: 0.2616\n",
            "Epoch 6: train_loss: 1.5661 train_acc: 0.2712 | val_loss: 1.5538 val_acc: 0.2979\n",
            "Epoch 7: train_loss: 1.5481 train_acc: 0.3020 | val_loss: 1.5405 val_acc: 0.3261\n",
            "Epoch 8: train_loss: 1.5353 train_acc: 0.3184 | val_loss: 1.5337 val_acc: 0.3206\n",
            "Epoch 9: train_loss: 1.5352 train_acc: 0.3021 | val_loss: 1.6011 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5632 train_acc: 0.2700 | val_loss: 1.6083 val_acc: 0.2698\n",
            "Epoch 11: train_loss: 1.5574 train_acc: 0.2786 | val_loss: 1.6529 val_acc: 0.2779\n",
            "Epoch 12: train_loss: 1.5457 train_acc: 0.3051 | val_loss: 1.5990 val_acc: 0.2480\n",
            "Epoch 13: train_loss: 1.5270 train_acc: 0.3024 | val_loss: 1.5498 val_acc: 0.2452\n",
            "Epoch 14: train_loss: 1.5513 train_acc: 0.2928 | val_loss: 1.5650 val_acc: 0.2770\n",
            "Epoch 15: train_loss: 1.5618 train_acc: 0.2820 | val_loss: 1.5655 val_acc: 0.2698\n",
            "Epoch 16: train_loss: 1.5644 train_acc: 0.2729 | val_loss: 1.5686 val_acc: 0.2652\n",
            "Epoch 17: train_loss: 1.5637 train_acc: 0.2726 | val_loss: 1.5616 val_acc: 0.2643\n",
            "Epoch 18: train_loss: 1.5614 train_acc: 0.2798 | val_loss: 1.5611 val_acc: 0.2679\n",
            "Epoch 19: train_loss: 1.5638 train_acc: 0.2760 | val_loss: 1.5885 val_acc: 0.2552\n",
            "Epoch 20: train_loss: 1.5688 train_acc: 0.2653 | val_loss: 1.5720 val_acc: 0.2525\n",
            "Epoch 21: train_loss: 1.5675 train_acc: 0.2694 | val_loss: 1.5726 val_acc: 0.2579\n",
            "Epoch 22: train_loss: 1.5669 train_acc: 0.2725 | val_loss: 1.5741 val_acc: 0.2725\n",
            "Epoch 23: train_loss: 1.5669 train_acc: 0.2747 | val_loss: 1.5724 val_acc: 0.2797\n",
            "Epoch 24: train_loss: 1.5658 train_acc: 0.2719 | val_loss: 1.5741 val_acc: 0.2634\n",
            "Lowest val_loss: 1.5337, at epoch 8\n",
            "LSTM 200 2 [30]\n",
            "Epoch 0: train_loss: 1.5743 train_acc: 0.2533 | val_loss: 1.5778 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5693 train_acc: 0.2644 | val_loss: 1.5767 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5695 train_acc: 0.2666 | val_loss: 1.5751 val_acc: 0.3006\n",
            "Epoch 3: train_loss: 1.5686 train_acc: 0.2749 | val_loss: 1.5777 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5684 train_acc: 0.2724 | val_loss: 1.5700 val_acc: 0.2934\n",
            "Epoch 5: train_loss: 1.5689 train_acc: 0.2740 | val_loss: 1.5754 val_acc: 0.2525\n",
            "Epoch 6: train_loss: 1.5676 train_acc: 0.2659 | val_loss: 1.5942 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5662 train_acc: 0.2832 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5654 train_acc: 0.2892 | val_loss: 1.5779 val_acc: 0.2561\n",
            "Epoch 9: train_loss: 1.5734 train_acc: 0.2663 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5690 train_acc: 0.2639 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5690 train_acc: 0.2669 | val_loss: 1.5740 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5685 train_acc: 0.2702 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5689 train_acc: 0.2718 | val_loss: 1.5760 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5684 train_acc: 0.2686 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5744 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5684 train_acc: 0.2657 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5689 train_acc: 0.2666 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5685 train_acc: 0.2690 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5685 train_acc: 0.2704 | val_loss: 1.5743 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5700, at epoch 4\n",
            "LSTM 200 2 [40]\n",
            "Epoch 0: train_loss: 1.5741 train_acc: 0.2636 | val_loss: 1.5780 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2680 | val_loss: 1.5741 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5696 train_acc: 0.2656 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5695 train_acc: 0.2695 | val_loss: 1.5758 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5688 train_acc: 0.2643 | val_loss: 1.5820 val_acc: 0.2525\n",
            "Epoch 5: train_loss: 1.5657 train_acc: 0.2810 | val_loss: 1.5629 val_acc: 0.2807\n",
            "Epoch 6: train_loss: 1.5573 train_acc: 0.2979 | val_loss: 1.5638 val_acc: 0.2852\n",
            "Epoch 7: train_loss: 1.5573 train_acc: 0.2772 | val_loss: 1.5655 val_acc: 0.2852\n",
            "Epoch 8: train_loss: 1.5634 train_acc: 0.2674 | val_loss: 1.5738 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5675 train_acc: 0.2718 | val_loss: 1.5737 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5638 train_acc: 0.2679 | val_loss: 1.5722 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5664 train_acc: 0.2665 | val_loss: 1.5742 val_acc: 0.2543\n",
            "Epoch 12: train_loss: 1.5650 train_acc: 0.2714 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5680 train_acc: 0.2718 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5743 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5753 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5681 train_acc: 0.2718 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5629, at epoch 5\n",
            "LSTM 200 2 [50]\n",
            "Epoch 0: train_loss: 1.5707 train_acc: 0.2695 | val_loss: 1.5805 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2680 | val_loss: 1.5732 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5695 train_acc: 0.2656 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5689 train_acc: 0.2687 | val_loss: 1.5703 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5671 train_acc: 0.2711 | val_loss: 1.5673 val_acc: 0.2570\n",
            "Epoch 5: train_loss: 1.5707 train_acc: 0.2683 | val_loss: 1.5687 val_acc: 0.2607\n",
            "Epoch 6: train_loss: 1.5658 train_acc: 0.2692 | val_loss: 1.5756 val_acc: 0.2516\n",
            "Epoch 7: train_loss: 1.5652 train_acc: 0.2654 | val_loss: 1.6366 val_acc: 0.2498\n",
            "Epoch 8: train_loss: 1.5624 train_acc: 0.2733 | val_loss: 1.5986 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5611 train_acc: 0.2657 | val_loss: 1.5983 val_acc: 0.2734\n",
            "Epoch 10: train_loss: 1.5600 train_acc: 0.2738 | val_loss: 1.6108 val_acc: 0.2779\n",
            "Epoch 11: train_loss: 1.5556 train_acc: 0.2774 | val_loss: 1.5719 val_acc: 0.2943\n",
            "Epoch 12: train_loss: 1.5315 train_acc: 0.3200 | val_loss: 1.5036 val_acc: 0.3470\n",
            "Epoch 13: train_loss: 1.5103 train_acc: 0.3068 | val_loss: 1.4984 val_acc: 0.3233\n",
            "Epoch 14: train_loss: 1.5470 train_acc: 0.2928 | val_loss: 1.5737 val_acc: 0.2552\n",
            "Epoch 15: train_loss: 1.5678 train_acc: 0.2714 | val_loss: 1.5725 val_acc: 0.2561\n",
            "Epoch 16: train_loss: 1.5668 train_acc: 0.2711 | val_loss: 1.5670 val_acc: 0.3252\n",
            "Epoch 17: train_loss: 1.5652 train_acc: 0.2582 | val_loss: 1.5816 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5613 train_acc: 0.2639 | val_loss: 2.0027 val_acc: 0.2589\n",
            "Epoch 19: train_loss: 1.5609 train_acc: 0.2727 | val_loss: 1.5719 val_acc: 0.2589\n",
            "Epoch 20: train_loss: 1.5605 train_acc: 0.2756 | val_loss: 1.6309 val_acc: 0.2761\n",
            "Epoch 21: train_loss: 1.5530 train_acc: 0.2869 | val_loss: 1.5793 val_acc: 0.2679\n",
            "Epoch 22: train_loss: 1.5367 train_acc: 0.2989 | val_loss: 1.5866 val_acc: 0.3533\n",
            "Epoch 23: train_loss: 1.4035 train_acc: 0.3861 | val_loss: 1.5203 val_acc: 0.3742\n",
            "Epoch 24: train_loss: 1.2958 train_acc: 0.4215 | val_loss: 1.4080 val_acc: 0.3915\n",
            "Lowest val_loss: 1.4080, at epoch 24\n",
            "LSTM 200 2 [60]\n",
            "Epoch 0: train_loss: 1.5740 train_acc: 0.2688 | val_loss: 1.5742 val_acc: 0.2625\n",
            "Epoch 1: train_loss: 1.5699 train_acc: 0.2722 | val_loss: 1.5724 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5684 train_acc: 0.2760 | val_loss: 1.5710 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5683 train_acc: 0.2731 | val_loss: 1.5610 val_acc: 0.2788\n",
            "Epoch 4: train_loss: 1.5701 train_acc: 0.2733 | val_loss: 1.5778 val_acc: 0.2525\n",
            "Epoch 5: train_loss: 1.5697 train_acc: 0.2679 | val_loss: 1.5771 val_acc: 0.2525\n",
            "Epoch 6: train_loss: 1.5678 train_acc: 0.2674 | val_loss: 1.5763 val_acc: 0.2525\n",
            "Epoch 7: train_loss: 1.5682 train_acc: 0.2681 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5687 train_acc: 0.2683 | val_loss: 1.5716 val_acc: 0.2598\n",
            "Epoch 9: train_loss: 1.5682 train_acc: 0.2733 | val_loss: 1.5776 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5666 train_acc: 0.2690 | val_loss: 1.5948 val_acc: 0.2797\n",
            "Epoch 11: train_loss: 1.5653 train_acc: 0.2747 | val_loss: 1.5797 val_acc: 0.2734\n",
            "Epoch 12: train_loss: 1.5696 train_acc: 0.2677 | val_loss: 1.5756 val_acc: 0.2552\n",
            "Epoch 13: train_loss: 1.5544 train_acc: 0.2949 | val_loss: 1.5317 val_acc: 0.3197\n",
            "Epoch 14: train_loss: 1.5299 train_acc: 0.3203 | val_loss: 1.5808 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5675 train_acc: 0.2705 | val_loss: 1.5735 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5059 train_acc: 0.3271 | val_loss: 1.4964 val_acc: 0.3288\n",
            "Epoch 17: train_loss: 1.4285 train_acc: 0.3605 | val_loss: 1.4024 val_acc: 0.3824\n",
            "Epoch 18: train_loss: 1.3254 train_acc: 0.4068 | val_loss: 1.3343 val_acc: 0.4169\n",
            "Epoch 19: train_loss: 1.2818 train_acc: 0.4246 | val_loss: 1.3523 val_acc: 0.3906\n",
            "Epoch 20: train_loss: 1.2487 train_acc: 0.4390 | val_loss: 1.3622 val_acc: 0.4005\n",
            "Epoch 21: train_loss: 1.2326 train_acc: 0.4444 | val_loss: 1.3768 val_acc: 0.3887\n",
            "Epoch 22: train_loss: 1.2036 train_acc: 0.4593 | val_loss: 1.4246 val_acc: 0.3996\n",
            "Epoch 23: train_loss: 1.1831 train_acc: 0.4690 | val_loss: 1.3557 val_acc: 0.4096\n",
            "Epoch 24: train_loss: 1.1585 train_acc: 0.4775 | val_loss: 1.3740 val_acc: 0.3978\n",
            "Lowest val_loss: 1.3343, at epoch 18\n",
            "LSTM 200 2 [70]\n",
            "Epoch 0: train_loss: 1.5755 train_acc: 0.2610 | val_loss: 1.5763 val_acc: 0.2816\n",
            "Epoch 1: train_loss: 1.5701 train_acc: 0.2711 | val_loss: 1.5770 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5695 train_acc: 0.2698 | val_loss: 1.5701 val_acc: 0.2643\n",
            "Epoch 3: train_loss: 1.5682 train_acc: 0.2702 | val_loss: 1.5654 val_acc: 0.2579\n",
            "Epoch 4: train_loss: 1.5621 train_acc: 0.2939 | val_loss: 1.5581 val_acc: 0.3025\n",
            "Epoch 5: train_loss: 1.5488 train_acc: 0.2946 | val_loss: 1.4880 val_acc: 0.3333\n",
            "Epoch 6: train_loss: 1.5667 train_acc: 0.2728 | val_loss: 1.5732 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5689 train_acc: 0.2636 | val_loss: 1.5766 val_acc: 0.2688\n",
            "Epoch 8: train_loss: 1.5686 train_acc: 0.2741 | val_loss: 1.5752 val_acc: 0.2779\n",
            "Epoch 9: train_loss: 1.5671 train_acc: 0.2715 | val_loss: 1.5449 val_acc: 0.3324\n",
            "Epoch 10: train_loss: 1.5771 train_acc: 0.2713 | val_loss: 1.5786 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5705 train_acc: 0.2704 | val_loss: 1.5759 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5691 train_acc: 0.2731 | val_loss: 1.5769 val_acc: 0.2625\n",
            "Epoch 13: train_loss: 1.5689 train_acc: 0.2684 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5689 train_acc: 0.2734 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5690 train_acc: 0.2697 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5690 train_acc: 0.2678 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5684 train_acc: 0.2695 | val_loss: 1.5773 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5683 train_acc: 0.2695 | val_loss: 1.5759 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5686 train_acc: 0.2683 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5687 train_acc: 0.2679 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5684 train_acc: 0.2636 | val_loss: 1.5759 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5690 train_acc: 0.2695 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Lowest val_loss: 1.4880, at epoch 5\n",
            "LSTM 250 1 [30]\n",
            "Epoch 0: train_loss: 1.5756 train_acc: 0.2614 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5694 train_acc: 0.2747 | val_loss: 1.5814 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5699 train_acc: 0.2726 | val_loss: 1.5768 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5697 train_acc: 0.2646 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5693 train_acc: 0.2676 | val_loss: 1.5733 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5686 train_acc: 0.2741 | val_loss: 1.5725 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5690 train_acc: 0.2715 | val_loss: 1.5722 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5687 train_acc: 0.2639 | val_loss: 1.5740 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5686 train_acc: 0.2683 | val_loss: 1.5711 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5669 train_acc: 0.2713 | val_loss: 1.5702 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5677 train_acc: 0.2683 | val_loss: 1.5582 val_acc: 0.3206\n",
            "Epoch 11: train_loss: 1.5668 train_acc: 0.2814 | val_loss: 1.5913 val_acc: 0.2607\n",
            "Epoch 12: train_loss: 1.5702 train_acc: 0.2664 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 13: train_loss: 1.5690 train_acc: 0.2674 | val_loss: 1.5751 val_acc: 0.2997\n",
            "Epoch 14: train_loss: 1.5683 train_acc: 0.2692 | val_loss: 1.5757 val_acc: 0.2579\n",
            "Epoch 15: train_loss: 1.5679 train_acc: 0.2665 | val_loss: 1.5748 val_acc: 0.2552\n",
            "Epoch 16: train_loss: 1.5680 train_acc: 0.2688 | val_loss: 1.5731 val_acc: 0.2589\n",
            "Epoch 17: train_loss: 1.5670 train_acc: 0.2706 | val_loss: 1.5694 val_acc: 0.2616\n",
            "Epoch 18: train_loss: 1.5657 train_acc: 0.2707 | val_loss: 1.5730 val_acc: 0.2688\n",
            "Epoch 19: train_loss: 1.5654 train_acc: 0.2711 | val_loss: 1.5732 val_acc: 0.2589\n",
            "Epoch 20: train_loss: 1.5663 train_acc: 0.2733 | val_loss: 1.5719 val_acc: 0.2561\n",
            "Epoch 21: train_loss: 1.5221 train_acc: 0.3120 | val_loss: 1.4119 val_acc: 0.3624\n",
            "Epoch 22: train_loss: 1.3351 train_acc: 0.4006 | val_loss: 1.3642 val_acc: 0.3797\n",
            "Epoch 23: train_loss: 1.2635 train_acc: 0.4293 | val_loss: 1.3938 val_acc: 0.3933\n",
            "Epoch 24: train_loss: 1.2151 train_acc: 0.4563 | val_loss: 1.3618 val_acc: 0.4033\n",
            "Lowest val_loss: 1.3618, at epoch 24\n",
            "LSTM 250 1 [40]\n",
            "Epoch 0: train_loss: 1.5738 train_acc: 0.2637 | val_loss: 1.5734 val_acc: 0.2643\n",
            "Epoch 1: train_loss: 1.5697 train_acc: 0.2645 | val_loss: 1.5698 val_acc: 0.3106\n",
            "Epoch 2: train_loss: 1.5684 train_acc: 0.2651 | val_loss: 1.5671 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5672 train_acc: 0.2664 | val_loss: 1.5579 val_acc: 0.2716\n",
            "Epoch 4: train_loss: 1.5670 train_acc: 0.2713 | val_loss: 1.5758 val_acc: 0.2834\n",
            "Epoch 5: train_loss: 1.5634 train_acc: 0.2738 | val_loss: 1.5543 val_acc: 0.2807\n",
            "Epoch 6: train_loss: 1.5632 train_acc: 0.2747 | val_loss: 1.5470 val_acc: 0.3206\n",
            "Epoch 7: train_loss: 1.5585 train_acc: 0.2960 | val_loss: 1.5677 val_acc: 0.2879\n",
            "Epoch 8: train_loss: 1.5515 train_acc: 0.3029 | val_loss: 1.5268 val_acc: 0.2852\n",
            "Epoch 9: train_loss: 1.5374 train_acc: 0.3180 | val_loss: 1.5461 val_acc: 0.3070\n",
            "Epoch 10: train_loss: 1.5428 train_acc: 0.3064 | val_loss: 1.5746 val_acc: 0.2752\n",
            "Epoch 11: train_loss: 1.5599 train_acc: 0.2930 | val_loss: 1.5666 val_acc: 0.2743\n",
            "Epoch 12: train_loss: 1.5589 train_acc: 0.2750 | val_loss: 1.5776 val_acc: 0.2589\n",
            "Epoch 13: train_loss: 1.5563 train_acc: 0.2825 | val_loss: 1.5673 val_acc: 0.2661\n",
            "Epoch 14: train_loss: 1.5544 train_acc: 0.2830 | val_loss: 1.5729 val_acc: 0.2589\n",
            "Epoch 15: train_loss: 1.5617 train_acc: 0.2766 | val_loss: 1.5756 val_acc: 0.3088\n",
            "Epoch 16: train_loss: 1.5674 train_acc: 0.2702 | val_loss: 1.5764 val_acc: 0.3097\n",
            "Epoch 17: train_loss: 1.5661 train_acc: 0.2697 | val_loss: 1.5789 val_acc: 0.2543\n",
            "Epoch 18: train_loss: 1.5660 train_acc: 0.2695 | val_loss: 1.5718 val_acc: 0.2598\n",
            "Epoch 19: train_loss: 1.5659 train_acc: 0.2665 | val_loss: 1.5696 val_acc: 0.2561\n",
            "Epoch 20: train_loss: 1.5644 train_acc: 0.2732 | val_loss: 1.5748 val_acc: 0.2552\n",
            "Epoch 21: train_loss: 1.5603 train_acc: 0.2775 | val_loss: 1.5256 val_acc: 0.3624\n",
            "Epoch 22: train_loss: 1.4209 train_acc: 0.3790 | val_loss: 1.3954 val_acc: 0.3896\n",
            "Epoch 23: train_loss: 1.3094 train_acc: 0.4119 | val_loss: 1.4202 val_acc: 0.3806\n",
            "Epoch 24: train_loss: 1.2539 train_acc: 0.4366 | val_loss: 1.3774 val_acc: 0.3942\n",
            "Lowest val_loss: 1.3774, at epoch 24\n",
            "LSTM 250 1 [50]\n",
            "Epoch 0: train_loss: 1.5718 train_acc: 0.2681 | val_loss: 1.5747 val_acc: 0.2679\n",
            "Epoch 1: train_loss: 1.5690 train_acc: 0.2656 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5682 train_acc: 0.2710 | val_loss: 1.5721 val_acc: 0.2525\n",
            "Epoch 3: train_loss: 1.5677 train_acc: 0.2651 | val_loss: 1.5694 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5676 train_acc: 0.2702 | val_loss: 1.5671 val_acc: 0.2434\n",
            "Epoch 5: train_loss: 1.5660 train_acc: 0.2808 | val_loss: 1.5466 val_acc: 0.2716\n",
            "Epoch 6: train_loss: 1.5660 train_acc: 0.2777 | val_loss: 1.5556 val_acc: 0.2525\n",
            "Epoch 7: train_loss: 1.5613 train_acc: 0.2860 | val_loss: 1.5783 val_acc: 0.2661\n",
            "Epoch 8: train_loss: 1.5838 train_acc: 0.2713 | val_loss: 1.5836 val_acc: 0.2371\n",
            "Epoch 9: train_loss: 1.5650 train_acc: 0.2708 | val_loss: 1.5905 val_acc: 0.2834\n",
            "Epoch 10: train_loss: 1.5623 train_acc: 0.2731 | val_loss: 1.5623 val_acc: 0.2525\n",
            "Epoch 11: train_loss: 1.5579 train_acc: 0.2810 | val_loss: 1.5791 val_acc: 0.2243\n",
            "Epoch 12: train_loss: 1.5618 train_acc: 0.2719 | val_loss: 1.5833 val_acc: 0.2334\n",
            "Epoch 13: train_loss: 1.5597 train_acc: 0.2734 | val_loss: 1.5750 val_acc: 0.2352\n",
            "Epoch 14: train_loss: 1.5567 train_acc: 0.2748 | val_loss: 1.5920 val_acc: 0.2997\n",
            "Epoch 15: train_loss: 1.5682 train_acc: 0.2643 | val_loss: 1.7002 val_acc: 0.2262\n",
            "Epoch 16: train_loss: 1.5705 train_acc: 0.2742 | val_loss: 1.5867 val_acc: 0.2398\n",
            "Epoch 17: train_loss: 1.5562 train_acc: 0.3000 | val_loss: 1.5748 val_acc: 0.2688\n",
            "Epoch 18: train_loss: 1.5593 train_acc: 0.2757 | val_loss: 1.5915 val_acc: 0.2688\n",
            "Epoch 19: train_loss: 1.5628 train_acc: 0.2757 | val_loss: 1.5999 val_acc: 0.2698\n",
            "Epoch 20: train_loss: 1.5600 train_acc: 0.2769 | val_loss: 1.5972 val_acc: 0.2770\n",
            "Epoch 21: train_loss: 1.5578 train_acc: 0.2780 | val_loss: 1.5965 val_acc: 0.2443\n",
            "Epoch 22: train_loss: 1.5591 train_acc: 0.2787 | val_loss: 1.6192 val_acc: 0.2752\n",
            "Epoch 23: train_loss: 1.5464 train_acc: 0.2915 | val_loss: 1.5609 val_acc: 0.3406\n",
            "Epoch 24: train_loss: 1.5423 train_acc: 0.2939 | val_loss: 1.6011 val_acc: 0.2443\n",
            "Lowest val_loss: 1.5466, at epoch 5\n",
            "LSTM 250 1 [60]\n",
            "Epoch 0: train_loss: 1.5732 train_acc: 0.2662 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5683 train_acc: 0.2678 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5680 train_acc: 0.2717 | val_loss: 1.5680 val_acc: 0.2707\n",
            "Epoch 3: train_loss: 1.5666 train_acc: 0.2685 | val_loss: 1.5555 val_acc: 0.2743\n",
            "Epoch 4: train_loss: 1.5671 train_acc: 0.2683 | val_loss: 1.5715 val_acc: 0.2489\n",
            "Epoch 5: train_loss: 1.5637 train_acc: 0.2739 | val_loss: 1.5491 val_acc: 0.2906\n",
            "Epoch 6: train_loss: 1.5378 train_acc: 0.2995 | val_loss: 1.5710 val_acc: 0.3188\n",
            "Epoch 7: train_loss: 1.5383 train_acc: 0.2882 | val_loss: 1.5491 val_acc: 0.2652\n",
            "Epoch 8: train_loss: 1.5503 train_acc: 0.2871 | val_loss: 1.5847 val_acc: 0.2543\n",
            "Epoch 9: train_loss: 1.5600 train_acc: 0.2848 | val_loss: 1.5680 val_acc: 0.2552\n",
            "Epoch 10: train_loss: 1.5593 train_acc: 0.2794 | val_loss: 1.5683 val_acc: 0.2507\n",
            "Epoch 11: train_loss: 1.5532 train_acc: 0.2756 | val_loss: 1.5739 val_acc: 0.2679\n",
            "Epoch 12: train_loss: 1.5515 train_acc: 0.2827 | val_loss: 1.5996 val_acc: 0.2561\n",
            "Epoch 13: train_loss: 1.5523 train_acc: 0.2808 | val_loss: 1.5927 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5233 train_acc: 0.3289 | val_loss: 1.5400 val_acc: 0.3052\n",
            "Epoch 15: train_loss: 1.5172 train_acc: 0.3323 | val_loss: 1.5432 val_acc: 0.3134\n",
            "Epoch 16: train_loss: 1.5108 train_acc: 0.3357 | val_loss: 1.5505 val_acc: 0.3015\n",
            "Epoch 17: train_loss: 1.5132 train_acc: 0.3329 | val_loss: 1.6101 val_acc: 0.2770\n",
            "Epoch 18: train_loss: 1.5561 train_acc: 0.2769 | val_loss: 1.6150 val_acc: 0.2788\n",
            "Epoch 19: train_loss: 1.5478 train_acc: 0.2948 | val_loss: 1.5722 val_acc: 0.2525\n",
            "Epoch 20: train_loss: 1.5690 train_acc: 0.2680 | val_loss: 1.5710 val_acc: 0.2543\n",
            "Epoch 21: train_loss: 1.5582 train_acc: 0.2860 | val_loss: 1.5648 val_acc: 0.2906\n",
            "Epoch 22: train_loss: 1.4461 train_acc: 0.3695 | val_loss: 1.5180 val_acc: 0.3152\n",
            "Epoch 23: train_loss: 1.3458 train_acc: 0.3999 | val_loss: 1.4480 val_acc: 0.3579\n",
            "Epoch 24: train_loss: 1.2924 train_acc: 0.4163 | val_loss: 1.4350 val_acc: 0.3579\n",
            "Lowest val_loss: 1.4350, at epoch 24\n",
            "LSTM 250 1 [70]\n",
            "Epoch 0: train_loss: 1.5750 train_acc: 0.2609 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5687 train_acc: 0.2645 | val_loss: 1.5684 val_acc: 0.2870\n",
            "Epoch 2: train_loss: 1.5683 train_acc: 0.2722 | val_loss: 1.5629 val_acc: 0.2561\n",
            "Epoch 3: train_loss: 1.5676 train_acc: 0.2721 | val_loss: 1.5597 val_acc: 0.2906\n",
            "Epoch 4: train_loss: 1.5648 train_acc: 0.2697 | val_loss: 1.5639 val_acc: 0.3070\n",
            "Epoch 5: train_loss: 1.5624 train_acc: 0.2766 | val_loss: 1.6550 val_acc: 0.2679\n",
            "Epoch 6: train_loss: 1.5608 train_acc: 0.2727 | val_loss: 1.5605 val_acc: 0.3088\n",
            "Epoch 7: train_loss: 1.5584 train_acc: 0.2816 | val_loss: 1.6134 val_acc: 0.3243\n",
            "Epoch 8: train_loss: 1.5549 train_acc: 0.2823 | val_loss: 1.5753 val_acc: 0.2788\n",
            "Epoch 9: train_loss: 1.5570 train_acc: 0.2760 | val_loss: 1.5923 val_acc: 0.2498\n",
            "Epoch 10: train_loss: 1.5217 train_acc: 0.3079 | val_loss: 1.6667 val_acc: 0.2480\n",
            "Epoch 11: train_loss: 1.5567 train_acc: 0.2804 | val_loss: 1.6021 val_acc: 0.2807\n",
            "Epoch 12: train_loss: 1.5554 train_acc: 0.2728 | val_loss: 1.6349 val_acc: 0.2943\n",
            "Epoch 13: train_loss: 1.5517 train_acc: 0.2767 | val_loss: 1.7475 val_acc: 0.2643\n",
            "Epoch 14: train_loss: 1.4964 train_acc: 0.3446 | val_loss: 1.5750 val_acc: 0.3106\n",
            "Epoch 15: train_loss: 1.4646 train_acc: 0.3690 | val_loss: 1.5302 val_acc: 0.3361\n",
            "Epoch 16: train_loss: 1.5501 train_acc: 0.2797 | val_loss: 1.6184 val_acc: 0.2906\n",
            "Epoch 17: train_loss: 1.5285 train_acc: 0.2885 | val_loss: 1.5960 val_acc: 0.2779\n",
            "Epoch 18: train_loss: 1.5207 train_acc: 0.3055 | val_loss: 1.7075 val_acc: 0.2507\n",
            "Epoch 19: train_loss: 1.5551 train_acc: 0.2800 | val_loss: 1.6414 val_acc: 0.2561\n",
            "Epoch 20: train_loss: 1.5553 train_acc: 0.2752 | val_loss: 1.6677 val_acc: 0.2607\n",
            "Epoch 21: train_loss: 1.5470 train_acc: 0.2883 | val_loss: 1.6631 val_acc: 0.3097\n",
            "Epoch 22: train_loss: 1.4919 train_acc: 0.3538 | val_loss: 1.5443 val_acc: 0.3270\n",
            "Epoch 23: train_loss: 1.3826 train_acc: 0.3901 | val_loss: 1.4952 val_acc: 0.3497\n",
            "Epoch 24: train_loss: 1.3106 train_acc: 0.4161 | val_loss: 1.5584 val_acc: 0.3442\n",
            "Lowest val_loss: 1.4952, at epoch 23\n",
            "LSTM 250 2 [30]\n",
            "Epoch 0: train_loss: 1.5744 train_acc: 0.2647 | val_loss: 1.5770 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5695 train_acc: 0.2687 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5704 train_acc: 0.2680 | val_loss: 1.5761 val_acc: 0.2543\n",
            "Epoch 3: train_loss: 1.5697 train_acc: 0.2698 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5692 train_acc: 0.2669 | val_loss: 1.5760 val_acc: 0.2625\n",
            "Epoch 5: train_loss: 1.5687 train_acc: 0.2735 | val_loss: 1.5758 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5690 train_acc: 0.2665 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5691 train_acc: 0.2674 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5690 train_acc: 0.2647 | val_loss: 1.5780 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5690 train_acc: 0.2713 | val_loss: 1.5758 val_acc: 0.2652\n",
            "Epoch 10: train_loss: 1.5690 train_acc: 0.2699 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 11: train_loss: 1.5689 train_acc: 0.2697 | val_loss: 1.5744 val_acc: 0.2625\n",
            "Epoch 12: train_loss: 1.5688 train_acc: 0.2700 | val_loss: 1.5767 val_acc: 0.2625\n",
            "Epoch 13: train_loss: 1.5688 train_acc: 0.2672 | val_loss: 1.5741 val_acc: 0.2625\n",
            "Epoch 14: train_loss: 1.5685 train_acc: 0.2700 | val_loss: 1.5748 val_acc: 0.3224\n",
            "Epoch 15: train_loss: 1.5688 train_acc: 0.2739 | val_loss: 1.5745 val_acc: 0.2743\n",
            "Epoch 16: train_loss: 1.5685 train_acc: 0.2599 | val_loss: 1.5762 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5683 train_acc: 0.2656 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5683 train_acc: 0.2674 | val_loss: 1.5746 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5682 train_acc: 0.2710 | val_loss: 1.5746 val_acc: 0.2625\n",
            "Epoch 22: train_loss: 1.5684 train_acc: 0.2692 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5745 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5741, at epoch 13\n",
            "LSTM 250 2 [40]\n",
            "Epoch 0: train_loss: 1.5742 train_acc: 0.2597 | val_loss: 1.5749 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5700 train_acc: 0.2643 | val_loss: 1.5773 val_acc: 0.2616\n",
            "Epoch 2: train_loss: 1.5698 train_acc: 0.2683 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5694 train_acc: 0.2669 | val_loss: 1.5769 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5697 train_acc: 0.2695 | val_loss: 1.5755 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5687 train_acc: 0.2707 | val_loss: 1.5754 val_acc: 0.2534\n",
            "Epoch 6: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5753 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5688 train_acc: 0.2718 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 8: train_loss: 1.5691 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 9: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 10: train_loss: 1.5701 train_acc: 0.2685 | val_loss: 1.5753 val_acc: 0.2625\n",
            "Epoch 11: train_loss: 1.5692 train_acc: 0.2671 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 12: train_loss: 1.5681 train_acc: 0.2712 | val_loss: 1.5766 val_acc: 0.2634\n",
            "Epoch 13: train_loss: 1.5686 train_acc: 0.2707 | val_loss: 1.5763 val_acc: 0.2534\n",
            "Epoch 14: train_loss: 1.5679 train_acc: 0.2720 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2720 | val_loss: 1.5748 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5684 train_acc: 0.2720 | val_loss: 1.5752 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5681 train_acc: 0.2715 | val_loss: 1.5741 val_acc: 0.2634\n",
            "Epoch 18: train_loss: 1.5689 train_acc: 0.2679 | val_loss: 1.5747 val_acc: 0.2634\n",
            "Epoch 19: train_loss: 1.5687 train_acc: 0.2684 | val_loss: 1.5751 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5685 train_acc: 0.2674 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 21: train_loss: 1.5680 train_acc: 0.2720 | val_loss: 1.5764 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5687 train_acc: 0.2720 | val_loss: 1.5761 val_acc: 0.2534\n",
            "Epoch 23: train_loss: 1.5690 train_acc: 0.2720 | val_loss: 1.5747 val_acc: 0.2534\n",
            "Epoch 24: train_loss: 1.5685 train_acc: 0.2720 | val_loss: 1.5750 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5741, at epoch 17\n",
            "LSTM 250 2 [50]\n",
            "Epoch 0: train_loss: 1.5740 train_acc: 0.2590 | val_loss: 1.5864 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5707 train_acc: 0.2643 | val_loss: 1.5821 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5698 train_acc: 0.2670 | val_loss: 1.5716 val_acc: 0.3288\n",
            "Epoch 3: train_loss: 1.5698 train_acc: 0.2631 | val_loss: 1.5701 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5720 train_acc: 0.2717 | val_loss: 1.5818 val_acc: 0.2525\n",
            "Epoch 5: train_loss: 1.5693 train_acc: 0.2683 | val_loss: 1.5637 val_acc: 0.2625\n",
            "Epoch 6: train_loss: 1.5680 train_acc: 0.2667 | val_loss: 1.5626 val_acc: 0.2534\n",
            "Epoch 7: train_loss: 1.5653 train_acc: 0.2687 | val_loss: 1.5492 val_acc: 0.3233\n",
            "Epoch 8: train_loss: 1.5677 train_acc: 0.2728 | val_loss: 1.5867 val_acc: 0.2507\n",
            "Epoch 9: train_loss: 1.5695 train_acc: 0.2671 | val_loss: 1.5869 val_acc: 0.2543\n",
            "Epoch 10: train_loss: 1.5689 train_acc: 0.2657 | val_loss: 1.5865 val_acc: 0.2543\n",
            "Epoch 11: train_loss: 1.5685 train_acc: 0.2699 | val_loss: 1.5868 val_acc: 0.2507\n",
            "Epoch 12: train_loss: 1.5689 train_acc: 0.2711 | val_loss: 1.5871 val_acc: 0.2552\n",
            "Epoch 13: train_loss: 1.5692 train_acc: 0.2707 | val_loss: 1.5861 val_acc: 0.2498\n",
            "Epoch 14: train_loss: 1.5685 train_acc: 0.2686 | val_loss: 1.5861 val_acc: 0.2498\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2688 | val_loss: 1.5868 val_acc: 0.2534\n",
            "Epoch 16: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5864 val_acc: 0.2543\n",
            "Epoch 17: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5866 val_acc: 0.2552\n",
            "Epoch 18: train_loss: 1.5687 train_acc: 0.2678 | val_loss: 1.5880 val_acc: 0.2552\n",
            "Epoch 19: train_loss: 1.5683 train_acc: 0.2718 | val_loss: 1.5866 val_acc: 0.2543\n",
            "Epoch 20: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5864 val_acc: 0.2552\n",
            "Epoch 21: train_loss: 1.5682 train_acc: 0.2699 | val_loss: 1.5860 val_acc: 0.2534\n",
            "Epoch 22: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5861 val_acc: 0.2552\n",
            "Epoch 23: train_loss: 1.5688 train_acc: 0.2702 | val_loss: 1.5860 val_acc: 0.2552\n",
            "Epoch 24: train_loss: 1.5688 train_acc: 0.2692 | val_loss: 1.5865 val_acc: 0.2534\n",
            "Lowest val_loss: 1.5492, at epoch 7\n",
            "LSTM 250 2 [60]\n",
            "Epoch 0: train_loss: 1.5719 train_acc: 0.2650 | val_loss: 1.5731 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5689 train_acc: 0.2706 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5685 train_acc: 0.2674 | val_loss: 1.5704 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5672 train_acc: 0.2722 | val_loss: 1.5566 val_acc: 0.2852\n",
            "Epoch 4: train_loss: 1.5667 train_acc: 0.2671 | val_loss: 1.5691 val_acc: 0.3342\n",
            "Epoch 5: train_loss: 1.5646 train_acc: 0.2748 | val_loss: 1.5323 val_acc: 0.3170\n",
            "Epoch 6: train_loss: 1.5665 train_acc: 0.2789 | val_loss: 1.5777 val_acc: 0.2625\n",
            "Epoch 7: train_loss: 1.5689 train_acc: 0.2679 | val_loss: 1.5758 val_acc: 0.2525\n",
            "Epoch 8: train_loss: 1.5691 train_acc: 0.2688 | val_loss: 1.5755 val_acc: 0.2525\n",
            "Epoch 9: train_loss: 1.5691 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2525\n",
            "Epoch 10: train_loss: 1.5684 train_acc: 0.2642 | val_loss: 1.5770 val_acc: 0.2525\n",
            "Epoch 11: train_loss: 1.5689 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2525\n",
            "Epoch 12: train_loss: 1.5687 train_acc: 0.2718 | val_loss: 1.5779 val_acc: 0.2525\n",
            "Epoch 13: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5751 val_acc: 0.2525\n",
            "Epoch 14: train_loss: 1.5679 train_acc: 0.2718 | val_loss: 1.5749 val_acc: 0.2525\n",
            "Epoch 15: train_loss: 1.5682 train_acc: 0.2718 | val_loss: 1.5752 val_acc: 0.2525\n",
            "Epoch 16: train_loss: 1.5681 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2525\n",
            "Epoch 17: train_loss: 1.5684 train_acc: 0.2718 | val_loss: 1.5737 val_acc: 0.2525\n",
            "Epoch 18: train_loss: 1.5669 train_acc: 0.2754 | val_loss: 1.5785 val_acc: 0.2552\n",
            "Epoch 19: train_loss: 1.5686 train_acc: 0.2697 | val_loss: 1.5757 val_acc: 0.2534\n",
            "Epoch 20: train_loss: 1.5514 train_acc: 0.2944 | val_loss: 1.4691 val_acc: 0.3551\n",
            "Epoch 21: train_loss: 1.3822 train_acc: 0.3873 | val_loss: 1.4992 val_acc: 0.3533\n",
            "Epoch 22: train_loss: 1.3011 train_acc: 0.4119 | val_loss: 1.3663 val_acc: 0.3806\n",
            "Epoch 23: train_loss: 1.2476 train_acc: 0.4379 | val_loss: 1.3398 val_acc: 0.4096\n",
            "Epoch 24: train_loss: 1.2171 train_acc: 0.4561 | val_loss: 1.3603 val_acc: 0.4078\n",
            "Lowest val_loss: 1.3398, at epoch 23\n",
            "LSTM 250 2 [70]\n",
            "Epoch 0: train_loss: 1.5714 train_acc: 0.2660 | val_loss: 1.5739 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5696 train_acc: 0.2721 | val_loss: 1.5736 val_acc: 0.2534\n",
            "Epoch 2: train_loss: 1.5686 train_acc: 0.2718 | val_loss: 1.5729 val_acc: 0.2534\n",
            "Epoch 3: train_loss: 1.5691 train_acc: 0.2630 | val_loss: 1.5806 val_acc: 0.2534\n",
            "Epoch 4: train_loss: 1.5689 train_acc: 0.2712 | val_loss: 1.5913 val_acc: 0.2534\n",
            "Epoch 5: train_loss: 1.5672 train_acc: 0.2681 | val_loss: 1.5616 val_acc: 0.3261\n",
            "Epoch 6: train_loss: 1.5656 train_acc: 0.2749 | val_loss: 1.5762 val_acc: 0.2634\n",
            "Epoch 7: train_loss: 1.5547 train_acc: 0.2924 | val_loss: 1.5760 val_acc: 0.2489\n",
            "Epoch 8: train_loss: 1.5407 train_acc: 0.2919 | val_loss: 1.5761 val_acc: 0.2589\n",
            "Epoch 9: train_loss: 1.5668 train_acc: 0.2734 | val_loss: 1.5762 val_acc: 0.2525\n",
            "Epoch 10: train_loss: 1.5688 train_acc: 0.2666 | val_loss: 1.5764 val_acc: 0.2525\n",
            "Epoch 11: train_loss: 1.5687 train_acc: 0.2678 | val_loss: 1.5778 val_acc: 0.2525\n",
            "Epoch 12: train_loss: 1.5683 train_acc: 0.2728 | val_loss: 1.5786 val_acc: 0.2616\n",
            "Epoch 13: train_loss: 1.5682 train_acc: 0.2693 | val_loss: 1.5769 val_acc: 0.2525\n",
            "Epoch 14: train_loss: 1.5688 train_acc: 0.2707 | val_loss: 1.5762 val_acc: 0.2625\n",
            "Epoch 15: train_loss: 1.5684 train_acc: 0.2698 | val_loss: 1.5775 val_acc: 0.2525\n",
            "Epoch 16: train_loss: 1.5686 train_acc: 0.2695 | val_loss: 1.5742 val_acc: 0.2534\n",
            "Epoch 17: train_loss: 1.5685 train_acc: 0.2718 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 18: train_loss: 1.5681 train_acc: 0.2666 | val_loss: 1.5756 val_acc: 0.2534\n",
            "Epoch 19: train_loss: 1.5684 train_acc: 0.2677 | val_loss: 1.5758 val_acc: 0.2498\n",
            "Epoch 20: train_loss: 1.5668 train_acc: 0.2708 | val_loss: 1.5776 val_acc: 0.2516\n",
            "Epoch 21: train_loss: 1.5674 train_acc: 0.2710 | val_loss: 1.5766 val_acc: 0.2525\n",
            "Epoch 22: train_loss: 1.5643 train_acc: 0.2731 | val_loss: 1.5849 val_acc: 0.2452\n",
            "Epoch 23: train_loss: 1.5364 train_acc: 0.2985 | val_loss: 1.4528 val_acc: 0.3742\n",
            "Epoch 24: train_loss: 1.3489 train_acc: 0.3965 | val_loss: 1.4767 val_acc: 0.3579\n",
            "Lowest val_loss: 1.4528, at epoch 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzC2e40a85EO",
        "colab_type": "text"
      },
      "source": [
        "Looking at the results of grid search, we noticed that:\n",
        "\n",
        "\n",
        "1.   GRU reach the highest validation accuracy (~44%) than LSTM in most scenarios\n",
        "2.   Out of those hyperparameter combinations, a common theme was 2-layer GRUs\n",
        "3.   There were a couple of combinations of parameters that achieved consistently high validation accuracy (~33%). Thus, we selected the combination with the least number of units for generalisation reasons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5P5X5qoBQXM",
        "colab_type": "text"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFjwQOgIiYDW",
        "colab_type": "text"
      },
      "source": [
        "Here, we have our optimum architecture based on our grid search. We trained our model to convergence on training loss. However, we picked the model when it has the lowest validation loss, which happens quite early on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJODJ5S5tRSk",
        "outputId": "b4dabd2c-0f42-438f-e269-d6fe60d5db9f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "embedding_dim = TEXT.vocab.vectors.size()[1]\n",
        "num_hidden_rnn = 50\n",
        "num_rnn_layers = 2\n",
        "mlp_layers = [50]\n",
        "num_classes = 5\n",
        "rec_unit_type = \"GRU\"\n",
        "train_embeddings = False\n",
        "\n",
        "m = Model(\n",
        "    vocab_size, \n",
        "    embedding_dim, \n",
        "    TEXT.vocab.vectors, \n",
        "    num_hidden_rnn, \n",
        "    num_rnn_layers, \n",
        "    mlp_layers, \n",
        "    num_classes, \n",
        "    rec_unit_type, \n",
        "    train_embeddings).to(device)\n",
        "# Filter is in place to ensure only layers with \"requires_grad\" will have their weights updated\n",
        "opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), 1e-3)\n",
        "\n",
        "print(m)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (embeddings): Embedding(18254, 300)\n",
            "  (rec): GRU(300, 50, num_layers=2)\n",
            "  (mlp): ModuleList(\n",
            "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
            "  )\n",
            "  (out): Linear(in_features=50, out_features=5, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3zrl8-EQ24Wm",
        "outputId": "c639426d-acdc-4520-96d1-0c4d86fe9bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "m, measurements = fit(\n",
        "    model=m,\n",
        "    train_dl=train_batch_it, \n",
        "    val_dl=val_batch_it, \n",
        "    loss_fn=F.cross_entropy,\n",
        "    opt=opt,\n",
        "    epochs=100,\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train_loss: 1.5715 train_acc: 0.2665 | val_loss: 1.5787 val_acc: 0.2534\n",
            "Epoch 1: train_loss: 1.5685 train_acc: 0.2704 | val_loss: 1.5682 val_acc: 0.2589\n",
            "Epoch 2: train_loss: 1.5236 train_acc: 0.3150 | val_loss: 1.4061 val_acc: 0.3833\n",
            "Epoch 3: train_loss: 1.3206 train_acc: 0.4084 | val_loss: 1.4621 val_acc: 0.3633\n",
            "Epoch 4: train_loss: 1.2489 train_acc: 0.4426 | val_loss: 1.3289 val_acc: 0.4133\n",
            "Epoch 5: train_loss: 1.2102 train_acc: 0.4544 | val_loss: 1.3418 val_acc: 0.4205\n",
            "Epoch 6: train_loss: 1.1798 train_acc: 0.4753 | val_loss: 1.3229 val_acc: 0.4060\n",
            "Epoch 7: train_loss: 1.1579 train_acc: 0.4798 | val_loss: 1.3177 val_acc: 0.4269\n",
            "Epoch 8: train_loss: 1.1384 train_acc: 0.4925 | val_loss: 1.3349 val_acc: 0.4069\n",
            "Epoch 9: train_loss: 1.1169 train_acc: 0.5049 | val_loss: 1.3678 val_acc: 0.4133\n",
            "Epoch 10: train_loss: 1.0849 train_acc: 0.5254 | val_loss: 1.3218 val_acc: 0.4196\n",
            "Epoch 11: train_loss: 1.0637 train_acc: 0.5296 | val_loss: 1.3211 val_acc: 0.4205\n",
            "Epoch 12: train_loss: 1.0370 train_acc: 0.5500 | val_loss: 1.3192 val_acc: 0.4360\n",
            "Epoch 13: train_loss: 1.0040 train_acc: 0.5611 | val_loss: 1.3326 val_acc: 0.4342\n",
            "Epoch 14: train_loss: 0.9652 train_acc: 0.5879 | val_loss: 1.4055 val_acc: 0.4142\n",
            "Epoch 15: train_loss: 0.9348 train_acc: 0.6044 | val_loss: 1.3449 val_acc: 0.4332\n",
            "Epoch 16: train_loss: 0.8870 train_acc: 0.6264 | val_loss: 1.4176 val_acc: 0.4405\n",
            "Epoch 17: train_loss: 0.8461 train_acc: 0.6553 | val_loss: 1.4696 val_acc: 0.4024\n",
            "Epoch 18: train_loss: 0.7983 train_acc: 0.6737 | val_loss: 1.5255 val_acc: 0.4114\n",
            "Epoch 19: train_loss: 0.7600 train_acc: 0.6963 | val_loss: 1.5124 val_acc: 0.4360\n",
            "Epoch 20: train_loss: 0.7215 train_acc: 0.7143 | val_loss: 1.6241 val_acc: 0.4096\n",
            "Epoch 21: train_loss: 0.6816 train_acc: 0.7335 | val_loss: 1.6068 val_acc: 0.4205\n",
            "Epoch 22: train_loss: 0.6206 train_acc: 0.7612 | val_loss: 1.7095 val_acc: 0.4114\n",
            "Epoch 23: train_loss: 0.5855 train_acc: 0.7787 | val_loss: 1.8020 val_acc: 0.4178\n",
            "Epoch 24: train_loss: 0.5466 train_acc: 0.7946 | val_loss: 1.7930 val_acc: 0.4060\n",
            "Epoch 25: train_loss: 0.5135 train_acc: 0.8075 | val_loss: 1.8339 val_acc: 0.4087\n",
            "Epoch 26: train_loss: 0.4594 train_acc: 0.8332 | val_loss: 1.9529 val_acc: 0.3960\n",
            "Epoch 27: train_loss: 0.4491 train_acc: 0.8391 | val_loss: 1.9812 val_acc: 0.4015\n",
            "Epoch 28: train_loss: 0.4093 train_acc: 0.8533 | val_loss: 2.0102 val_acc: 0.3878\n",
            "Epoch 29: train_loss: 0.4033 train_acc: 0.8548 | val_loss: 1.9791 val_acc: 0.3906\n",
            "Epoch 30: train_loss: 0.3605 train_acc: 0.8741 | val_loss: 2.1139 val_acc: 0.3933\n",
            "Epoch 31: train_loss: 0.3591 train_acc: 0.8735 | val_loss: 2.0893 val_acc: 0.3842\n",
            "Epoch 32: train_loss: 0.3377 train_acc: 0.8814 | val_loss: 2.1528 val_acc: 0.3842\n",
            "Epoch 33: train_loss: 0.3134 train_acc: 0.8917 | val_loss: 2.1821 val_acc: 0.3842\n",
            "Epoch 34: train_loss: 0.2954 train_acc: 0.8985 | val_loss: 2.3144 val_acc: 0.3987\n",
            "Epoch 35: train_loss: 0.2950 train_acc: 0.9007 | val_loss: 2.1946 val_acc: 0.3787\n",
            "Epoch 36: train_loss: 0.2637 train_acc: 0.9123 | val_loss: 2.2931 val_acc: 0.3787\n",
            "Epoch 37: train_loss: 0.2519 train_acc: 0.9165 | val_loss: 2.3980 val_acc: 0.3860\n",
            "Epoch 38: train_loss: 0.2435 train_acc: 0.9204 | val_loss: 2.3956 val_acc: 0.3906\n",
            "Epoch 39: train_loss: 0.2469 train_acc: 0.9167 | val_loss: 2.3734 val_acc: 0.3915\n",
            "Epoch 40: train_loss: 0.2142 train_acc: 0.9313 | val_loss: 2.4698 val_acc: 0.3751\n",
            "Epoch 41: train_loss: 0.2005 train_acc: 0.9353 | val_loss: 2.5304 val_acc: 0.3869\n",
            "Epoch 42: train_loss: 0.2350 train_acc: 0.9223 | val_loss: 2.4547 val_acc: 0.3815\n",
            "Epoch 43: train_loss: 0.2158 train_acc: 0.9279 | val_loss: 2.5196 val_acc: 0.3742\n",
            "Epoch 44: train_loss: 0.1915 train_acc: 0.9398 | val_loss: 2.5594 val_acc: 0.3815\n",
            "Epoch 45: train_loss: 0.1976 train_acc: 0.9349 | val_loss: 2.6282 val_acc: 0.3924\n",
            "Epoch 46: train_loss: 0.1963 train_acc: 0.9368 | val_loss: 2.6185 val_acc: 0.3915\n",
            "Epoch 47: train_loss: 0.1609 train_acc: 0.9489 | val_loss: 2.6694 val_acc: 0.3815\n",
            "Epoch 48: train_loss: 0.1512 train_acc: 0.9535 | val_loss: 2.7694 val_acc: 0.3760\n",
            "Epoch 49: train_loss: 0.1662 train_acc: 0.9486 | val_loss: 2.6611 val_acc: 0.3769\n",
            "Epoch 50: train_loss: 0.1571 train_acc: 0.9501 | val_loss: 2.8423 val_acc: 0.3842\n",
            "Epoch 51: train_loss: 0.1591 train_acc: 0.9492 | val_loss: 2.8139 val_acc: 0.3833\n",
            "Epoch 52: train_loss: 0.1551 train_acc: 0.9513 | val_loss: 2.8339 val_acc: 0.3787\n",
            "Epoch 53: train_loss: 0.1504 train_acc: 0.9528 | val_loss: 2.7870 val_acc: 0.3697\n",
            "Epoch 54: train_loss: 0.1423 train_acc: 0.9542 | val_loss: 2.9722 val_acc: 0.3824\n",
            "Epoch 55: train_loss: 0.1282 train_acc: 0.9603 | val_loss: 2.9595 val_acc: 0.3815\n",
            "Epoch 56: train_loss: 0.1062 train_acc: 0.9685 | val_loss: 3.0172 val_acc: 0.3887\n",
            "Epoch 57: train_loss: 0.1206 train_acc: 0.9621 | val_loss: 3.1832 val_acc: 0.3715\n",
            "Epoch 58: train_loss: 0.1322 train_acc: 0.9585 | val_loss: 3.0752 val_acc: 0.3887\n",
            "Epoch 59: train_loss: 0.1315 train_acc: 0.9599 | val_loss: 3.0779 val_acc: 0.3933\n",
            "Epoch 60: train_loss: 0.1075 train_acc: 0.9689 | val_loss: 3.1196 val_acc: 0.3778\n",
            "Epoch 61: train_loss: 0.0981 train_acc: 0.9707 | val_loss: 3.2232 val_acc: 0.3896\n",
            "Epoch 62: train_loss: 0.1095 train_acc: 0.9650 | val_loss: 3.2339 val_acc: 0.3869\n",
            "Epoch 63: train_loss: 0.1130 train_acc: 0.9644 | val_loss: 3.2577 val_acc: 0.3942\n",
            "Epoch 64: train_loss: 0.1308 train_acc: 0.9615 | val_loss: 3.1922 val_acc: 0.3615\n",
            "Epoch 65: train_loss: 0.1148 train_acc: 0.9648 | val_loss: 3.2305 val_acc: 0.3806\n",
            "Epoch 66: train_loss: 0.1059 train_acc: 0.9675 | val_loss: 3.3129 val_acc: 0.3878\n",
            "Epoch 67: train_loss: 0.1017 train_acc: 0.9676 | val_loss: 3.2458 val_acc: 0.3860\n",
            "Epoch 68: train_loss: 0.0987 train_acc: 0.9693 | val_loss: 3.3746 val_acc: 0.3915\n",
            "Epoch 69: train_loss: 0.0955 train_acc: 0.9707 | val_loss: 3.2927 val_acc: 0.3869\n",
            "Epoch 70: train_loss: 0.0762 train_acc: 0.9767 | val_loss: 3.5887 val_acc: 0.3797\n",
            "Epoch 71: train_loss: 0.0878 train_acc: 0.9725 | val_loss: 3.4288 val_acc: 0.3797\n",
            "Epoch 72: train_loss: 0.1334 train_acc: 0.9588 | val_loss: 3.3572 val_acc: 0.3778\n",
            "Epoch 73: train_loss: 0.0948 train_acc: 0.9716 | val_loss: 3.4578 val_acc: 0.3787\n",
            "Epoch 74: train_loss: 0.0642 train_acc: 0.9817 | val_loss: 3.5601 val_acc: 0.3815\n",
            "Epoch 75: train_loss: 0.0663 train_acc: 0.9815 | val_loss: 3.6235 val_acc: 0.3769\n",
            "Epoch 76: train_loss: 0.0764 train_acc: 0.9786 | val_loss: 3.6059 val_acc: 0.3760\n",
            "Epoch 77: train_loss: 0.0817 train_acc: 0.9758 | val_loss: 3.6564 val_acc: 0.3778\n",
            "Epoch 78: train_loss: 0.0809 train_acc: 0.9745 | val_loss: 3.6749 val_acc: 0.3688\n",
            "Epoch 79: train_loss: 0.0701 train_acc: 0.9785 | val_loss: 3.6845 val_acc: 0.3815\n",
            "Epoch 80: train_loss: 0.1120 train_acc: 0.9634 | val_loss: 3.6674 val_acc: 0.3878\n",
            "Epoch 81: train_loss: 0.0855 train_acc: 0.9754 | val_loss: 3.5565 val_acc: 0.3951\n",
            "Epoch 82: train_loss: 0.0632 train_acc: 0.9821 | val_loss: 3.6144 val_acc: 0.3842\n",
            "Epoch 83: train_loss: 0.0573 train_acc: 0.9836 | val_loss: 3.7583 val_acc: 0.4005\n",
            "Epoch 84: train_loss: 0.0533 train_acc: 0.9855 | val_loss: 3.8373 val_acc: 0.3824\n",
            "Epoch 85: train_loss: 0.0712 train_acc: 0.9792 | val_loss: 3.7866 val_acc: 0.3842\n",
            "Epoch 86: train_loss: 0.0563 train_acc: 0.9850 | val_loss: 3.7946 val_acc: 0.3833\n",
            "Epoch 87: train_loss: 0.0449 train_acc: 0.9870 | val_loss: 3.8795 val_acc: 0.3996\n",
            "Epoch 88: train_loss: 0.0527 train_acc: 0.9846 | val_loss: 3.9318 val_acc: 0.3924\n",
            "Epoch 89: train_loss: 0.0664 train_acc: 0.9789 | val_loss: 3.8572 val_acc: 0.3860\n",
            "Epoch 90: train_loss: 0.0628 train_acc: 0.9808 | val_loss: 3.9508 val_acc: 0.3878\n",
            "Epoch 91: train_loss: 0.0779 train_acc: 0.9768 | val_loss: 3.7715 val_acc: 0.3833\n",
            "Epoch 92: train_loss: 0.0692 train_acc: 0.9799 | val_loss: 3.9271 val_acc: 0.3824\n",
            "Epoch 93: train_loss: 0.0442 train_acc: 0.9878 | val_loss: 4.0137 val_acc: 0.3733\n",
            "Epoch 94: train_loss: 0.0312 train_acc: 0.9917 | val_loss: 4.1155 val_acc: 0.3842\n",
            "Epoch 95: train_loss: 0.0507 train_acc: 0.9854 | val_loss: 4.0678 val_acc: 0.3815\n",
            "Epoch 96: train_loss: 0.0757 train_acc: 0.9774 | val_loss: 4.0531 val_acc: 0.3996\n",
            "Epoch 97: train_loss: 0.0613 train_acc: 0.9823 | val_loss: 4.0071 val_acc: 0.3824\n",
            "Epoch 98: train_loss: 0.0593 train_acc: 0.9830 | val_loss: 4.0772 val_acc: 0.3942\n",
            "Epoch 99: train_loss: 0.0335 train_acc: 0.9904 | val_loss: 4.1749 val_acc: 0.3915\n",
            "Lowest val_loss: 1.3177, at epoch 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrmAmxBlyQV6",
        "colab_type": "code",
        "outputId": "a734078c-884c-42b6-ef5a-32d0bea95cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(measurements[\"Train Loss\"], label=\"Train Loss\")\n",
        "plt.plot(measurements[\"Val Loss\"], label=\"Validation Loss\")\n",
        "plt.axvline(measurements[\"Lowest Val Loss Epoch\"], linestyle='--', color='r',label='Checkpoint')\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cross Entropy Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe2ad013668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFNCAYAAAAtnkrkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngedyQwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlK2yhmMyQV-",
        "colab_type": "text"
      },
      "source": [
        "## Final Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-g3CyY0t9cqV",
        "colab": {}
      },
      "source": [
        "testdl = data.Iterator(testds,\n",
        "                        batch_size=batch_size,\n",
        "                        sort_key=lambda x: len(x.Text),\n",
        "                        device=device,\n",
        "                        sort_within_batch=False)\n",
        "test_batch_it = BatchGenerator(testdl, 'Text', 'Label')\n",
        "m.eval()\n",
        "loss_fn=F.cross_entropy\n",
        "accuracies = []\n",
        "\n",
        "for batch_it in [train_batch_it, val_batch_it, test_batch_it]:\n",
        "  y_true = list()\n",
        "  y_pred = list()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (X,lengths),y in iter(batch_it):\n",
        "      pred = m(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      pred_idx = torch.max(pred, 1)[1]\n",
        "\n",
        "      y_true += list(y.cpu().data.numpy())\n",
        "      y_pred += list(pred_idx.cpu().data.numpy())\n",
        "      total_loss += loss.item()\n",
        "\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  accuracies.append(acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aEkKa9zyQWF",
        "colab_type": "code",
        "outputId": "de51c6ed-2033-41d0-e654-cb7f7766db2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f'Training Accuracy: {accuracies[0]:.4f}')\n",
        "print(f'Validation Accuracy: {accuracies[1]:.4f}')\n",
        "print(f'Test Accuracy: {accuracies[2]:.4f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.5091\n",
            "Validation Accuracy: 0.4269\n",
            "Test Accuracy: 0.4416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFVgJBllyQWH",
        "colab_type": "text"
      },
      "source": [
        "## Test Inferences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl54_VloyQWI",
        "colab_type": "code",
        "outputId": "62632557-ca93-468c-a0cc-87d6d3b208e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Movie reviews from:\n",
        "# https://www.rottentomatoes.com/m/the_dark_knight\n",
        "\n",
        "reviews = [\n",
        "    \"An exceptionally smart, brooding picture with some terrific performances.\",\n",
        "    \"You will feel utterly numb after the screening of The Dark Knight. The film is bleak and brilliant.\",\n",
        "    \"The definitive movie of its genre and the best Batman film to date\",\n",
        "    \"Too much psychology and not enough pop. It's possible to be too serious, you know.\",\n",
        "    \"One of the most stylish extravaganzas in years.\",\n",
        "]\n",
        "field = [('Text', TEXT)]\n",
        "my_examples = pd.DataFrame({'text': reviews})\n",
        "my_examples.to_csv('/tmp/my_examples.csv', index=False)\n",
        "my_ds = data.TabularDataset(path='/tmp/my_examples.csv', \n",
        "                            format='csv', \n",
        "                            fields=field, \n",
        "                            skip_header=True)\n",
        "my_dl = data.Iterator(my_ds, batch_size=5, device=device)\n",
        "my_it = BatchGenerator(my_dl, 'Text', 'Text')\n",
        "m.eval()\n",
        "\n",
        "(X,_),_ = next(iter(my_it))\n",
        "pred = m(X)\n",
        "pred_idx = torch.max(pred, 1)[1].cpu().data.numpy()\n",
        "for i in range(len(pred_idx)):\n",
        "  print(\"Sentiment: {}. Review: {}\".format(pred_idx[i], reviews[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment: 4. Review: An exceptionally smart, brooding picture with some terrific performances.\n",
            "Sentiment: 4. Review: You will feel utterly numb after the screening of The Dark Knight. The film is bleak and brilliant.\n",
            "Sentiment: 4. Review: The definitive movie of its genre and the best Batman film to date\n",
            "Sentiment: 0. Review: Too much psychology and not enough pop. It's possible to be too serious, you know.\n",
            "Sentiment: 1. Review: One of the most stylish extravaganzas in years.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "MXr25yHvyQWK",
        "colab_type": "text"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhsYZ_K-yQWL",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8"
      ]
    }
  ]
}